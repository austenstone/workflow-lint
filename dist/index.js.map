{"version":3,"file":"index.js","mappings":";;;;;;;;;;AAAa;AACb;AACA;AACA,mCAAmC,oCAAoC,gBAAgB;AACvF,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA,0CAA0C,4BAA4B;AACtE,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,aAAa,GAAG,oBAAoB;AACpC,wBAAwB,mBAAO,CAAC,cAAI;AACpC,gBAAgB,mBAAO,CAAC,0DAAS;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA,yBAAyB;AACzB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,IAAI,GAAG,oBAAoB;AAChE;AACA;AACA;AACA;AACA,qBAAqB,WAAW,EAAE,yBAAyB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AC3Fa;AACb;AACA;AACA,mCAAmC,oCAAoC,gBAAgB;AACvF,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA,0CAA0C,4BAA4B;AACtE,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,+DAA+D,iBAAiB;AAC5G;AACA,oCAAoC,MAAM,+BAA+B,YAAY;AACrF,mCAAmC,MAAM,mCAAmC,YAAY;AACxF,gCAAgC;AAChC;AACA,KAAK;AACL;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,kBAAkB,GAAG,gBAAgB,GAAG,iBAAiB,GAAG,aAAa,GAAG,gBAAgB,GAAG,kBAAkB,GAAG,YAAY,GAAG,cAAc,GAAG,eAAe,GAAG,aAAa,GAAG,aAAa,GAAG,eAAe,GAAG,iBAAiB,GAAG,sBAAsB,GAAG,iBAAiB,GAAG,uBAAuB,GAAG,yBAAyB,GAAG,gBAAgB,GAAG,eAAe,GAAG,iBAAiB,GAAG,sBAAsB,GAAG,gBAAgB;AACjb,kBAAkB,mBAAO,CAAC,8DAAW;AACrC,uBAAuB,mBAAO,CAAC,wEAAgB;AAC/C,gBAAgB,mBAAO,CAAC,0DAAS;AACjC,wBAAwB,mBAAO,CAAC,cAAI;AACpC,0BAA0B,mBAAO,CAAC,kBAAM;AACxC,qBAAqB,mBAAO,CAAC,oEAAc;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,kCAAkC,gBAAgB,KAAK;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,MAAM;AAC9C;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA,6BAA6B,UAAU,EAAE,eAAe,EAAE,oBAAoB;AAC9E;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,sCAAsC;AAC3E;AACA,4DAA4D,KAAK;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF,KAAK;AAC1F;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,MAAM;AACjD;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,MAAM;AACjD;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,KAAK;AACrC;AACA,gBAAgB;AAChB;AACA;AACA;AACA,KAAK;AACL;AACA,kBAAkB;AAClB;AACA;AACA;AACA,gBAAgB,mBAAO,CAAC,8DAAW;AACnC,2CAA0C,EAAE,qCAAqC,6BAA6B,EAAC;AAC/G;AACA;AACA;AACA,gBAAgB,mBAAO,CAAC,8DAAW;AACnC,mDAAkD,EAAE,qCAAqC,qCAAqC,EAAC;AAC/H;AACA;AACA;AACA,mBAAmB,mBAAO,CAAC,oEAAc;AACzC,+CAA8C,EAAE,qCAAqC,oCAAoC,EAAC;AAC1H,+CAA8C,EAAE,qCAAqC,oCAAoC,EAAC;AAC1H,kDAAiD,EAAE,qCAAqC,uCAAuC,EAAC;AAChI;;;;;;;;;;;AC/Ua;AACb;AACA;AACA;AACA,mCAAmC,oCAAoC,gBAAgB;AACvF,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA,0CAA0C,4BAA4B;AACtE,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,8BAA8B,GAAG,wBAAwB;AACzD;AACA;AACA,wBAAwB,mBAAO,CAAC,cAAI;AACpC,wBAAwB,mBAAO,CAAC,cAAI;AACpC,eAAe,mBAAO,CAAC,wDAAM;AAC7B,gBAAgB,mBAAO,CAAC,0DAAS;AACjC;AACA,2CAA2C,QAAQ;AACnD;AACA,gFAAgF,QAAQ;AACxF;AACA;AACA,iDAAiD,SAAS;AAC1D;AACA,mCAAmC,gCAAgC,EAAE,OAAO;AAC5E;AACA,KAAK;AACL;AACA,wBAAwB;AACxB;AACA,sCAAsC,YAAY;AAClD;AACA;AACA;AACA;AACA;AACA,oFAAoF,UAAU;AAC9F;AACA;AACA,qFAAqF,UAAU;AAC/F;AACA,cAAc,IAAI,IAAI,UAAU,EAAE,OAAO,EAAE,eAAe,EAAE,OAAO,EAAE,UAAU;AAC/E;AACA,8BAA8B;AAC9B;;;;;;;;;;;ACzDa;AACb;AACA,4BAA4B,+DAA+D,iBAAiB;AAC5G;AACA,oCAAoC,MAAM,+BAA+B,YAAY;AACrF,mCAAmC,MAAM,mCAAmC,YAAY;AACxF,gCAAgC;AAChC;AACA,KAAK;AACL;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,kBAAkB;AAClB,sBAAsB,mBAAO,CAAC,8EAAsB;AACpD,eAAe,mBAAO,CAAC,sFAA+B;AACtD,eAAe,mBAAO,CAAC,wDAAQ;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC,yBAAyB,cAAc;AACvC,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,aAAa,YAAY,gBAAgB;AAC/E;AACA,gDAAgD,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA,kDAAkD,cAAc;AAChE;AACA,SAAS;AACT;AACA;AACA,kBAAkB;AAClB;;;;;;;;;;;AC5Ea;AACb;AACA;AACA,mCAAmC,oCAAoC,gBAAgB;AACvF,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA,0CAA0C,4BAA4B;AACtE,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,sBAAsB,GAAG,mBAAmB,GAAG,mBAAmB;AAClE,0BAA0B,mBAAO,CAAC,kBAAM;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;;;;;;;;;;;ACzDa;AACb;AACA,4BAA4B,+DAA+D,iBAAiB;AAC5G;AACA,oCAAoC,MAAM,+BAA+B,YAAY;AACrF,mCAAmC,MAAM,mCAAmC,YAAY;AACxF,gCAAgC;AAChC;AACA,KAAK;AACL;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,eAAe,GAAG,uBAAuB,GAAG,wBAAwB,GAAG,uBAAuB;AAC9F,aAAa,mBAAO,CAAC,cAAI;AACzB,aAAa,mBAAO,CAAC,cAAI;AACzB,QAAQ,gCAAgC;AACxC,uBAAuB;AACvB,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,wBAAwB;AACpG;AACA;AACA;AACA;AACA;AACA,mEAAmE,YAAY;AAC/E;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,eAAe;AAC9B,eAAe,6BAA6B;AAC5C;AACA,iBAAiB,QAAQ;AACzB;AACA,iCAAiC;AACjC;AACA,uCAAuC,IAAI,IAAI,MAAM;AACrD;AACA;AACA,uBAAuB,IAAI,EAAE,UAAU;AACvC;AACA,mBAAmB,IAAI,EAAE,UAAU,GAAG,QAAQ,IAAI,IAAI;AACtD;AACA;AACA;AACA;AACA,eAAe,qBAAqB;AACpC;AACA,iBAAiB,kBAAkB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,kBAAkB;AACxE;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA,8CAA8C,iBAAiB;AAC/D,SAAS;AACT;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,SAAS;AACxB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA,sCAAsC,aAAa,MAAM;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,UAAU;AACzB,eAAe,SAAS;AACxB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oBAAoB;AACnC;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,iCAAiC;AACzD;AACA,4DAA4D,gBAAgB,SAAS,kBAAkB,SAAS;AAChH;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,qBAAqB;AACpC;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA,gBAAgB,gBAAgB;AAChC,oDAAoD,cAAc,OAAO,iBAAiB,QAAQ;AAClG,+DAA+D,UAAU;AACzE;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,iBAAiB;AAChC;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA,wBAAwB,MAAM;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA,sCAAsC,aAAa,MAAM;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA,+CAA+C,MAAM;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,eAAe;AACf;;;;;;;;;;;AC1Ra;AACb;AACA;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,2BAA2B,GAAG,sBAAsB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;;;;;;;;;;;ACvCa;AACb;AACA,4BAA4B,+DAA+D,iBAAiB;AAC5G;AACA,oCAAoC,MAAM,+BAA+B,YAAY;AACrF,mCAAmC,MAAM,mCAAmC,YAAY;AACxF,gCAAgC;AAChC;AACA,KAAK;AACL;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,4CAA4C,GAAG,+BAA+B,GAAG,8BAA8B;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,eAAe,cAAc,GAAG,cAAc,sBAAsB;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,WAAW;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,mBAAmB,WAAW,sBAAsB;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,4CAA4C;AAC5C;;;;;;;;;;;AChFa;AACb;AACA;AACA;AACA,mCAAmC,oCAAoC,gBAAgB;AACvF,CAAC;AACD;AACA;AACA,CAAC;AACD;AACA,0CAA0C,4BAA4B;AACtE,CAAC;AACD;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,+DAA+D,iBAAiB;AAC5G;AACA,oCAAoC,MAAM,+BAA+B,YAAY;AACrF,mCAAmC,MAAM,mCAAmC,YAAY;AACxF,gCAAgC;AAChC;AACA,KAAK;AACL;AACA,8CAA6C,EAAE,aAAa,EAAC;AAC7D,kBAAkB,GAAG,eAAe,GAAG,0BAA0B,GAAG,uBAAuB,GAAG,mBAAmB,GAAG,kBAAkB,GAAG,eAAe,GAAG,iBAAiB;AAC5K,0BAA0B,mBAAO,CAAC,kBAAM;AACxC,2BAA2B,mBAAO,CAAC,oBAAO;AAC1C,wBAAwB,mBAAO,CAAC,iEAAS;AACzC,4BAA4B,mBAAO,CAAC,8CAAQ;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oCAAoC,iBAAiB,KAAK;AAC3D;AACA;AACA;AACA;AACA,CAAC,gCAAgC,eAAe,KAAK;AACrD;AACA;AACA;AACA,CAAC,sCAAsC,kBAAkB,KAAK;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF;AACpF,SAAS;AACT;AACA;AACA;AACA,gFAAgF;AAChF,SAAS;AACT;AACA;AACA;AACA,mFAAmF;AACnF,SAAS;AACT;AACA;AACA;AACA,iFAAiF;AACjF,SAAS;AACT;AACA;AACA;AACA,kFAAkF;AAClF,SAAS;AACT;AACA;AACA;AACA,gFAAgF;AAChF,SAAS;AACT;AACA;AACA;AACA,iFAAiF;AACjF,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,mDAAmD;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,uDAAuD,kBAAkB;AACzE,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,yEAAyE;AAC5G;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD;AACrD,kCAAkC,kBAAkB,GAAG,kBAAkB;AACzE,iBAAiB,MAAM,8CAA8C;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D;AAC7D;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,WAAW;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA,kBAAkB;AAClB,uGAAuG;AACvG;;;;;;;;;;;AC5lBa;AACb,8CAA6C,EAAE,aAAa,EAAC;AAC7D,mBAAmB,GAAG,mBAAmB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,iBAAiB,GAAG,QAAQ;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;;;;;;;;;;AC5DA;AACA,IAAI,IAAyD;AAC7D;AACA,MAAM,EAK0B;AAChC,CAAC;AACD,yBAAyB;AACzB;AACA;;AAEA;AACA,0CAA0C,8BAAmB;;;AAG7D,gDAAgD,aAAa;AAC7D;AACA,uBAAuB,8BAAmB;AAC1C;AACA;AACA,kDAAkD;AAClD,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,EAAE;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,IAAI,aAAa,IAAI;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,4BAA4B;AACpD;AACA;AACA;AACA;AACA,iDAAiD,oBAAoB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;AAGA,OAAO;;AAEP;AACA,0CAA0C,+BAAmB;;;AAG7D,gDAAgD,aAAa;AAC7D;AACA,wBAAwB,+BAAmB;AAC3C,mBAAmB,+BAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,sBAAsB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,IAAI,QAAQ,IAAI;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,IAAI;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,yBAAyB;AACzB;AACA,yBAAyB;AACzB;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,qBAAqB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;AAGA,OAAO;;AAEP;AACA,0CAA0C,gCAAmB;;;AAG7D,gDAAgD,aAAa;AAC7D;AACA,WAAW,gCAAmB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;AAGA,OAAO;;AAEP;AACA;;;AAGA,gDAAgD,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;AAGA,OAAO;;AAEP;AACA;;;AAGA,gDAAgD,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;AAGA,OAAO;;AAEP;AACA;;;AAGA,gDAAgD,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,uBAAuB;AAChD;AACA;AACA;AACA;AACA,6BAA6B,uBAAuB;AACpD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,CAAC;AACD;;;AAGA,OAAO;;AAEP,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,mBAAmB,gCAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,gCAAmB;AACpF;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,0BAAmB;AACvB;AACA;AACA,cAAc,0BAAmB;;AAEjC,gDAAgD,aAAa;AAC7D;AACA,6BAA6B,gCAAmB;AAChD,uBAAuB,gCAAmB;AAC1C;AACA;AACA;AACA;;AAEA,CAAC;;AAED,iBAAiB,0BAAmB;AACpC,UAAU;AACV;AACA,CAAC;;;;;;;;;;ACvhCD,+FAAwC;;;;;;;;;;;;ACA3B;;AAEb,UAAU,mBAAO,CAAC,gBAAK;AACvB,UAAU,mBAAO,CAAC,gBAAK;AACvB,WAAW,mBAAO,CAAC,kBAAM;AACzB,YAAY,mBAAO,CAAC,oBAAO;AAC3B,aAAa,mBAAO,CAAC,sBAAQ;AAC7B,aAAa,mBAAO,CAAC,sBAAQ;AAC7B,WAAW,mBAAO,CAAC,kBAAM;;;AAGzB,oBAAoB;AACpB,qBAAqB;AACrB,qBAAqB;AACrB,sBAAsB;;;AAGtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gDAAgD,SAAS;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA,8BAA8B,aAAa;;AAE3C;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,kDAAkD;AAClD,2CAA2C;AAC3C,2CAA2C;AAC3C,2CAA2C;AAC3C;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA,GAAG;AACH;;;AAGA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;;AAEA;AACA,0CAA0C,SAAS;AACnD;AACA;AACA;AACA,4CAA4C,YAAY;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA,aAAa,UAAU;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvQiB;AACA;AACA;AACA;AACE;AACQ;AACE;AACE;;;;;;;;;;;;;;;;;;ACP1B;;AAE5B;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA,SAAS,wDAAiB;AAC1B;;AAEA,iEAAe,GAAG;;;;;;;;;;;;;;;ACZlB,iEAAe,sCAAsC;;;;;;;;;;;;;;;;ACAhB;;AAErC;AACA,OAAO,wDAAQ;AACf;AACA;;AAEA;AACA,kCAAkC;;AAElC;AACA;AACA;AACA,qBAAqB;;AAErB;AACA,qBAAqB;;AAErB;AACA,qBAAqB;;AAErB;AACA,qBAAqB;AACrB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iEAAe,KAAK;;;;;;;;;;;;;;;AClCpB,iEAAe,cAAc,EAAE,UAAU,EAAE,eAAe,EAAE,gBAAgB,EAAE,UAAU,GAAG,yCAAyC;;;;;;;;;;;;;;;;;ACAxG;AAC5B,uCAAuC;;AAEvC;AACe;AACf;AACA,IAAI,4DAAqB;AACzB;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;ACX4B;;AAE5B;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA,SAAS,wDAAiB;AAC1B;;AAEA,iEAAe,IAAI;;;;;;;;;;;;;;;;ACZkB;AACrC;AACA;AACA;AACA;;AAEA;;AAEA,gBAAgB,SAAS;AACzB;AACA;;AAEA;AACA;AACA;AACA,4gBAA4gB;AAC5gB;AACA;AACA;AACA;;AAEA,OAAO,wDAAQ;AACf;AACA;;AAEA;AACA;;AAEA,iEAAe,SAAS;;;;;;;;;;;;;;;;;AC5BG;AACY,CAAC;AACxC;AACA;AACA;;AAEA;;AAEA,eAAe;;;AAGf;AACA,oBAAoB;;AAEpB;AACA;AACA;AACA;AACA;AACA,gFAAgF;AAChF;AACA;;AAEA;AACA,wDAAwD,+CAAG;;AAE3D;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;;AAGA,wEAAwE;AACxE;;AAEA,4EAA4E;;AAE5E,gEAAgE;;AAEhE;AACA;AACA,IAAI;AACJ;;;AAGA;AACA;AACA,IAAI;;;AAGJ;AACA;AACA;;AAEA;AACA;AACA,wBAAwB;;AAExB,2BAA2B;;AAE3B;AACA;AACA;AACA;AACA,sBAAsB;;AAEtB;AACA;AACA,uBAAuB;;AAEvB,oCAAoC;;AAEpC,8BAA8B;;AAE9B,kCAAkC;;AAElC,4BAA4B;;AAE5B,kBAAkB,OAAO;AACzB;AACA;;AAEA,gBAAgB,yDAAS;AACzB;;AAEA,iEAAe,EAAE;;;;;;;;;;;;;;;;;AC9FU;AACA;AAC3B,WAAW,mDAAG,aAAa,+CAAG;AAC9B,iEAAe,EAAE;;;;;;;;;;;;;;;;;;;ACHsB;AACR;;AAE/B;AACA,2CAA2C;;AAE3C;;AAEA,kBAAkB,gBAAgB;AAClC;AACA;;AAEA;AACA;;AAEO;AACA;AACP,6BAAe,oCAAU;AACzB;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,qDAAK;AACvB;;AAEA;AACA;AACA,MAAM;AACN;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,sBAAsB,QAAQ;AAC9B;AACA;;AAEA;AACA;;AAEA,WAAW,yDAAS;AACpB,IAAI;;;AAGJ;AACA,8BAA8B;AAC9B,IAAI,eAAe;;;AAGnB;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC/D2B;AACY;;AAEvC;AACA;AACA,iDAAiD,+CAAG,KAAK;;AAEzD;AACA,mCAAmC;;AAEnC;AACA;;AAEA,oBAAoB,QAAQ;AAC5B;AACA;;AAEA;AACA;;AAEA,SAAS,yDAAS;AAClB;;AAEA,iEAAe,EAAE;;;;;;;;;;;;;;;;;ACvBU;AACE;AAC7B,WAAW,mDAAG,aAAa,gDAAI;AAC/B,iEAAe,EAAE;;;;;;;;;;;;;;;;ACHc;;AAE/B;AACA,qCAAqC,iDAAK;AAC1C;;AAEA,iEAAe,QAAQ;;;;;;;;;;;;;;;;ACNc;;AAErC;AACA,OAAO,wDAAQ;AACf;AACA;;AAEA;AACA;;AAEA,iEAAe,OAAO;;;;;;;;;;;ACVtB;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAA;;;;;;;;;;;ACAa;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,aAAa,mBAAO,CAAC,oEAAoB;AACzC,cAAc,mBAAO,CAAC,sEAAqB;AAC3C,cAAc,mBAAO,CAAC,sEAAqB;AAC3C,sBAAsB,mBAAO,CAAC,qFAAwB;AACtD,sBAAsB,mBAAO,CAAC,qFAAwB;AACtD,4BAA4B,mBAAO,CAAC,iGAA8B;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,QAAQ,gBAAgB;AACzE;AACA;AACA;AACA;AACA,4DAA4D,QAAQ,WAAW,SAAS,0BAA0B,cAAc;AAChI;AACA;AACA,2EAA2E,QAAQ;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB;;;;;;;;;;;;AC7EZ;;AAEb,eAAe,mBAAO,CAAC,oEAAoB;AAC3C,kBAAkB,mBAAO,CAAC,2EAAmB;AAC7C,iBAAiB,mBAAO,CAAC,yEAAkB;AAC3C,mBAAmB,mBAAO,CAAC,6EAAoB;;AAE/C,2CAA2C,2BAA2B;AACtE,iCAAiC,yBAAyB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kBAAkB;;;;;;;;;;;;AC1CL;;AAEb,YAAY,mBAAO,CAAC,kEAAmB;AACvC,wBAAwB,mBAAO,CAAC,uFAAyB;AACzD,oBAAoB,mBAAO,CAAC,+EAAqB;AACjD,iBAAiB,mBAAO,CAAC,yEAAkB;AAC3C,8BAA8B,mBAAO,CAAC,uGAAiC;;AAEvE,aAAa;AACb;AACA,YAAY,oCAAoC;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,WAAW;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,wCAAwC;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,SAAS,IAAI,qBAAqB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,wBAAwB;AACxB,mBAAmB;;;;;;;;;;;;AC9FN;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,aAAa,mBAAO,CAAC,oEAAoB;AACzC,yBAAyB,mBAAO,CAAC,2FAA2B;AAC5D,wBAAwB,mBAAO,CAAC,yFAA0B;;AAE1D;AACA,YAAY,8BAA8B;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,QAAQ,iCAAiC;AAClF;AACA;AACA,+DAA+D,QAAQ;AACvE;AACA;AACA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,IAAI,KAAK,GAAG;AACrE;AACA;AACA;AACA;AACA;;AAEA,qBAAqB;;;;;;;;;;;;ACjFR;;AAEb,iBAAiB,mBAAO,CAAC,wEAAsB;AAC/C,eAAe,mBAAO,CAAC,oEAAoB;AAC3C,aAAa,mBAAO,CAAC,wDAAc;AACnC,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,iBAAiB,mBAAO,CAAC,yEAAkB;AAC3C,iBAAiB,mBAAO,CAAC,yEAAkB;;AAE3C;AACA;AACA;AACA;AACA;AACA,YAAY,iBAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,YAAY,mBAAmB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,mCAAmC;AACzF;AACA;AACA;AACA,gBAAgB,0BAA0B;AAC1C,wBAAwB,mCAAmC;AAC3D;AACA;AACA;AACA,+CAA+C,YAAY,IAAI,QAAQ;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,QAAQ,IAAI,GAAG;AAC1D;AACA;AACA;AACA,2CAA2C,QAAQ,IAAI,GAAG;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,aAAa;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,cAAc,IAAI,6BAA6B;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,GAAG,IAAI,YAAY;AAClE;AACA;AACA;AACA;AACA;AACA,wHAAwH,WAAW;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,8BAA8B;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gBAAgB;;;;;;;;;;;;AC5NH;;AAEb,WAAW,mBAAO,CAAC,gEAAkB;AACrC,cAAc,mBAAO,CAAC,sEAAqB;AAC3C,mBAAmB,mBAAO,CAAC,6EAAoB;AAC/C,0BAA0B,mBAAO,CAAC,6FAA4B;AAC9D,0BAA0B,mBAAO,CAAC,+FAA6B;AAC/D,sBAAsB,mBAAO,CAAC,qFAAwB;;AAEtD;AACA,2BAA2B,+BAA+B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yBAAyB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB;;;;;;;;;;;;AChHV;;AAEb,aAAa,mBAAO,CAAC,oEAAoB;;AAEzC;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,mCAAmC,QAAQ;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,iBAAiB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA,+BAA+B,gBAAgB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,IAAI;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,kBAAkB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,kCAAkC,eAAe;AACjD;AACA;AACA;AACA;AACA;AACA,YAAY,SAAS;AACrB;AACA;AACA;AACA;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6FAA6F,OAAO;AACpG;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,WAAW;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;;AAEA,0BAA0B;;;;;;;;;;;;ACnMb;;AAEb,cAAc,mBAAO,CAAC,sEAAqB;AAC3C,mBAAmB,mBAAO,CAAC,6EAAoB;AAC/C,0BAA0B,mBAAO,CAAC,+FAA6B;;AAE/D,2BAA2B,+BAA+B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,eAAe;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB;;;;;;;;;;;;AC/CV;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,eAAe;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,MAAM;AAC3E;AACA;AACA;AACA;AACA,aAAa;AACb;;AAEA,kBAAkB;;;;;;;;;;;;ACtCL;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,WAAW,mBAAO,CAAC,gEAAkB;AACrC,cAAc,mBAAO,CAAC,sEAAqB;AAC3C,cAAc,mBAAO,CAAC,sEAAqB;AAC3C,iBAAiB,mBAAO,CAAC,yEAAkB;AAC3C,mBAAmB,mBAAO,CAAC,6EAAoB;AAC/C,0BAA0B,mBAAO,CAAC,6FAA4B;AAC9D,sBAAsB,mBAAO,CAAC,qFAAwB;;AAEtD;AACA;AACA,iCAAiC,+BAA+B;AAChE,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,qBAAqB;AACzC;AACA,gBAAgB,yBAAyB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,gFAAgF,OAAO;AACvF;AACA,yFAAyF,OAAO;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,OAAO;AACnF;AACA;AACA;AACA,0EAA0E,QAAQ;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+EAA+E,OAAO;AACtF;AACA,wFAAwF,QAAQ;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,MAAM,kBAAkB,YAAY;AACrD,iBAAiB,MAAM,mEAAmE,YAAY;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,6BAA6B;;;;;;;;;;;;ACxMhB;;AAEb,aAAa,mBAAO,CAAC,oEAAoB;AACzC,iBAAiB,mBAAO,CAAC,yEAAkB;;AAE3C;AACA,YAAY,4BAA4B;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4FAA4F,KAAK;AACjG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,UAAU;AAC1D;AACA;AACA;AACA;AACA,4CAA4C,UAAU;AACtD;AACA;AACA;AACA;AACA,wEAAwE,QAAQ;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;AACA;AACA,oBAAoB,eAAe;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,kBAAkB;AACnD;AACA;AACA;AACA;AACA;AACA,2EAA2E,IAAI;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,IAAI;AAC5E;AACA;AACA;AACA;;AAEA,yBAAyB;;;;;;;;;;;;AChOZ;;AAEb,gCAAgC,wDAAwD;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2FAA2F,cAAc;AACzG;AACA,qEAAqE,cAAc,KAAK,qBAAqB;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,KAAK;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,YAAY;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB;;;;;;;;;;;;ACvIP;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB;;;;;;;;;;;;ACnCV;;AAEb;AACA;AACA;AACA;AACA,8BAA8B,QAAQ;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,2BAA2B;;;;;;;;;;;;AC5Bd;;AAEb,0BAA0B,mBAAO,CAAC,6FAA4B;;AAE9D;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB;;;;;;;;;;;;AChBV;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;;AAE7C;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB;;;;;;;;;;;;AClBN;;AAEb,YAAY,mBAAO,CAAC,kEAAmB;AACvC,iBAAiB,mBAAO,CAAC,4EAAwB;AACjD,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,WAAW,mBAAO,CAAC,gEAAkB;AACrC,WAAW,mBAAO,CAAC,gEAAkB;AACrC,aAAa,mBAAO,CAAC,sEAAqB;AAC1C,wBAAwB,mBAAO,CAAC,kGAAmC;AACnE,cAAc,mBAAO,CAAC,6DAAc;AACpC,mBAAmB,mBAAO,CAAC,uEAAmB;AAC9C,iBAAiB,mBAAO,CAAC,mEAAiB;AAC1C,iBAAiB,mBAAO,CAAC,mEAAiB;;AAE1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,qBAAqB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,cAAc,UAAU;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,SAAS;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC,SAAS;AACT;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,WAAW;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,0EAA0E;AAC1F,gBAAgB,sCAAsC;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,gBAAgB;AAClF,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,SAAS;AAC3E,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,GAAG;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,iBAAiB;AAC9E;AACA;AACA,WAAW,4DAA4D,IAAI;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,aAAa;AACtC;AACA;AACA,mDAAmD,SAAS;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gDAAgD;AAC3E;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,+EAA+E,EAAE;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gBAAgB;;;;;;;;;;;;AC/UH;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,YAAY,mBAAO,CAAC,sDAAa;;AAEjC;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA,iFAAiF,GAAG;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oBAAoB,MAAM;AAC1B,wBAAwB,OAAO,EAAE,EAAE;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA,qBAAqB;AACrB,mBAAmB;AACnB,yBAAyB;AACzB,qBAAqB;;;;;;;;;;;;AC5ER;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,SAAS;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB;;;;;;;;;;;;ACvDP;;AAEb,YAAY,mBAAO,CAAC,kEAAmB;AACvC,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,aAAa,mBAAO,CAAC,oEAAoB;;AAEzC;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,SAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mEAAmE;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kBAAkB;;;;;;;;;;;;AC1FL;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,YAAY,mBAAO,CAAC,sDAAa;;AAEjC;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,MAAM;AACN;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,QAAQ;AACnE;AACA;AACA;AACA;AACA,gDAAgD,KAAK;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA,wCAAwC,OAAO;AAC/C;AACA;AACA;AACA;AACA;AACA,6DAA6D,QAAQ;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA,2BAA2B;AAC3B,0CAA0C,OAAO;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,IAAI;AAC/C;AACA;AACA;AACA,wBAAwB,2BAA2B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,QAAQ,EAAE,OAAO;AACpD;AACA;AACA;AACA;AACA,2BAA2B;AAC3B,2BAA2B;;AAE3B,kBAAkB;;;;;;;;;;;;AC1KL;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,YAAY;AACxB,iCAAiC,KAAK,WAAW,IAAI;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,QAAQ,IAAI,QAAQ;AACrD;AACA;;AAEA,iBAAiB;AACjB,sBAAsB;AACtB,mBAAmB;AACnB,qBAAqB;;;;;;;;;;;;AC7DR;;AAEb,eAAe,mBAAO,CAAC,2EAAuB;AAC9C,eAAe,mBAAO,CAAC,mEAAmB;AAC1C,aAAa,mBAAO,CAAC,qEAAoB;AACzC,aAAa,mBAAO,CAAC,uDAAa;AAClC,YAAY,mBAAO,CAAC,iEAAkB;AACtC,eAAe,mBAAO,CAAC,uEAAqB;AAC5C,WAAW,mBAAO,CAAC,+DAAiB;AACpC,aAAa,mBAAO,CAAC,mEAAmB;AACxC,cAAc,mBAAO,CAAC,qEAAoB;AAC1C,cAAc,mBAAO,CAAC,qEAAoB;AAC1C,UAAU,mBAAO,CAAC,6DAAgB;AAClC,YAAY,mBAAO,CAAC,iEAAkB;AACtC,kBAAkB,mBAAO,CAAC,+EAAyB;AACnD,aAAa,mBAAO,CAAC,mEAAmB;AACxC,gBAAgB,mBAAO,CAAC,+DAAiB;AACzC,YAAY,mBAAO,CAAC,qDAAY;;;;AAIhC,gBAAgB;AAChB,gBAAgB;AAChB,cAAc;AACd,iBAAiB;AACjB,sBAAsB;AACtB,mBAAmB;AACnB,aAAa;AACb,eAAe;AACf,oBAAoB;AACpB,kBAAkB;AAClB,aAAa;AACb,cAAc;AACd,cAAc;AACd,gBAAgB;AAChB,aAAa;AACb,YAAY;AACZ,cAAc;AACd,eAAe;AACf,eAAe;AACf,WAAW;AACX,aAAa;AACb,mBAAmB;AACnB,cAAc;AACd,aAAa;AACb,yBAAyB;AACzB,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb,kBAAkB;;;;;;;;;;;;ACjDL;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa;AACb,YAAY;;;;;;;;;;;;AClBC;;AAEb,cAAc,mBAAO,CAAC,kEAAmB;AACzC,YAAY,mBAAO,CAAC,sDAAa;AACjC,eAAe,mBAAO,CAAC,iEAAe;AACtC,WAAW,mBAAO,CAAC,yDAAW;AAC9B,WAAW,mBAAO,CAAC,yDAAW;;AAE9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,qBAAqB;AACrB,gBAAgB,8BAA8B;AAC9C;AACA;AACA,uFAAuF,YAAY;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA;AACA;AACA,2FAA2F,YAAY;AACvG;AACA;AACA;AACA,0BAA0B,KAAK;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa;;;;;;;;;;;;ACtGA;;AAEb,iBAAiB,mBAAO,CAAC,wEAAsB;AAC/C,eAAe,mBAAO,CAAC,iEAAe;AACtC,WAAW,mBAAO,CAAC,yDAAW;;AAE9B;AACA;AACA,kCAAkC,QAAQ;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,YAAY;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,IAAI,oBAAoB,KAAK;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,IAAI,oBAAoB,KAAK;AACxF;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,IAAI,oBAAoB,KAAK;AAC5F;AACA;AACA;AACA;;AAEA,kBAAkB;AAClB,0BAA0B;AAC1B,mBAAmB;;;;;;;;;;;;ACvJN;;AAEb,mBAAmB,mBAAO,CAAC,4EAAwB;AACnD,eAAe,mBAAO,CAAC,iEAAe;AACtC,WAAW,mBAAO,CAAC,yDAAW;;AAE9B;AACA;AACA,0DAA0D,aAAa;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,6CAA6C,IAAI;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,aAAa;AACtC;AACA;AACA,mDAAmD,SAAS;AAC5D;AACA;AACA;;AAEA,gBAAgB;;;;;;;;;;;;ACvCH;;AAEb,iBAAiB,mBAAO,CAAC,wEAAsB;AAC/C,oBAAoB,mBAAO,CAAC,0FAA+B;AAC3D,qBAAqB,mBAAO,CAAC,6EAAqB;AAClD,eAAe,mBAAO,CAAC,iEAAe;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,sBAAsB;AAChF;AACA;AACA;AACA;AACA,cAAc,aAAa;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,YAAY;AACZ,kBAAkB;;;;;;;;;;;;ACtCL;;AAEb,eAAe,mBAAO,CAAC,iEAAe;AACtC,WAAW,mBAAO,CAAC,yDAAW;AAC9B,WAAW,mBAAO,CAAC,yDAAW;;AAE9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,cAAc;AACd,qBAAqB;;;;;;;;;;;;AC1BR;;AAEb,0BAA0B,mBAAO,CAAC,sGAAqC;AACvE,qBAAqB,mBAAO,CAAC,6EAAqB;AAClD,iBAAiB,mBAAO,CAAC,qEAAiB;AAC1C,eAAe,mBAAO,CAAC,iEAAe;AACtC,WAAW,mBAAO,CAAC,yDAAW;AAC9B,aAAa,mBAAO,CAAC,6DAAa;;AAElC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,0BAA0B;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,WAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,QAAQ,sBAAsB;AAC5F;AACA;AACA,kCAAkC,SAAS,qBAAqB;AAChE;AACA;AACA,yBAAyB,SAAS,UAAU,GAAG;AAC/C;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA,eAAe;AACf,gBAAgB;;;;;;;;;;;;AClJH;;AAEb,iBAAiB,mBAAO,CAAC,wEAAsB;AAC/C,0BAA0B,mBAAO,CAAC,sGAAqC;AACvE,iBAAiB,mBAAO,CAAC,qEAAiB;AAC1C,eAAe,mBAAO,CAAC,iEAAe;AACtC,aAAa,mBAAO,CAAC,6DAAa;AAClC,WAAW,mBAAO,CAAC,yDAAW;;AAE9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,IAAI;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sBAAsB;AAC/C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,gBAAgB,WAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe;;;;;;;;;;;;AClHF;;AAEb,UAAU,mBAAO,CAAC,kDAAW;AAC7B,gBAAgB,mBAAO,CAAC,kFAA2B;AACnD,eAAe,mBAAO,CAAC,iEAAe;AACtC,aAAa,mBAAO,CAAC,6DAAa;AAClC,WAAW,mBAAO,CAAC,yDAAW;;AAE9B;AACA,oCAAoC,YAAY;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iIAAiI,QAAQ;AACzI;AACA;AACA;AACA;AACA;AACA;;AAEA,sBAAsB;;;;;;;;;;;;ACzGT;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa;AACb,WAAW;AACX,WAAW;AACX,iBAAiB;AACjB,YAAY;AACZ,cAAc;AACd,WAAW;AACX,iBAAiB;AACjB,eAAe;AACf,oBAAoB;AACpB,kBAAkB;AAClB,aAAa;AACb,cAAc;AACd,cAAc;AACd,gBAAgB;AAChB,aAAa;;;;;;;;;;;;ACpDA;;AAEb,eAAe,mBAAO,CAAC,iEAAe;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,YAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,YAAY;;;;;;;;;;;;ACtCC;;AAEb,yBAAyB,mBAAO,CAAC,oGAAoC;AACrE,wBAAwB,mBAAO,CAAC,kGAAmC;AACnE,aAAa,mBAAO,CAAC,wDAAc;AACnC,sBAAsB,mBAAO,CAAC,8FAAiC;;AAE/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,2EAA2E;AACvF,qDAAqD,aAAa;AAClE;AACA;AACA;AACA,mBAAmB;AACnB,KAAK;AACL;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA,6BAA6B,mDAAmD;AAChF,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA,qBAAqB;AACrB;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD,UAAU,8DAA8D;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,aAAa;AAClE;AACA;AACA;AACA,mBAAmB;AACnB,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA,cAAc;AACd;AACA;AACA,yBAAyB,mDAAmD;AAC5E;AACA;AACA;AACA,+BAA+B,mDAAmD;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,mBAAmB;AACtD;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,mCAAmC,yBAAyB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,2BAA2B;AAC9D;AACA;AACA;;AAEA,yBAAyB;AACzB,uBAAuB;AACvB,sBAAsB;;;;;;;;;;;;ACzNT;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,wBAAwB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB;;;;;;;;;;;;AC9DJ;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,wBAAwB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa;;;;;;;;;;;;AClGA;;AAEb,gBAAgB,mBAAO,CAAC,qEAAiB;AACzC,mBAAmB,mBAAO,CAAC,2EAAoB;AAC/C,eAAe,mBAAO,CAAC,mEAAgB;;AAEvC;AACA,gBAAgB,KAAK;AACrB;AACA,yBAAyB;AACzB;AACA,yBAAyB;AACzB;AACA,uBAAuB;AACvB;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB;AACzB,uBAAuB;AACvB,sBAAsB;AACtB,iBAAiB;AACjB,aAAa;AACb,WAAW;AACX,gBAAgB;AAChB,gBAAgB;AAChB,cAAc;AACd,oBAAoB;AACpB,gBAAgB;AAChB,mBAAmB;AACnB,iBAAiB;;;;;;;;;;;;AC/GJ;;AAEb,UAAU,mBAAO,CAAC,uDAAU;;AAE5B;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF;AACnF,qCAAqC;AACrC,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,KAAK;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD,kDAAkD;AAClD;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,qCAAqC,uBAAuB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,aAAa;;;;;;;;;;;;AC9rBA;;AAEb;AACA;AACA,kCAAkC,WAAW;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,yBAAyB;AACzB;AACA,qBAAqB;AACrB;AACA;AACA;;AAEA,mBAAmB;;;;;;;;;;;;ACxCN;;AAEb,UAAU,mBAAO,CAAC,uDAAU;AAC5B,YAAY,mBAAO,CAAC,2DAAY;;AAEhC;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,wBAAwB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,OAAO;AACxD,8BAA8B,qDAAqD;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA,yCAAyC,gCAAgC;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,qBAAqB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,yBAAyB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,gCAAgC;AACzE;AACA;AACA;AACA,4CAA4C,qBAAqB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,mBAAmB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,WAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,WAAW;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,yBAAyB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,2BAA2B;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,2BAA2B;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,mBAAmB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,OAAO;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,OAAO;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,2BAA2B;AACjE,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,oCAAoC;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,2CAA2C;AACzF,iCAAiC;AACjC;AACA;AACA;AACA,6CAA6C,+CAA+C;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,2CAA2C;AACrF,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,iBAAiB;AAC3D,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,oCAAoC;AACpF;AACA;AACA,6CAA6C,2CAA2C;AACxF;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,+CAA+C;AACzF,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,yBAAyB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,kBAAkB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,OAAO;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,2BAA2B;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,2BAA2B;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,2BAA2B;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,2BAA2B;AACnE;AACA;AACA;AACA;AACA;AACA,wCAAwC,+CAA+C;AACvF;AACA;AACA;AACA,4CAA4C,oCAAoC;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,2BAA2B;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,6BAA6B;AACrE;AACA;AACA;AACA,4CAA4C,kBAAkB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,qBAAqB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2BAA2B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,OAAO;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,2CAA2C;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,cAAc;;;;;;;;;;;;ACz7BD;;AAEb,eAAe,mBAAO,CAAC,2EAAuB;AAC9C,eAAe,mBAAO,CAAC,mEAAmB;AAC1C,aAAa,mBAAO,CAAC,uDAAa;AAClC,UAAU,mBAAO,CAAC,iDAAU;AAC5B,kBAAkB,mBAAO,CAAC,+EAAyB;AACnD,aAAa,mBAAO,CAAC,mEAAmB;;AAExC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C;AAC/C,YAAY,4BAA4B;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,aAAa;AAC5C;AACA;AACA,2CAA2C;AAC3C,YAAY,4BAA4B;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oIAAoI;AACpI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mBAAmB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,YAAY,IAAI;AAC1E;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA;;AAEA,aAAa;AACb,yBAAyB;AACzB,qBAAqB;AACrB,iBAAiB;;;;;;;;;;;;ACvGJ;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,UAAU,mBAAO,CAAC,sEAAiB;AACnC,UAAU,mBAAO,CAAC,sEAAiB;AACnC,aAAa,mBAAO,CAAC,4EAAoB;AACzC,WAAW,mBAAO,CAAC,0DAAW;;AAE9B;AACA;AACA,kBAAkB,uFAAuF;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,gBAAgB;AACpE,uDAAuD,sBAAsB;AAC7E,oDAAoD,gBAAgB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,cAAc;;;;;;;;;;;;ACvCD;;AAEb,eAAe,mBAAO,CAAC,2EAAyB;AAChD,cAAc,mBAAO,CAAC,yEAAwB;;AAE9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA,WAAW;;;;;;;;;;;;AClBE;;AAEb,aAAa,mBAAO,CAAC,uEAAuB;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,QAAQ;AAC1B;AACA;AACA;;AAEA,eAAe;;;;;;;;;;;;AChBF;;AAEb,eAAe,mBAAO,CAAC,2EAAyB;AAChD,cAAc,mBAAO,CAAC,yEAAwB;;AAE9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA,WAAW;;;;;;;;;;;;AClBE;;AAEb,sBAAsB,mBAAO,CAAC,iGAAoC;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oBAAoB;AAClD;AACA;AACA;;AAEA,cAAc;;;;;;;;;;;;ACfD;;AAEb,aAAa,mBAAO,CAAC,uEAAuB;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,eAAe;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe;;;;;;;;;;;;ACpBF;;AAEb,aAAa,mBAAO,CAAC,uEAAuB;AAC5C,sBAAsB,mBAAO,CAAC,iGAAoC;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA,aAAa;AACb,gBAAgB;AAChB,gBAAgB;;;;;;;;;;;;AC9CH;;AAEb,sBAAsB,mBAAO,CAAC,iGAAoC;;AAElE;AACA,0CAA0C,aAAa;AACvD;AACA,YAAY,QAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,WAAW;AACX,cAAc;AACd,cAAc;;;;;;;;;;;;ACzCD;;AAEb,UAAU,mBAAO,CAAC,uEAAkB;AACpC,YAAY,mBAAO,CAAC,yEAAmB;AACvC,UAAU,mBAAO,CAAC,uEAAkB;AACpC,aAAa,mBAAO,CAAC,6EAAqB;AAC1C,WAAW,mBAAO,CAAC,+DAAW;AAC9B,YAAY,mBAAO,CAAC,iEAAY;AAChC,UAAU,mBAAO,CAAC,6DAAU;;AAE5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,cAAc;;;;;;;;;;;;ACxBD;;AAEb,aAAa,mBAAO,CAAC,uEAAuB;AAC5C,UAAU,mBAAO,CAAC,uEAAkB;AACpC,UAAU,mBAAO,CAAC,uEAAkB;;AAEpC;AACA;AACA;AACA,yBAAyB,OAAO;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,mCAAmC,aAAa;AAChD,sBAAsB,OAAO;AAC7B,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,oBAAoB;AAC/D;AACA;AACA;AACA;;AAEA,cAAc;;;;;;;;;;;;AC/DD;;AAEb,UAAU,mBAAO,CAAC,sEAAiB;AACnC,YAAY,mBAAO,CAAC,wEAAkB;AACtC,UAAU,mBAAO,CAAC,sEAAiB;AACnC,aAAa,mBAAO,CAAC,4EAAoB;AACzC,WAAW,mBAAO,CAAC,oEAAgB;AACnC,YAAY,mBAAO,CAAC,sEAAiB;AACrC,UAAU,mBAAO,CAAC,kEAAe;AACjC,aAAa,mBAAO,CAAC,wEAAkB;AACvC,eAAe,mBAAO,CAAC,wEAAkB;AACzC,aAAa,mBAAO,CAAC,gFAAsB;AAC3C,WAAW,mBAAO,CAAC,4EAAoB;AACvC,YAAY,mBAAO,CAAC,8EAAqB;AACzC,eAAe,mBAAO,CAAC,gFAAsB;AAC7C,UAAU,mBAAO,CAAC,0EAAmB;AACrC,gBAAgB,mBAAO,CAAC,sFAAyB;;AAEjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,WAAW,GAAG,aAAa,MAAM;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,IAAI,GAAG,aAAa,KAAK;AACxE,KAAK;AACL;;AAEA,qBAAqB;AACrB,eAAe;;;;;;;;;;;;ACrFF;;AAEb,aAAa,mBAAO,CAAC,uEAAuB;AAC5C,sBAAsB,mBAAO,CAAC,iGAAoC;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,oBAAoB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,gBAAgB;AAC5C;AACA;AACA;AACA;AACA,4EAA4E;AAC5E;AACA;AACA,KAAK;AACL,gBAAgB,sBAAsB;AACtC,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,gBAAgB;AAC5C;AACA;AACA;AACA;AACA,oFAAoF;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,OAAO;AAC1C;AACA;AACA;AACA;AACA,iDAAiD,2BAA2B;AAC5E;AACA;;AAEA,cAAc;;;;;;;;;;;;ACnED;;AAEb,aAAa,mBAAO,CAAC,uEAAuB;;AAE5C,yBAAyB,eAAe;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gBAAgB;AAChB,eAAe;;;;;;;;;;;;AC5BF;;AAEb,aAAa,mBAAO,CAAC,uEAAuB;AAC5C,sBAAsB,mBAAO,CAAC,iGAAoC;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA,aAAa;AACb,gBAAgB;AAChB,gBAAgB;;;;;;;;;;;;ACjDH;;AAEb,sBAAsB,mBAAO,CAAC,iGAAoC;;AAElE;AACA,0CAA0C,aAAa;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,IAAI;AAC/B;AACA;AACA,2BAA2B,IAAI;AAC/B;AACA;AACA,2BAA2B,IAAI;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,QAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,WAAW;AACX,cAAc;AACd,cAAc;AACd,cAAc;;;;;;;;;;;;AC3ED;;AAEb,eAAe,mBAAO,CAAC,2EAAyB;AAChD,WAAW,mBAAO,CAAC,mEAAqB;AACxC,cAAc,mBAAO,CAAC,yEAAwB;AAC9C,cAAc,mBAAO,CAAC,yEAAwB;AAC9C,YAAY,mBAAO,CAAC,qEAAY;;AAEhC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,MAAM;AAC3B;AACA;AACA,6EAA6E,UAAU;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA,gBAAgB;AAChB,YAAY;;;;;;;;;;;;AC5EC;;AAEb,eAAe,mBAAO,CAAC,2EAAyB;AAChD,WAAW,mBAAO,CAAC,mEAAqB;AACxC,aAAa,mBAAO,CAAC,uEAAuB;AAC5C,cAAc,mBAAO,CAAC,yEAAwB;;AAE9C;AACA;AACA,wBAAwB,sBAAsB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mBAAmB,IAAI,uBAAuB;AAC3E;AACA;AACA;AACA;AACA,6BAA6B,aAAa,IAAI,WAAW;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,WAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,GAAG;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,aAAa;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mBAAmB;AACnB,aAAa;AACb,oBAAoB;;;;;;;;;;;;ACjFP;;AAEb,UAAU,mBAAO,CAAC,uEAAkB;AACpC,YAAY,mBAAO,CAAC,yEAAmB;AACvC,UAAU,mBAAO,CAAC,uEAAkB;AACpC,aAAa,mBAAO,CAAC,6EAAqB;AAC1C,aAAa,mBAAO,CAAC,uEAAa;AAClC,WAAW,mBAAO,CAAC,mEAAW;AAC9B,YAAY,mBAAO,CAAC,qEAAY;AAChC,UAAU,mBAAO,CAAC,iEAAU;AAC5B,WAAW,mBAAO,CAAC,mEAAW;AAC9B,YAAY,mBAAO,CAAC,qEAAY;AAChC,UAAU,mBAAO,CAAC,iEAAU;AAC5B,gBAAgB,mBAAO,CAAC,6EAAgB;;AAExC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,cAAc;;;;;;;;;;;;ACtCD;;AAEb,eAAe,mBAAO,CAAC,2EAAyB;AAChD,WAAW,mBAAO,CAAC,mEAAqB;AACxC,cAAc,mBAAO,CAAC,yEAAwB;;AAE9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6FAA6F,aAAa;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,SAAS,qBAAqB;AAChF;AACA;AACA;AACA;AACA,gBAAgB,WAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe;AACf,WAAW;;;;;;;;;;;;AC/FE;;AAEb,sBAAsB,mBAAO,CAAC,iGAAoC;;AAElE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,QAAQ;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,aAAa;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,EAAE,SAAS,IAAI,SAAS,IAAI;AACtD;AACA;AACA,gBAAgB,IAAI,SAAS,IAAI,SAAS,IAAI;AAC9C,+CAA+C,EAAE;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,kBAAkB,OAAO;AACzB;;AAEA,iBAAiB;AACjB,eAAe;AACf,iBAAiB;;;;;;;;;;;;ACxGJ;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,0EAA0E,IAAI;AACpI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,sBAAsB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;AACA,uBAAuB,OAAO,EAAE,mBAAmB;AACnD;AACA;AACA,0BAA0B,WAAW;AACrC,wBAAwB,OAAO,EAAE,0BAA0B;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;;AAEA,kBAAkB;AAClB,iBAAiB;AACjB,mBAAmB;AACnB,qBAAqB;;;;;;;;;;;;AC3IR;;AAEb,cAAc,mBAAO,CAAC,kEAAmB;AACzC,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,uBAAuB,mBAAO,CAAC,qFAAuB;AACtD,sBAAsB,mBAAO,CAAC,mFAAsB;;AAEpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,MAAM;AACtD;AACA;AACA;AACA;AACA,wCAAwC,yBAAyB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,OAAO;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,6BAA6B;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD,aAAa,OAAO,EAAE,IAAI;AAC1B,aAAa,MAAM,IAAI,WAAW,EAAE,IAAI;AACxC;;AAEA,8BAA8B;AAC9B,iBAAiB;;;;;;;;;;;;AC9HJ;;AAEb,iBAAiB,mBAAO,CAAC,4EAAwB;AACjD,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,gBAAgB,mBAAO,CAAC,uEAAgB;AACxC,uBAAuB,mBAAO,CAAC,qFAAuB;;AAEtD;AACA;AACA;AACA;AACA;AACA,oCAAoC,gBAAgB,SAAS,gEAAgE;AAC7H,YAAY,mBAAmB,kBAAkB;AACjD,oCAAoC,SAAS,gCAAgC;AAC7E,2BAA2B;AAC3B;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,kBAAkB;AAC1C;AACA,+BAA+B,OAAO,EAAE,KAAK;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,gBAAgB,SAAS,kCAAkC;AAC9F,YAAY,iEAAiE,kBAAkB;AAC/F;AACA,oCAAoC;AACpC;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,aAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,WAAW,EAAE,OAAO,EAAE,KAAK;AAC9D,wBAAwB,OAAO,EAAE,IAAI;AACrC;AACA;AACA,qBAAqB,MAAM,EAAE,UAAU,EAAE,gBAAgB,EAAE,UAAU,EAAE,IAAI;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,mBAAmB,iBAAiB;AAChE;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;;AAEA,2BAA2B;;;;;;;;;;;;ACxJd;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB;AACrB,mBAAmB;AACnB,wBAAwB;;;;;;;;;;;;ACvBX;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,gBAAgB,mBAAO,CAAC,uEAAgB;AACxC,uBAAuB,mBAAO,CAAC,qFAAuB;;AAEtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gBAAgB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,KAAK;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,GAAG;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,yBAAyB;;;;;;;;;;;;ACtFZ;;AAEb,2BAA2B,uCAAuC;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB;;;;;;;;;;;;ACzBV;;AAEb,eAAe,mBAAO,CAAC,wEAAsB;AAC7C,aAAa,mBAAO,CAAC,oEAAoB;AACzC,gBAAgB,mBAAO,CAAC,uEAAgB;AACxC,uBAAuB,mBAAO,CAAC,qFAAuB;;AAEtD,yBAAyB,YAAY;AACrC,YAAY,mDAAmD,yCAAyC;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,IAAI;AAC7D;AACA;AACA;AACA,mBAAmB,IAAI;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,IAAI,IAAI,OAAO;AAClC;AACA;AACA,iBAAiB,IAAI;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,+CAA+C;AACtE;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,WAAW;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,WAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB;;;;;;;;;;;;ACvJR;;AAEb,aAAa,mBAAO,CAAC,oEAAoB;AACzC,oBAAoB,mBAAO,CAAC,+EAAoB;;AAEhD;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,YAAY;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,cAAc;AAC1B;AACA;AACA;AACA;AACA,kCAAkC,IAAI;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,OAAO;AAC9E;AACA;AACA;AACA;AACA;AACA,YAAY,cAAc;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C,YAAY,uCAAuC;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,cAAc;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA,iDAAiD,OAAO;AACxD;AACA;AACA;AACA;AACA;AACA,uBAAuB,yBAAyB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,OAAO;AAClD;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,OAAO;AAClD,kBAAkB,OAAO,IAAI,OAAO,EAAE,MAAM,EAAE,MAAM,EAAE,IAAI;AAC1D;AACA;AACA;AACA;AACA;AACA,8BAA8B,OAAO;AACrC,gDAAgD,MAAM,EAAE,MAAM,EAAE,IAAI;AACpE,cAAc,OAAO,IAAI,OAAO,EAAE,KAAK;AACvC;AACA;AACA,YAAY,cAAc;AAC1B,YAAY,wDAAwD;AACpE;AACA,0BAA0B;AAC1B;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,OAAO;AACpD;AACA;AACA;AACA;AACA;AACA,gBAAgB,eAAe;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sBAAsB;AAClC;AACA;AACA,0BAA0B,UAAU,2BAA2B;AAC/D,UAAU,OAAO;AACjB;AACA;AACA,4CAA4C,KAAK,IAAI,KAAK;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oCAAoC;AACpD;AACA;AACA;AACA,+DAA+D,EAAE;AACjE;AACA;AACA;;AAEA,uBAAuB;;;;;;;;;;;;ACzUV;;AAEb,eAAe,mBAAO,CAAC,uEAAqB;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uBAAuB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uBAAuB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,IAAI;AACxD;AACA;;AAEA,aAAa;AACb,kBAAkB;;;;;;;;;;;;;;;;;;;;;;;;;AC3OX;AACP;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACtFiD;AACT;AACK;AACF;AACT;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,sBAAsB,yCAAK;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B;AACA;AACA,iBAAiB,6CAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,2CAAM;AACxB;AACA,mBAAmB,iDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA,yCAAyC,sDAAkB;AAC3D;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8DAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC3HgD;AACF;AACvC;AACP,sBAAsB,sDAAI;AAC1B;AACO,oCAAoC,wDAAU;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,iDAAiD;AAClF;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AChCiD;AAC1C;AACP;AACA;AACA,oBAAoB,iDAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wDAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC1BwC;AACjC;AACP;AACA;AACA,oBAAoB,iDAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACpBiD;AAC1C;AACP;AACA;AACA;AACA;AACA,oBAAoB,iDAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wDAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,sDAAsD;AAChF;AACA;AACA;AACA;AACO;AACP,sBAAsB,iDAAI;AAC1B;AACA;;;;;;;;;;;;;;;;AC/CO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oBAAoB;AACd;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3BgC;AACQ;AACE;AACF;AACV;AACQ;AACA;AACF;AACE;AACtC;;;;;;;;;;;;;;;;ACTwC;AACjC;AACP;AACA,oBAAoB,iDAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACbwC;AACjC;AACP;AACA;AACA,oBAAoB,iDAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACnBgC;AACQ;AACE;AACZ;AACQ;AACA;AACtC;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB,uCAAI;AAC7B;AACA;AACA,yBAAyB,iDAAW;AACpC;AACA;AACA,yBAAyB,+CAAU;AACnC;AACA;AACA,yBAAyB,+CAAU;AACnC;AACA;AACA,yBAAyB,yCAAK;AAC9B;AACA;AACA,yBAAyB,mDAAU;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACrC0C;AACF;AACE;AACZ;AACQ;AACA;AACtC;AACA;AACA;AACA;AACA;AACO;AACP;AACA,mBAAmB,uCAAI;AACvB;AACA;AACA,mBAAmB,+CAAU;AAC7B;AACA;AACA,mBAAmB,+CAAU;AAC7B;AACA;AACA,mBAAmB,iDAAW;AAC9B;AACA;AACA,mBAAmB,yCAAM;AACzB;AACA;AACA,mBAAmB,mDAAU;AAC7B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACpCwC;AACjC;AACP;AACA;AACA,oBAAoB,iDAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACdsC;AAC/B;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA,iBAAiB,sBAAsB,KAAK,mDAAW,MAAM;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,iBAAiB;AACrE;AACA,qDAAqD,sBAAsB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;;;;;;;;;;;;;;;;;;;;;;ACjD6B;AACE;AACkB;AACJ;AACL;AACJ;AACoC;AACjE;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6CAAS;AAC7C,uBAAuB,8CAAgB,CAAC,8CAAK;AAC7C;AACA,mDAAmD,sBAAsB;AACzE;AACA;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B,2BAA2B,8CAAgB,CAAC,+CAAM;AAClD,iBAAiB,6CAAS;AAC1B,2BAA2B,8CAAgB,EAAE,+CAAM;AACnD,iBAAiB,6CAAS;AAC1B,2BAA2B,8CAAgB,CAAC,oDAAW;AACvD,iBAAiB,6CAAS;AAC1B,2BAA2B,8CAAgB,CAAC,+CAAM,iBAAiB,oDAAW;AAC9E,iBAAiB,6CAAS;AAC1B,2BAA2B,8CAAgB,CAAC,iDAAQ;AACpD,iBAAiB,6CAAS;AAC1B,2BAA2B,8CAAgB,CAAC,+CAAM,iBAAiB,iDAAQ;AAC3E;AACA,oDAAoD,uBAAuB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,6CAAS,QAAQ,8CAAK;AACjE,2CAA2C,6CAAS,OAAO,+CAAM;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,sCAAI;AACpC,sBAAsB,iDAAS;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,UAAU,KAAK,UAAU;AACvG;AACA,sBAAsB,iDAAS;AAC/B;AACA;AACA;AACA;AACA,iBAAiB,uCAAS;AAC1B;AACA,0CAA0C,0DAAa;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,uCAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,0DAAa;AAC9C;AACA;AACA,iCAAiC,uCAAS;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,sDAAkB;AACzE;AACA;AACA;AACA;AACA,uBAAuB,0DAAa;AACpC;AACA;AACA;AACA,iBAAiB,uCAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,uCAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,0DAAa;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uCAAS;AACxB;AACA;AACA;AACA,uBAAuB,0DAAa;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uCAAS;AACxB;AACA;;;;;;;;;;;;;;;;AC9L+B;AACxB,4BAA4B,wCAAU;AAC7C;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACHsD;AACV;AACA;AACJ;AACI;AACR;AACY;AACR;AACjC;AACP,cAAc,qDAAQ;AACtB,cAAc,qDAAQ;AACtB,YAAY,iDAAM;AAClB,cAAc,qDAAQ;AACtB,UAAU,6CAAI;AACd,gBAAgB,yDAAU;AAC1B,YAAY,iDAAM;AAClB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,oDAAe,CAAC,8CAAS;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,oDAAe,CAAC,8CAAS;AAC3C;AACA;AACA,kBAAkB,oDAAe,CAAC,8CAAS;AAC3C;AACA;AACA;;;;;;;;;;;;;;;;;AC1C4C;AACT;AAC5B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,8CAAW;AACtC;AACA;AACA,+BAA+B,uCAAI;AACnC;AACA;AACA,2BAA2B,8CAAW;AACtC;AACA;AACA,oBAAoB,+CAAM;AAC1B,+BAA+B,8CAAW;AAC1C;AACA;AACA;AACA,mBAAmB,8CAAW;AAC9B;AACA;AACA;;;;;;;;;;;;;;;;;AC/BsC;AACK;AACpC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8CAAW;AAClC;AACA;AACA;AACA,uBAAuB,8CAAW;AAClC;AACA,mBAAmB,uDAAc;AACjC,mBAAmB,uDAAc;AACjC,mBAAmB,8CAAW;AAC9B;AACA;AACA;;;;;;;;;;;;;;;;ACrBqC;AAC9B;AACP;AACA,iNAAiN,EAAE;AACnN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC;AACxC,wCAAwC;AACxC;AACA;AACA;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yHAAyH,GAAG;AAC5H;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,yCAAyC;AAChF;AACA;AACA;AACA;AACA,2EAA2E,GAAG;AAC9E;AACA;AACA;AACA;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA,+EAA+E,GAAG;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,6CAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC9F0C;AACY;AAC/C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,kDAAO;AACzC;AACA;AACA,sBAAsB,8DAAyB,kDAAkD,UAAU;AAC3G;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrB2C;AACpC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6CAAU;AACjC;AACA;AACA,6BAA6B,uCAAI;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6CAAU;AACjC;AACA;AACA;AACA;AACA,mBAAmB,6CAAU;AAC7B;AACA;AACA;;;;;;;;;;;;;;;;;AC3BsC;AACK;AACpC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8CAAW;AAClC;AACA;AACA;AACA,uBAAuB,8CAAW;AAClC;AACA,mBAAmB,uDAAc;AACjC,mBAAmB,uDAAc;AACjC,mBAAmB,8CAAW;AAC9B;AACA;AACA;;;;;;;;;;;;;;;;;ACrBqC;AACO;AACrC;AACP;AACA;AACA;AACA;AACA;AACA,mBAAmB,6CAAU,yBAAyB,oDAAQ;AAC9D;AACA;AACA;;;;;;;;;;;;;;;ACXO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClB6B;AACW;AAC4D;AACrE;AACuC;AAC9B;AACK;AACb;AACE;AAClC;;;;;;;;;;;;;;;;;;;ACToC;AACa;AAC1C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,0DAAqB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAU;AACpC;AACA,mDAAmD,OAAO,yBAAyB,gBAAgB,qBAAqB,WAAW;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,iCAAiC,yBAAyB,gBAAgB,qBAAqB,WAAW;AAC7J;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,OAAO,yBAAyB,gBAAgB,qBAAqB,WAAW;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACnUkH;AACnF;AACyC;AAC7B;AACP;AAC7B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,aAAa;AAClC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,8CAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6CAAS;AAChC;AACA;AACA;AACA,oCAAoC,yCAAO;AAC3C;AACA,kCAAkC,6CAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6CAAS;AAChC;AACA;AACA;AACA,oCAAoC,yCAAO;AAC3C;AACA,kCAAkC,6CAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS,aAAa,6CAAS;AACzD;AACA;AACA,uBAAuB,wCAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS,UAAU,6CAAS,gBAAgB,6CAAS,OAAO,6CAAS;AAC/F;AACA;AACA,uBAAuB,wCAAM;AAC7B;AACA;AACA;AACA;AACA,uBAAuB,6CAAS;AAChC;AACA;AACA;AACA;AACA;AACA,2BAA2B,uCAAK;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,0CAAQ,oBAAoB,8CAAY,oBAAoB,+CAAa;AACrG;AACA;AACA;AACA,oCAAoC,6CAAS;AAC7C;AACA,uCAAuC,6CAAS;AAChD,4CAA4C,sCAAI;AAChD;AACA;AACA;AACA;AACA,qCAAqC,6CAAS,gBAAgB,8CAAS;AACvE;AACA;AACA;AACA,mCAAmC,6CAAW;AAC9C;AACA;AACA,oCAAoC,6CAAS;AAC7C;AACA;AACA;AACA,uCAAuC,6CAAS;AAChD;AACA,uCAAuC,6CAAW,WAAW,yCAAO,KAAK,6CAAe;AACxF;AACA,4CAA4C,6CAAS;AACrD,uCAAuC,6CAAW,WAAW,sCAAI;AACjE;AACA;AACA,kDAAkD,8CAAS;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA,wBAAwB,6CAAS;AACjC;AACA;AACA;AACA,wBAAwB,6CAAS;AACjC;AACA,sCAAsC,8CAAS;AAC/C;AACA,uBAAuB,+CAAa;AACpC;AACA;AACA;AACA;AACA,2BAA2B,6CAAS;AACpC;AACA;AACA,4BAA4B,6CAAS;AACrC,6BAA6B,6CAAS,QAAQ,8CAAS;AACvD;AACA;AACA,QAAQ,wDAAgB;AACxB,mBAAmB,8CAAY;AAC/B;AACA;AACA;AACA,4BAA4B,6CAAS;AACrC,2BAA2B,yCAAO,KAAK,8CAAgB;AACvD,4BAA4B,6CAAS;AACrC,2BAA2B,yCAAO,KAAK,8CAAgB;AACvD,4BAA4B,6CAAS;AACrC,2BAA2B,yCAAO,KAAK,uCAAS;AAChD,4BAA4B,6CAAS;AACrC,2BAA2B,yCAAO,KAAK,6CAAe;AACtD,4BAA4B,6CAAS;AACrC,2BAA2B,yCAAO,KAAK,6CAAe;AACtD,4BAA4B,6CAAS;AACrC;AACA;AACA,0CAA0C,8CAAS,mDAAmD;AACtG;AACA,6BAA6B,6CAAS,cAAc,8CAAS;AAC7D,2BAA2B,0CAAQ;AACnC;AACA;AACA,sCAAsC,8CAAS,mDAAmD;AAClG;AACA,8BAA8B,8CAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,6CAAS;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,qDAAgB;AACzC,kCAAkC,8CAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oDAAe;AAClC;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC3R+B;AACxB;AACP;AACA,aAAa,uCAAS;AACtB;AACA,aAAa,uCAAS;AACtB;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB,4BAA4B,uCAAS;AACrC,yBAAyB,6CAAe;AACxC;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB,4BAA4B,uCAAS;AACrC,yBAAyB,6CAAe;AACxC;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB,aAAa,uCAAS;AACtB,qBAAqB,6CAAe;AACpC;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB,aAAa,uCAAS;AACtB,qBAAqB,6CAAe;AACpC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,uCAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7L0D;AACX;AACmB;AACN;AAC5D;;;;;;;;;;;;;;;;;;;;;;;;;ACJwE;AACP;AACJ;AACA;AACd;AACuB;AACvB;AAC4B;AACrB;AAC/C;AACP;AACA;AACA;AACA,CAAC,kCAAkC;AACnC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mFAAyB,kBAAkB,QAAQ,4DAAS;AAChG;AACA;AACA,kCAAkC,mFAAyB,0BAA0B,4DAAW;AAChG;AACA;AACA,oBAAoB,mFAAyB,kBAAkB,QAAQ,0EAAkB;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mEAAqB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,6EAAkB;AACrF,qCAAqC,yEAAa;AAClD;AACA;AACA;AACA,oBAAoB,wFAAyB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gFAAkB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACxG8D;AACvD;AACP;AACA;AACA;AACA;AACA,QAAQ,uEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,mBAAmB;AACzF;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC7BuD;AACO;AACvD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,4DAAa;AACzC;AACA;AACA;AACA;AACA,QAAQ,uEAAQ;AAChB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yEAAyE,UAAU;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,UAAU;AAChE;AACA;AACA,aAAa;AACb;AACA;;;;;;;;;;;;;;;;;;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB;AACvB,qBAAqB;AACrB,oBAAoB;AACpB,sBAAsB;AACtB,oBAAoB;AAC3B;;;;;;;;;;;;;;;;;;AC7BkC;AAC6D;AACxF;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yDAAY;AAClD,gCAAgC,uDAAU;AAC1C,8BAA8B,sDAAS;AACvC,iCAAiC,wDAAW;AAC5C,8BAA8B,sDAAS;AACvC;AACO;AACP;AACA;AACA;AACA;AACA;AACA,eAAe,+CAAkB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC3FgG;AACvC;AACpB;AACa;AACS;AACc;AAClE;AACP,QAAQ,wEAAS;AACjB;AACA;AACA;AACA;AACA;AACA,QAAQ,yEAAU;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,wEAAS;AACjB;AACA;AACA;AACA;AACA,iDAAiD,8DAAS;AAC1D;AACA;AACA;AACA;AACA;AACA,yEAAyE,UAAU;AACnF;AACA;AACA;AACA;AACA;AACA,iEAAiE,UAAU;AAC3E;AACA,uCAAuC,wEAAwB;AAC/D;AACA;AACA;AACA,2CAA2C,sFAAkC;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,MAAM;AACnD;AACA;AACA,oBAAoB,uEAAQ;AAC5B;AACA;AACA;AACA,mCAAmC,+DAAiB,oCAAoC,MAAM;AAC9F;AACA;AACA,oBAAoB,KAAK;AACzB,oBAAoB,uEAAQ;AAC5B,8BAA8B,KAAK;AACnC;AACA;AACA,8BAA8B,KAAK,YAAY,+DAAiB,IAAI,KAAK,uCAAuC,KAAK;AACrH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,MAAM;AACnD;AACA;AACA,oBAAoB,uEAAQ;AAC5B;AACA;AACA;AACA,mCAAmC,+DAAiB,oCAAoC,MAAM;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,kDAAW;AAChC;AACA;AACA,8BAA8B,kBAAkB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC/H2E;AACpE;AACP;AACA;AACA;AACA;AACA;AACA,2BAA2B,gFAAkB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,wBAAwB;AACtD;AACA;AACA;AACA;AACA,6BAA6B,QAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,MAAM,0IAA0I,YAAY;AAClM;AACA;AACA,sCAAsC,MAAM;AAC5C;AACA;AACA,sCAAsC,MAAM;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AChH8D;AACY;AACvB;AACuB;AACd;AACnB;AAC0B;AACrB;AACP;AAChC;AACP,sBAAsB,kDAAS;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yEAAyB,uCAAuC,gEAAkB;AAClG;AACA;AACA;AACA,gBAAgB,iEAAqB;AACrC;AACA;AACA;AACA,gBAAgB,yEAAyB;AACzC;AACA,iBAAiB;AACjB;AACA;AACA,gBAAgB,yEAAyB,uCAAuC,gFAA8B;AAC9G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uEAAQ;AAC5B;AACA;AACA;AACA,oBAAoB,yEAAU;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yEAAyB;AACzC;AACA,iBAAiB;AACjB;AACA;AACA,gBAAgB,yEAAyB,uCAAuC,2DAAa;AAC7F;AACA;AACA;AACA,gBAAgB,gEAAoB;AACpC;AACA;AACA;AACA,wBAAwB,oDAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yEAAyB;AACzC;AACA,iBAAiB;AACjB;AACA;AACA,oBAAoB,uEAAQ;AAC5B;AACA;AACA;AACA,oBAAoB,yEAAyB;AAC7C;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mEAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mEAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,uEAAQ;AAChB;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC/IiE;AAC1D;AACP;AACA;AACA;AACA;AACA,QAAQ,uEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC3BO;AACP;AACA;AACA;AACA;AACA,0EAA0E,KAAK,aAAa,MAAM;AAClG;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF,MAAM;AACzF;AACA,gDAAgD,MAAM;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,MAAM;AAC7D;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,8CAA8C,aAAa;AAC3D;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrCwF;AACjF;AACP;AACA,SAAS,wEAAS;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF,UAAU;AAC/F;AACA;AACA;AACA,qFAAqF,UAAU;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA,iFAAiF,UAAU;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,uEAAQ;AAChB;AACA;AACA;AACA,QAAQ,yEAAU;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC7EsD;AACZ;AACnC;AACP;AACA;AACA;AACA;AACA,8BAA8B,uDAAc;AAC5C,yBAAyB,uDAAc;AACvC;AACA;AACA,iCAAiC,wDAAS;AAC1C;AACA;AACA,+BAA+B,uDAAc,+BAA+B,KAAK,cAAc,MAAM;AACrG,sFAAsF,MAAM;AAC5F;AACA;AACA,qDAAqD,MAAM;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,MAAM;AAC9D;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC/B+D;AACH;AACzB;AAC5B;AACP,QAAQ,wEAAS;AACjB;AACA;AACA;AACA;AACA;AACA,2DAA2D,aAAa;AACxE,wBAAwB,yEAAyB,kCAAkC,gDAAU;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,QAAQ;AACrE;AACA,0DAA0D,QAAQ;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,oBAAoB,oBAAoB,WAAW;AACnG;AACA;AACA,gDAAgD,oBAAoB,4BAA4B,WAAW;AAC3G;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACzEyD;AACG;AACJ;AACE;AACrB;AAC9B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,yEAAyB;AACzC;AACA;AACA;AACA,2BAA2B,yEAAyB,oCAAoC,kDAAW;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAS;AACtB;AACA;AACA,gBAAgB,yEAAyB,2CAA2C,qEAAwB;AAC5G,gBAAgB,yEAAyB,2CAA2C,uEAAyB;AAC7G;AACA;AACA;AACA;AACA,aAAa,8DAAS;AACtB;AACA;AACA,qFAAqF,WAAW;AAChG;AACA,oBAAoB,yEAAyB,2CAA2C,qEAAwB;AAChH,oBAAoB,yEAAyB,2CAA2C,uEAAyB;AACjH;AACA;AACA;AACA;AACA;AACA,aAAa,8DAAS;AACtB;AACA;AACA,mFAAmF,SAAS;AAC5F;AACA;AACA;AACA,qDAAqD,8DAAS;AAC9D,oBAAoB,yEAAyB,2CAA2C,qEAAwB;AAChH,oBAAoB,yEAAyB,2CAA2C,uEAAyB;AACjH;AACA;AACA,4FAA4F,SAAS;AACrG;AACA,0FAA0F,eAAe;AACzG;AACA;AACA,0GAA0G,eAAe;AACzH;AACA;AACA,6FAA6F,eAAe;AAC5G;AACA;AACA,2GAA2G,eAAe;AAC1H;AACA;AACA;AACA,gBAAgB,yEAAyB,2CAA2C,qEAAwB;AAC5G,gBAAgB,yEAAyB,2CAA2C,uEAAyB;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACpF8D;AACE;AAClB;AACc;AACnB;AAClC;AACP,SAAS,yEAAU;AACnB;AACA;AACA;AACA,0BAA0B,kDAAS;AACnC;AACA;AACA,qBAAqB,yEAAyB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0DAAY;AACxB;AACA;AACA;AACA;AACA;AACA,qCAAqC,GAAG;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,mEAAoB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,gBAAgB,GAAG,gBAAgB;AACrD;AACA;AACA;AACA;;;;;;;;;;;;;;;ACrHO;AACP;AACA;AACA,yCAAyC,MAAM;AAC/C;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACP+D;AACd;AACC;AAC3C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,cAAc,yDAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,yDAAS;AACvC;AACA;AACA,iCAAiC,+DAAiB;AAClD;AACA;AACA,wDAAwD,UAAU;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,yDAAS;AAC9B;AACA;AACA,qBAAqB,yDAAS;AAC9B,qBAAqB,yDAAS;AAC9B,qBAAqB,yDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yDAAS;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,wEAAS;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACjHiD;AACC;AAC3C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,cAAc,yDAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,yDAAS;AACvC;AACA;AACA,iCAAiC,+DAAiB;AAClD;AACA;AACA,wDAAwD,UAAU;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,yDAAS;AAC9B;AACA;AACA,qBAAqB,yDAAS;AAC9B,qBAAqB,yDAAS;AAC9B,qBAAqB,yDAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,yDAAS;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACjFO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;ACZO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;;;;;;;;;;;;;;;;ACPoD;AAC7C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,6DAAY;AACvE;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC7BsD;AACoD;AACnG;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,mDAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAU,CAAC,mDAAS;AAC1C;AACA;AACA;AACA,0BAA0B,oDAAU,CAAC,mDAAS,cAAc,8CAAS;AACrE;AACA;AACA,0BAA0B,oDAAU,CAAC,mDAAS,cAAc,iDAAY;AACxE;AACA;AACA,0BAA0B,oDAAU,CAAC,mDAAS,cAAc,gDAAW;AACvE;AACA;AACA,0BAA0B,oDAAU,CAAC,mDAAS,cAAc,gDAAW;AACvE;AACA;AACA;AACA;AACA,8BAA8B,oDAAU,CAAC,mDAAS,cAAc,8CAAS;AACzE;AACA;AACA;AACA,8BAA8B,oDAAU,CAAC,mDAAS,oBAAoB,kDAAa;AACnF;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAU,CAAC,mDAAS;AAClD;AACA;AACA;AACA,8BAA8B,oDAAU,CAAC,mDAAS,mBAAmB,iDAAY;AACjF;AACA,kCAAkC,oDAAU,CAAC,mDAAS,cAAc,gDAAW;AAC/E;AACA;AACA;AACA;AACA,8BAA8B,oDAAU,CAAC,mDAAS;AAClD;AACA;AACA;AACA,0DAA0D,aAAa;AACvE;AACA;AACA,sBAAsB,oDAAU,CAAC,mDAAS;AAC1C;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACtIO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AAC/B;;;;;;;;;;;;;;;;;;;AChB4D;AAChB;AACO;AACI;AAChD,gCAAgC,gEAAgB;AACvD;AACA;AACA;AACA;AACA,yEAAyE,2DAAU,EAAE;AACrF;AACA,yBAAyB,wDAAO;AAChC,8EAA8E,2DAAU,EAAE,EAAE,wDAAO,CAAC;AACpG;AACA,+EAA+E,2DAAU,EAAE,EAAE,wDAAO,EAAE;AACtG;AACA;AACA;AACA,wEAAwE,2DAAU,EAAE,EAAE,wDAAO,EAAE;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2DAAU,EAAE,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAc;AAC7B;AACA;AACA,6CAA6C,oDAAS;AACtD;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACxCO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACvCO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,wCAAwC;AACzC;;;;;;;;;;;;;;;;ACXyE;AACzE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,qBAAqB;AACjD,4EAA4E,2DAAU,EAAE;AACxF;AACA,yBAAyB,wDAAO;AAChC,kFAAkF,2DAAU,EAAE,EAAE,wDAAO,CAAC;AACxG;AACA;AACA;AACA;AACA,iEAAiE,wDAAO,EAAE;AAC1E;AACA;AACA,2EAA2E,QAAQ;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,gBAAgB;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,4DAAW;AACpC;AACA,8DAA8D,4DAAW;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC7DmD;AACnD;;;;;;;;;;;;;;;;;;;ACD0G;AAChE;AACS;AACQ;AACpD,gCAAgC,mDAAU;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yEAAyE,2DAAU,EAAE;AACrF;AACA,yBAAyB,wDAAO;AAChC,8EAA8E,2DAAU,EAAE,EAAE,wDAAO,CAAC;AACpG;AACA,+EAA+E,2DAAU,EAAE,EAAE,wDAAO,EAAE;AACtG;AACA,qCAAqC,2DAAU;AAC/C,0FAA0F,2DAAU,EAAE,EAAE,wDAAO,EAAE,EAAE,2DAAU,CAAC;AAC9H;AACA,gGAAgG,2DAAU,EAAE,EAAE,wDAAO,EAAE,EAAE,2DAAU,EAAE;AACrI,kFAAkF,oEAAkB;AACpG;AACA;AACA;AACA,qCAAqC,+DAAc;AACnD,2FAA2F,2DAAU,EAAE,EAAE,wDAAO,EAAE,EAAE,+DAAc,CAAC;AACnI;AACA;AACA;AACA,qCAAqC,iEAAgB;AACrD,6FAA6F,2DAAU,EAAE,EAAE,wDAAO,EAAE,EAAE,iEAAgB,CAAC;AACvI;AACA;AACA;AACA;AACA;AACA,wEAAwE,2DAAU,EAAE,EAAE,wDAAO,EAAE;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2DAAU,EAAE,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,+DAAc,CAAC,oBAAoB,iEAAgB,CAAC,uBAAuB,KAAK;AAC7H;AACA;AACA;AACA;AACA,yCAAyC,iEAAgB,CAAC,oBAAoB,+DAAc,CAAC,uBAAuB,KAAK;AACzH;AACA;AACA;AACA;AACA;AACA,wEAAwE,aAAa,QAAQ,KAAK;AAClG;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AChFyD;AACN;AACI;AACX;AACrC,6BAA6B,gEAAgB;AACpD;AACA;AACA;AACA;AACA,yEAAyE,2DAAU,EAAE;AACrF;AACA,yBAAyB,qDAAI;AAC7B,8EAA8E,2DAAU,EAAE,EAAE,qDAAI,CAAC;AACjG;AACA,+EAA+E,2DAAU,EAAE,EAAE,qDAAI,EAAE;AACnG;AACA;AACA;AACA,wEAAwE,2DAAU,EAAE,EAAE,qDAAI,EAAE;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2DAAU,EAAE,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAc;AAC7B;AACA;AACA,6CAA6C,oDAAS;AACtD;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACxC2D;AACR;AACI;AACX;AACrC,+BAA+B,gEAAgB;AACtD;AACA;AACA;AACA;AACA,yEAAyE,2DAAU,EAAE;AACrF;AACA,yBAAyB,uDAAM;AAC/B,8EAA8E,2DAAU,EAAE,EAAE,uDAAM,CAAC;AACnG;AACA,+EAA+E,2DAAU,EAAE,EAAE,uDAAM,EAAE;AACrG;AACA;AACA;AACA,wEAAwE,2DAAU,EAAE,EAAE,uDAAM,EAAE;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2DAAU,EAAE,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAc;AAC7B;AACA;AACA,6CAA6C,oDAAS;AACtD;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACxC8I;AACpG;AACS;AACnD;AACA;AACA;AACO,8BAA8B,mDAAU;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,yEAAyE,2DAAU,EAAE;AACrF;AACA,yBAAyB,uDAAM;AAC/B,6EAA6E,2DAAU,EAAE,EAAE,uDAAM,CAAC;AAClG;AACA,mEAAmE,2DAAU,EAAE,EAAE,uDAAM,EAAE;AACzF;AACA;AACA;AACA;AACA,yBAAyB,+DAAc;AACvC,6EAA6E,2DAAU,EAAE,EAAE,+DAAc,CAAC;AAC1G;AACA,mEAAmE,2DAAU,EAAE,EAAE,uDAAM,EAAE;AACzF;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2DAAU,EAAE;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAc;AAC7B;AACA;AACA;AACA,gCAAgC,KAAK;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,KAAK,oCAAoC,WAAW;AACxF;AACA;AACA;AACA;AACA,oCAAoC,KAAK;AACzC;AACA;AACA,qBAAqB,4DAAc;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,4DAAc;AACnC;AACA;AACA,4CAA4C,KAAK,gDAAgD,yDAAQ,CAAC;AAC1G;AACA;AACA;AACA;AACA,qBAAqB,4DAAc;AACnC;AACA;AACA,4CAA4C,KAAK,gDAAgD,qDAAI,CAAC;AACtG;AACA;AACA;AACA;AACA,qBAAqB,4DAAc;AACnC;AACA;AACA,4CAA4C,KAAK,gDAAgD,wDAAO,CAAC;AACzG;AACA;AACA;AACA;AACA,qBAAqB,4DAAc;AACnC;AACA;AACA,4CAA4C,KAAK,gDAAgD,uDAAM,CAAC;AACxG;AACA;AACA;AACA;AACA,qBAAqB,4DAAc;AACnC;AACA;AACA;AACA,4CAA4C,KAAK,6BAA6B,uDAAM,CAAC,0BAA0B,yDAAQ,CAAC;AACxH;AACA;AACA;AACA;AACA,qBAAqB,4DAAc;AACnC;AACA;AACA,4CAA4C,KAAK;AACjD;AACA;AACA;AACA;AACA;AACA,wCAAwC,KAAK,sCAAsC,gCAAgC;AACnH;AACA;AACA;AACA;AACA,oCAAoC,KAAK,kDAAkD,+DAAc,CAAC;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,KAAK;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACzJ4F;AAChD;AACrC;AACP;AACA;AACA;AACA,wCAAwC,oDAAS;AACjD;AACA;AACA;AACA,gDAAgD,uEAAsB;AACtE;AACA,mEAAmE,uEAAsB,EAAE;AAC3F;AACA,yBAAyB,qDAAI;AAC7B,sEAAsE,uEAAsB,EAAE,EAAE,qDAAI,CAAC;AACrG;AACA,yBAAyB,yDAAQ;AACjC,2EAA2E,uEAAsB,EAAE,EAAE,yDAAQ,CAAC;AAC9G;AACA,yBAAyB,4DAAW;AACpC,6EAA6E,uEAAsB,EAAE,EAAE,4DAAW,CAAC;AACnH;AACA;AACA,4DAA4D,uEAAsB,EAAE,OAAO;AAC3F;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC9B0C;AACnC,+BAA+B,mDAAU;AAChD;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACNwE;AAC9B;AACS;AAC5C,iCAAiC,mDAAU;AAClD;AACA;AACA;AACA;AACA;AACA,yEAAyE,2DAAU,EAAE;AACrF;AACA,yBAAyB,yDAAQ;AACjC,8EAA8E,2DAAU,EAAE,EAAE,yDAAQ,CAAC;AACrG;AACA,+EAA+E,2DAAU,EAAE,EAAE,yDAAQ,EAAE;AACvG;AACA,qCAAqC,0DAAS;AAC9C,uFAAuF,2DAAU,EAAE,EAAE,yDAAQ,EAAE,EAAE,0DAAS,CAAC;AAC3H;AACA;AACA;AACA;AACA;AACA,wEAAwE,2DAAU,EAAE,EAAE,yDAAQ,EAAE;AAChG;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2DAAU,EAAE,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAc;AAC7B;AACA;AACA;AACA,gCAAgC,KAAK,sBAAsB,0DAAS,CAAC;AACrE;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC9CoH;AACxE;AACO;AACI;AAChD,+BAA+B,gEAAgB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yEAAyE,2DAAU,EAAE;AACrF;AACA,yBAAyB,uDAAM;AAC/B,8EAA8E,2DAAU,EAAE,EAAE,uDAAM,CAAC;AACnG;AACA,+EAA+E,2DAAU,EAAE,EAAE,uDAAM,EAAE;AACrG;AACA,qCAAqC,yDAAQ;AAC7C,kGAAkG,2DAAU,EAAE,EAAE,uDAAM,EAAE,EAAE,yDAAQ,CAAC;AACnI;AACA;AACA;AACA,qCAAqC,4DAAW;AAChD,sGAAsG,2DAAU,EAAE,EAAE,uDAAM,EAAE,EAAE,4DAAW,CAAC;AAC1I;AACA;AACA;AACA,qCAAqC,kEAAiB;AACtD,2GAA2G,2DAAU,EAAE,EAAE,uDAAM,EAAE,EAAE,kEAAiB,CAAC;AACrJ;AACA;AACA;AACA,qCAAqC,8DAAa;AAClD,iGAAiG,2DAAU,EAAE,EAAE,uDAAM,EAAE,EAAE,8DAAa,CAAC;AACvI;AACA;AACA;AACA;AACA;AACA,wEAAwE,2DAAU,EAAE,EAAE,uDAAM,EAAE;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2DAAU,EAAE,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA,eAAe,4DAAc;AAC7B;AACA;AACA,0CAA0C,oDAAS;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,yDAAQ,CAAC,SAAS,kEAAiB,CAAC;AAC/E;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9EyD;AAC6pB;AACtoB;AAC9B;AACV;AACiB;AACA;AACN;AACM;AACN;AACI;AACD;AACK;AACA;AACJ;AACvD;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,yBAAyB,qDAAI,QAAQ,4DAAc,CAAC,qDAAI;AACxD;AACA,yBAAyB,wDAAO,QAAQ,kEAAiB,CAAC,wDAAO;AACjE;AACA,yBAAyB,uDAAM,QAAQ,iEAAgB,CAAC,uDAAM;AAC9D;AACA,yBAAyB,uDAAM,QAAQ,iEAAgB,CAAC,uDAAM;AAC9D;AACA,uCAAuC,qEAAkB,CAAC,yDAAQ;AAClE,sCAAsC,oDAAG;AACzC;AACA;AACA,sCAAsC,kEAAiB,CAAC,wDAAO;AAC/D,yCAAyC,uDAAM;AAC/C,2CAA2C,oDAAG;AAC9C;AACA;AACA,kCAAkC,gEAAe,CAAC,oDAAG;AACrD,iCAAiC,qDAAI;AACrC,iCAAiC,wDAAO;AACxC,iCAAiC,uDAAM;AACvC,iCAAiC,uDAAM;AACvC,iCAAiC,yDAAQ;AACzC,iCAAiC,wDAAO;AACxC;AACA;AACA;AACA,qDAAqD,gEAAe,EAAE;AACtE;AACA,yBAAyB,wDAAO;AAChC,kEAAkE,gEAAe,EAAE,EAAE,wDAAO,CAAC;AAC7F;AACA;AACA,yBAAyB,4DAAW;AACpC,wEAAwE,gEAAe,EAAE,EAAE,4DAAW,CAAC;AACvG;AACA,uFAAuF,gEAAe,EAAE,EAAE,4DAAW,EAAE;AACvH,4FAA4F,gEAAe,EAAE,EAAE,4DAAW,EAAE;AAC5H;AACA;AACA,yFAAyF,2DAAU,EAAE;AACrG;AACA;AACA,yCAAyC,qDAAI;AAC7C,yDAAyD,4DAAc;AACvE;AACA,yCAAyC,wDAAO;AAChD,yDAAyD,kEAAiB;AAC1E;AACA,yCAAyC,uDAAM;AAC/C,yDAAyD,iEAAgB;AACzE;AACA,yCAAyC,uDAAM;AAC/C,yDAAyD,iEAAgB;AACzE;AACA,yCAAyC,yDAAQ;AACjD,yDAAyD,qEAAkB;AAC3E;AACA,yCAAyC,wDAAO;AAChD,yDAAyD,kEAAiB;AAC1E;AACA,yCAAyC,uDAAM;AAC/C,yDAAyD,gEAAe;AACxE;AACA,yCAAyC,+DAAc;AACvD;AACA;AACA,iFAAiF,8DAAS;AAC1F;AACA;AACA;AACA,uFAAuF,8DAAS;AAChG;AACA;AACA,qFAAqF,iEAAgB;AACrG;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,gEAAe;AACxE;AACA,yCAAyC,wDAAO;AAChD,yCAAyC,4DAAW;AACpD;AACA;AACA;AACA,+EAA+E,2DAAU,EAAE;AAC3F;AACA;AACA;AACA;AACA;AACA,mGAAmG,qBAAqB;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,gEAAe,EAAE;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,KAAK;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,4DAAc;AAC/B,iBAAiB,4DAAc;AAC/B,iBAAiB,4DAAc;AAC/B,iBAAiB,4DAAc;AAC/B;AACA;AACA,iBAAiB,4DAAc;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,4DAAc;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uBAAuB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,KAAK;AACjE;AACA;AACA;AACA,8CAA8C,4DAAc;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,8DAAe,KAAK,uEAAwB,mDAAmD,iEAAsB;AACjJ,yBAAyB,8DAAY,UAAU,gEAAe;AAC9D;AACA;AACA,+CAA+C,gEAAe;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,kEAAiB,CAAC,gEAAe;AACzE,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,iEAAgB;AACjI,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,4DAAW;AAChI;AACA;AACA,oCAAoC,kEAAiB,CAAC,4DAAW;AACjE,6CAA6C,iEAAgB;AAC7D,+CAA+C,2DAAU;AACzD;AACA;AACA,sCAAsC,gEAAe,CAAC,2DAAU;AAChE,uCAAuC,gEAAe;AACtD,uCAAuC,mEAAkB;AACzD,uCAAuC,kEAAiB;AACxD,uCAAuC,kEAAiB;AACxD,uCAAuC,oEAAmB;AAC1D,uCAAuC,mEAAkB;AACzD,uCAAuC,kEAAiB;AACxD;AACA;AACA,oCAAoC,kEAAiB,CAAC,gEAAe;AACrE,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC7I,yCAAyC,qDAAI,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,2EAA0B;AACxI;AACA;AACA,oCAAoC,kEAAiB,CAAC,2EAA0B;AAChF;AACA;AACA,oCAAoC,kEAAiB,CAAC,mEAAkB;AACxE,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC7I,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,8EAA6B;AAC9I;AACA;AACA,oCAAoC,kEAAiB,CAAC,8EAA6B;AACnF;AACA;AACA,oCAAoC,kEAAiB,CAAC,kEAAiB;AACvE,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC7I,yCAAyC,uDAAM,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC5I;AACA;AACA,oCAAoC,kEAAiB,CAAC,6EAA4B;AAClF;AACA;AACA,oCAAoC,kEAAiB,CAAC,kEAAiB;AACvE,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC7I,yCAAyC,uDAAM,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC5I;AACA;AACA,oCAAoC,kEAAiB,CAAC,6EAA4B;AAClF,yCAAyC,yDAAQ,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,iEAAgB;AAClI,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,wDAAO;AAC5H,yCAAyC,kEAAiB,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,wDAAO;AAClI,yCAAyC,8DAAa,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,wDAAO;AAC9H;AACA;AACA,oCAAoC,kEAAiB,CAAC,oEAAmB;AACzE,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC7I,yCAAyC,yDAAQ,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,+EAA8B;AAChJ;AACA;AACA,oCAAoC,kEAAiB,CAAC,+EAA8B;AACpF,yCAAyC,0DAAS,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,iEAAgB;AACnI;AACA;AACA,oCAAoC,kEAAiB,CAAC,mEAAkB;AACxE,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC7I,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,8EAA6B;AAC9I;AACA;AACA,oCAAoC,kEAAiB,CAAC,8EAA6B;AACnF,yCAAyC,2DAAU,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,2DAAU;AAC9H,yCAAyC,+DAAc,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,iEAAgB;AACxI,yCAAyC,iEAAgB,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,iEAAgB;AAC1I;AACA;AACA,oCAAoC,kEAAiB,CAAC,2DAAU;AAChE,6CAA6C,iEAAgB;AAC7D,+CAA+C,+DAAc;AAC7D;AACA;AACA,kCAAkC,gEAAe,CAAC,+DAAc;AAChE,uCAAuC,iEAAgB;AACvD,uCAAuC,uEAAsB;AAC7D;AACA;AACA,oCAAoC,kEAAiB,CAAC,uEAAsB;AAC5E,yCAAyC,qDAAI,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,iEAAgB;AAC9H,yCAAyC,yDAAQ,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,wDAAO;AACzH,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H;AACA;AACA,oCAAoC,kEAAiB,CAAC,kEAAiB;AACvE,yCAAyC,4DAAW,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,uDAAM;AAC3H,yCAAyC,wDAAO,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC7I,yCAAyC,uDAAM,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AAC5I,yCAAyC,+DAAc,QAAQ,qEAAkB,KAAK,gDAAW,uBAAuB,6EAA4B;AACpJ;AACA;AACA,yCAAyC,iEAAgB,CAAC,iEAAgB;AAC1E;AACA;AACA;AACA,2CAA2C,qEAAkB,CAAC,6EAA4B;AAC1F,0CAA0C,iEAAgB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxXO;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACP;;;;;;;;;;;;;;;;;AChDsE;AACtE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,+EAAuB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,UAAU,SAAS,KAAK,SAAS,OAAO;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,KAAK,SAAS,OAAO;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,+EAAuB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,QAAQ,EAAE,2CAA2C;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACrHA;AACA;AAC0D;AACA;AACI;AACkC;AACK;AACrD;AACL;AAC3C;AACO;AACP;AACA;AACA;AACA;AACA,+BAA+B,mEAAc;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,mEAAc;AACrF;AACA;AACA,2CAA2C,mEAAc;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,mEAAc;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,mEAAc;AAC5D,gDAAgD,mEAAc;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,mEAAc,aAAa,oDAAG;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,oDAAS;AACzE;AACA,sBAAsB,gDAAW;AACjC;AACA;AACA;AACA;AACA,qDAAqD,cAAc;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,mEAAc;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,mEAAc;AAC3D,+CAA+C,mEAAc;AAC7D;AACA;AACA;AACA,2CAA2C,mEAAc;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,cAAc;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,mEAAc;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8HAA8H;AAC9H;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,kFAAkF,aAAa;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,oDAAS;AACzE;AACA,sBAAsB,gDAAW;AACjC;AACA;AACA;AACA;AACA,qDAAqD,cAAc;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,mEAAc;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oDAAS;AAC1B,iBAAiB,oDAAS;AAC1B,iBAAiB,oDAAS;AAC1B,iBAAiB,oDAAS;AAC1B;AACA;AACA;AACA;AACA;AACA,gDAAgD,mEAAc;AAC9D;AACA;AACA;AACA,kDAAkD,oDAAS;AAC3D,8CAA8C,gDAAW;AACzD;AACA;AACA,2DAA2D,mEAAc;AACzE;AACA;AACA;AACA;AACA,kEAAkE,mBAAmB;AACrF;AACA;AACA,iBAAiB,oDAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,kBAAkB;AACnF;AACA;AACA;AACA;AACA;AACA,aAAa,6DAAQ;AACrB;AACA;AACA;AACA;AACA,0CAA0C,gEAAe;AACzD;AACA,mCAAmC;AACnC;AACA,qDAAqD,uEAAgB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D;AAC5D;AACA;AACA;AACA,0BAA0B,gEAAe,SAAS,gBAAgB;AAClE;AACA,8CAA8C;AAC9C;AACA,uDAAuD,sBAAsB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,uCAAuC;AACtI;AACA;AACA;AACA,mEAAmE,gEAAe,+CAA+C,gEAAe,UAAU,iEAAgB;AAC1K;AACA;AACA;AACA;AACA,iCAAiC,gEAAgE;AACjG,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,gEAAgE;AACjG,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,qBAAqB;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,gEAAe;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,IAAI,oBAAoB;AAC5E,uEAAuE,oDAAS;AAChF;AACA;AACA;AACA,2BAA2B,gDAAW;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,6DAAQ;AACxB;AACA;AACA,gCAAgC,OAAO;AACvC,gCAAgC,OAAO;AACvC;AACA;AACA;AACA,8BAA8B,EAAE,UAAU,IAAI;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,yDAAoB,uCAAuC,gBAAgB,GAAG,cAAc;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,iEAAgB;AAClF;AACA;AACA,gCAAgC,0DAAqB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oDAAe;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,gEAAe;AAC5D,aAAa;AACb;AACA;AACA,2CAA2C,iEAAgB;AAC3D;AACA;AACA;AACA;AACA,4BAA4B,yDAAoB;AAChD;AACA;AACA;AACA;AACA;AACA,uFAAuF,oDAAS;AAChG;AACA,gDAAgD,gDAAW,yBAAyB,kBAAkB,EAAE,MAAM;AAC9G;AACA;AACA;AACA,8BAA8B,gDAAW;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oBAAoB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,oBAAoB,sDAAsD,UAAU,6BAA6B,kBAAkB;AACnL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACllBA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,YAAY,IAAI,gBAAgB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACpB0E;AACrB;AACR;AACT;AAC7B,mCAAmC,8DAAe;AACzD;AACA;AACA;AACA;AACA,cAAc,6CAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,gEAAe,EAAE,EAAE,WAAW,EAAE,iEAAgB,CAAC;AACnE;AACA;AACA;AACA,eAAe,sDAAW;AAC1B;AACA;AACA;AACA,kBAAkB,6CAAS;AAC3B;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACrCiC;AACG;AAC7B,2BAA2B,2CAAY;AAC9C;AACA,cAAc,6CAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACtBqD;AACI;AACZ;AACtC,8BAA8B,sDAAW;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,2BAA2B,EAAE,qEAAmB;AAChE;AACA,0BAA0B,uDAAK;AAC/B;AACA,sBAAsB,wDAAM;AAC5B;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvBiD;AACJ;AACE;AACF;AACA;AACE;AACN;AACO;AACC;AACF;AACM;AACW;AACE;AAClE;;;;;;;;;;;;;;;;;;ACbiD;AAC2C;AACxD;AAC7B,oCAAoC,8CAAe;AAC1D;AACA,cAAc,6CAAS,gCAAgC,iEAAgB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,gEAAe,EAAE,EAAE,iEAAgB,EAAE,EAAE,iEAAgB,CAAC;AAC1E;AACA;AACA,eAAe,0CAAW;AAC1B;AACA;AACA;AACA,kBAAkB,6CAAS;AAC3B;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACzBO;AACP;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACN6C;AACtC,2BAA2B,sDAAW;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sDAAW;AAC1B;AACA;AACA;AACA;AACA;AACA,gDAAgD,kBAAkB,uBAAuB,gBAAgB;AACzG;AACA;AACA;;;;;;;;;;;;;;;;;ACrBgD;AACZ;AAC7B,2BAA2B,4CAAa;AAC/C;AACA,cAAc,6CAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAAY;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kCAAkC;AAC3D;AACA;AACA,kBAAkB,6CAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACzDiC;AACG;AAC7B,wBAAwB,2CAAY;AAC3C;AACA,cAAc,6CAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AClBiC;AACG;AAC7B,0BAA0B,2CAAY;AAC7C;AACA,cAAc,6CAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,SAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACtBiD;AACjD;AACA;AACA;AACO,0BAA0B,0DAAa;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACrBkC;AACE;AAC7B,4BAA4B,4CAAa;AAChD;AACA,cAAc,6CAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,6CAAS;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC9CiC;AACG;AAC7B,0BAA0B,2CAAY;AAC7C;AACA,cAAc,6CAAS;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACpBmD;AACA;AAC5C;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qDAAa;AAC5B;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS;AACnC;AACA;AACA,yDAAyD,gBAAgB,+BAA+B,kBAAkB,eAAe,qDAAa,CAAC,6CAAS,OAAO;AACvK;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS;AACnC;AACA;AACA,yDAAyD,gBAAgB,+BAA+B,kBAAkB,eAAe,qDAAa,CAAC,6CAAS,UAAU;AAC1K;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS;AACnC;AACA;AACA,yDAAyD,gBAAgB,+BAA+B,kBAAkB,eAAe,qDAAa,CAAC,6CAAS,SAAS;AACzK;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS;AACnC;AACA;AACA,yDAAyD,gBAAgB,+BAA+B,kBAAkB,eAAe,qDAAa,CAAC,6CAAS,SAAS;AACzK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,gBAAgB,+BAA+B,kBAAkB;AAC1H;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS;AACnC;AACA;AACA,yDAAyD,gBAAgB,+BAA+B,kBAAkB,eAAe,qDAAa,CAAC,6CAAS,WAAW;AAC3K;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAS;AACnC;AACA;AACA,yDAAyD,gBAAgB,+BAA+B,kBAAkB,eAAe,qDAAa,CAAC,6CAAS,UAAU;AAC1K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B,iBAAiB,6CAAS;AAC1B,gCAAgC,4DAAc;AAC9C,4BAA4B,4DAAc;AAC1C;AACA;AACA;AACA;AACA;AACA,iCAAiC,6CAAS;AAC1C,iCAAiC,6CAAS;AAC1C,4CAA4C,4DAAc;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACzIoC;AAC7B;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6CAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,8BAA8B;AACxF;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACrD+C;AACE;AACb;AAC7B;AACP;AACA;AACO;AACP;AACA;AACO;AACP,mDAAmD,6CAAS;AAC5D;AACO;AACP,mDAAmD,6CAAS;AAC5D;AACO;AACP,mDAAmD,6CAAS;AAC5D;AACO;AACP,kDAAkD,6CAAS;AAC3D;AACO;AACP,wBAAwB,0DAAa;AACrC;AACO;AACP,wBAAwB,wDAAY;AACpC;AACA;;;;;;;;;;;;;;;;AC3BO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,8BAA8B;AACxB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,MAAM,EAAE,iBAAiB;AAC9E;AACA;AACA;AACA;;;;;;;;;;;;;;;ACpCO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACXO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,IAAI;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,cAAc,UAAU,GAAG,eAAe,GAAG,SAAS,GAAG,YAAY;AACrE;AACA;;;;;;;;;;;;;;;ACxBO;AACP;;;;;;;;;;;;;;;;;;;;ACD0F;AAC3B;AACV;AACC;AACE;AACjD;AACP,8CAA8C,wEAAe;AAC7D;AACA,cAAc,wEAAe,KAAK,iFAAwB,IAAI,mEAAiB;AAC/E;AACA,uBAAuB,iEAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oEAA2B,UAAU,8DAAa;AACrE;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC3BmE;AACd;AACsB;AAC3E;AACO;AACP;AACA,oCAAoC,gDAAc;AAClD,iBAAiB,6DAAc,UAAU,2EAAgB;AACzD;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACX4G;AAC3C;AAC0D;AACpH;AACP;AACA,+BAA+B,6CAAW;AAC1C;AACA,oBAAoB,mDAAa;AACjC;AACA;AACA;AACA,SAAS;AACT;AACA,+BAA+B,4DAA4D;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gDAAU;AACtB,sBAAsB,8DAAU,CAAC,6DAAS;AAC1C;AACA;AACA;AACA,sBAAsB,8DAAU,CAAC,6DAAS;AAC1C;AACA,YAAY,kDAAY;AACxB,gBAAgB,2CAAK;AACrB,0BAA0B,8DAAU,CAAC,6DAAS,oBAAoB,kEAAa;AAC/E;AACA,qBAAqB,2CAAK;AAC1B,0BAA0B,8DAAU,CAAC,6DAAS,mBAAmB,iEAAY;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,2CAAK;AACrB,0BAA0B,8DAAU,CAAC,6DAAS;AAC9C;AACA,qBAAqB,2CAAK;AAC1B,0BAA0B,8DAAU,CAAC,6DAAS;AAC9C;AACA;AACA,YAAY,8CAAQ;AACpB,sBAAsB,8DAAU,CAAC,6DAAS;AAC1C;AACA,YAAY,4CAAM;AAClB;AACA;AACA;AACA,sBAAsB,8DAAU,CAAC,6DAAS,cAAc,gEAAW;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,iCAAiC;AAC1D,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8DAAS;AAChC;AACA;AACA;AACA,2BAA2B,gEAAW;AACtC;AACA,2BAA2B,iEAAY;AACvC;AACA;AACA;AACA;AACA;AACA,2BAA2B,gEAAW;AACtC;AACA;AACA,0DAA0D,aAAa;AACvE;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,6DAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB,wCAAwC,gDAAgD;AACxF,aAAa;AACb;AACA;;;;;;;;;;;;;;;;;UCjLA;UACA;;UAEA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;;UAEA;UACA;UACA;;;;;WCtBA;WACA;WACA;WACA;WACA;WACA,iCAAiC,WAAW;WAC5C;WACA;;;;;WCPA;WACA;WACA;WACA;WACA,yCAAyC,wCAAwC;WACjF;WACA;WACA;;;;;WCPA;;;;;WCAA;WACA;WACA;WACA,uDAAuD,iBAAiB;WACxE;WACA,gDAAgD,aAAa;WAC7D;;;;;;;;;;;;;;;;;;;;;;ACN6E;AACyB;AACvD;AACnB;AAS5B,MAAM,YAAY,GAAG,mBAAmB,CAAC;AAElC,SAAS,SAAS;IACvB,MAAM,MAAM,GAAG,EAAW,CAAC;IAC3B,MAAM,CAAC,KAAK,GAAG,uDAAQ,CAAC,cAAc,CAAC,CAAC;IACxC,MAAM,CAAC,KAAK,GAAG,uDAAQ,CAAC,OAAO,CAAC,CAAC;IACjC,MAAM,CAAC,IAAI,GAAG,uDAAQ,CAAC,MAAM,CAAC,CAAC;IAC/B,MAAM,CAAC,KAAK,GAAG,uDAAQ,CAAC,OAAO,CAAC,CAAC;IACjC,OAAO,MAAM,CAAC;AAChB,CAAC;AAED,MAAM,GAAG,GAAG,KAAK,IAAmB,EAAE;IACpC,MAAM,MAAM,GAAG,SAAS,EAAE,CAAC;IAC3B,MAAM,aAAa,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;QAClC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC;QACxB,CAAC;YACD,+CAAW,CAAC,YAAY,CAAC;iBACtB,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;iBAC/D,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,0CAAI,CAAC,YAAY,EAAE,IAAI,CAAC,CAAC,CAAC;IAE3C,IAAI,OAAO,GAA0B,EAAE,CAAC;IACxC,aAAa,CAAC,OAAO,CAAC,QAAQ,CAAC,EAAE;QAC/B,oDAAK,CAAC,WAAW,QAAQ,EAAE,EAAE,KAAK,IAAI,EAAE;YACtC,IAAI;gBACF,MAAM,MAAM,GAAG,uEAAa,CAAC;oBAC3B,IAAI,EAAE,QAAQ;oBACd,OAAO,EAAE,gDAAY,CAAC,QAAQ,EAAE,MAAM,CAAC;iBACxC,EAAE,IAAI,4EAAsB,EAAE,CAAC,CAAC;gBACjC,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,SAAS,EAAE,EAAE,OAAO,CAAC,GAAG,CAAC,EAAE;oBAC/C,MAAM,OAAO,GAAG,GAAG,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;oBAC1C,oDAAK,CACH,OAAO,CAAC,CAAC,CAAC,EACV;wBACE,SAAS,EAAE,GAAG,CAAC,KAAK,EAAE,GAAG,CAAC,MAAM;wBAChC,WAAW,EAAE,GAAG,CAAC,KAAK,EAAE,KAAK,CAAC,MAAM;wBACpC,OAAO,EAAE,GAAG,CAAC,KAAK,EAAE,GAAG,CAAC,IAAI;wBAC5B,SAAS,EAAE,GAAG,CAAC,KAAK,EAAE,KAAK,CAAC,IAAI;wBAChC,IAAI,EAAE,MAAM,CAAC,OAAO,CAAC,YAAY,EAAE,CAAC,CAAC,CAAC;qBACvC,CACF;oBACD,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;gBACvB,CAAC,CAAC,CAAC;aACJ;YAAC,OAAO,GAAG,EAAE;gBACZ,wDAAS,CAAC,YAAY,QAAQ,qBAAqB,CAAC,GAAG,YAAY,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC;gBACjG,OAAO;aACR;QACH,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AAEL,CAAC,CAAC;AAEF,GAAG,EAAE,CAAC","sources":[".././node_modules/@actions/core/lib/command.js",".././node_modules/@actions/core/lib/core.js",".././node_modules/@actions/core/lib/file-command.js",".././node_modules/@actions/core/lib/oidc-utils.js",".././node_modules/@actions/core/lib/path-utils.js",".././node_modules/@actions/core/lib/summary.js",".././node_modules/@actions/core/lib/utils.js",".././node_modules/@actions/http-client/lib/auth.js",".././node_modules/@actions/http-client/lib/index.js",".././node_modules/@actions/http-client/lib/proxy.js",".././node_modules/cronstrue/dist/cronstrue.js",".././node_modules/tunnel/index.js",".././node_modules/tunnel/lib/tunnel.js",".././node_modules/uuid/dist/esm-node/index.js",".././node_modules/uuid/dist/esm-node/md5.js",".././node_modules/uuid/dist/esm-node/nil.js",".././node_modules/uuid/dist/esm-node/parse.js",".././node_modules/uuid/dist/esm-node/regex.js",".././node_modules/uuid/dist/esm-node/rng.js",".././node_modules/uuid/dist/esm-node/sha1.js",".././node_modules/uuid/dist/esm-node/stringify.js",".././node_modules/uuid/dist/esm-node/v1.js",".././node_modules/uuid/dist/esm-node/v3.js",".././node_modules/uuid/dist/esm-node/v35.js",".././node_modules/uuid/dist/esm-node/v4.js",".././node_modules/uuid/dist/esm-node/v5.js",".././node_modules/uuid/dist/esm-node/validate.js",".././node_modules/uuid/dist/esm-node/version.js","../external node-commonjs \"assert\"","../external node-commonjs \"crypto\"","../external node-commonjs \"events\"","../external node-commonjs \"fs\"","../external node-commonjs \"http\"","../external node-commonjs \"https\"","../external node-commonjs \"net\"","../external node-commonjs \"os\"","../external node-commonjs \"path\"","../external node-commonjs \"tls\"","../external node-commonjs \"util\"",".././node_modules/yaml/dist/compose/compose-collection.js",".././node_modules/yaml/dist/compose/compose-doc.js",".././node_modules/yaml/dist/compose/compose-node.js",".././node_modules/yaml/dist/compose/compose-scalar.js",".././node_modules/yaml/dist/compose/composer.js",".././node_modules/yaml/dist/compose/resolve-block-map.js",".././node_modules/yaml/dist/compose/resolve-block-scalar.js",".././node_modules/yaml/dist/compose/resolve-block-seq.js",".././node_modules/yaml/dist/compose/resolve-end.js",".././node_modules/yaml/dist/compose/resolve-flow-collection.js",".././node_modules/yaml/dist/compose/resolve-flow-scalar.js",".././node_modules/yaml/dist/compose/resolve-props.js",".././node_modules/yaml/dist/compose/util-contains-newline.js",".././node_modules/yaml/dist/compose/util-empty-scalar-position.js",".././node_modules/yaml/dist/compose/util-flow-indent-check.js",".././node_modules/yaml/dist/compose/util-map-includes.js",".././node_modules/yaml/dist/doc/Document.js",".././node_modules/yaml/dist/doc/anchors.js",".././node_modules/yaml/dist/doc/applyReviver.js",".././node_modules/yaml/dist/doc/createNode.js",".././node_modules/yaml/dist/doc/directives.js",".././node_modules/yaml/dist/errors.js",".././node_modules/yaml/dist/index.js",".././node_modules/yaml/dist/log.js",".././node_modules/yaml/dist/nodes/Alias.js",".././node_modules/yaml/dist/nodes/Collection.js",".././node_modules/yaml/dist/nodes/Node.js",".././node_modules/yaml/dist/nodes/Pair.js",".././node_modules/yaml/dist/nodes/Scalar.js",".././node_modules/yaml/dist/nodes/YAMLMap.js",".././node_modules/yaml/dist/nodes/YAMLSeq.js",".././node_modules/yaml/dist/nodes/addPairToJSMap.js",".././node_modules/yaml/dist/nodes/identity.js",".././node_modules/yaml/dist/nodes/toJS.js",".././node_modules/yaml/dist/parse/cst-scalar.js",".././node_modules/yaml/dist/parse/cst-stringify.js",".././node_modules/yaml/dist/parse/cst-visit.js",".././node_modules/yaml/dist/parse/cst.js",".././node_modules/yaml/dist/parse/lexer.js",".././node_modules/yaml/dist/parse/line-counter.js",".././node_modules/yaml/dist/parse/parser.js",".././node_modules/yaml/dist/public-api.js",".././node_modules/yaml/dist/schema/Schema.js",".././node_modules/yaml/dist/schema/common/map.js",".././node_modules/yaml/dist/schema/common/null.js",".././node_modules/yaml/dist/schema/common/seq.js",".././node_modules/yaml/dist/schema/common/string.js",".././node_modules/yaml/dist/schema/core/bool.js",".././node_modules/yaml/dist/schema/core/float.js",".././node_modules/yaml/dist/schema/core/int.js",".././node_modules/yaml/dist/schema/core/schema.js",".././node_modules/yaml/dist/schema/json/schema.js",".././node_modules/yaml/dist/schema/tags.js",".././node_modules/yaml/dist/schema/yaml-1.1/binary.js",".././node_modules/yaml/dist/schema/yaml-1.1/bool.js",".././node_modules/yaml/dist/schema/yaml-1.1/float.js",".././node_modules/yaml/dist/schema/yaml-1.1/int.js",".././node_modules/yaml/dist/schema/yaml-1.1/omap.js",".././node_modules/yaml/dist/schema/yaml-1.1/pairs.js",".././node_modules/yaml/dist/schema/yaml-1.1/schema.js",".././node_modules/yaml/dist/schema/yaml-1.1/set.js",".././node_modules/yaml/dist/schema/yaml-1.1/timestamp.js",".././node_modules/yaml/dist/stringify/foldFlowLines.js",".././node_modules/yaml/dist/stringify/stringify.js",".././node_modules/yaml/dist/stringify/stringifyCollection.js",".././node_modules/yaml/dist/stringify/stringifyComment.js",".././node_modules/yaml/dist/stringify/stringifyDocument.js",".././node_modules/yaml/dist/stringify/stringifyNumber.js",".././node_modules/yaml/dist/stringify/stringifyPair.js",".././node_modules/yaml/dist/stringify/stringifyString.js",".././node_modules/yaml/dist/visit.js",".././node_modules/@actions/expressions/dist/ast.js",".././node_modules/@actions/expressions/dist/completion.js",".././node_modules/@actions/expressions/dist/completion/descriptionDictionary.js",".././node_modules/@actions/expressions/dist/data/array.js",".././node_modules/@actions/expressions/dist/data/boolean.js",".././node_modules/@actions/expressions/dist/data/dictionary.js",".././node_modules/@actions/expressions/dist/data/expressiondata.js",".././node_modules/@actions/expressions/dist/data/index.js",".././node_modules/@actions/expressions/dist/data/null.js",".././node_modules/@actions/expressions/dist/data/number.js",".././node_modules/@actions/expressions/dist/data/replacer.js",".././node_modules/@actions/expressions/dist/data/reviver.js",".././node_modules/@actions/expressions/dist/data/string.js",".././node_modules/@actions/expressions/dist/errors.js",".././node_modules/@actions/expressions/dist/evaluator.js",".././node_modules/@actions/expressions/dist/filtered_array.js",".././node_modules/@actions/expressions/dist/funcs.js",".././node_modules/@actions/expressions/dist/funcs/contains.js",".././node_modules/@actions/expressions/dist/funcs/endswith.js",".././node_modules/@actions/expressions/dist/funcs/format.js",".././node_modules/@actions/expressions/dist/funcs/fromjson.js",".././node_modules/@actions/expressions/dist/funcs/join.js",".././node_modules/@actions/expressions/dist/funcs/startswith.js",".././node_modules/@actions/expressions/dist/funcs/tojson.js",".././node_modules/@actions/expressions/dist/idxHelper.js",".././node_modules/@actions/expressions/dist/index.js",".././node_modules/@actions/expressions/dist/lexer.js",".././node_modules/@actions/expressions/dist/parser.js",".././node_modules/@actions/expressions/dist/result.js",".././node_modules/@actions/workflow-parser/dist/index.js",".././node_modules/@actions/workflow-parser/dist/model/convert.js",".././node_modules/@actions/workflow-parser/dist/model/converter/concurrency.js",".././node_modules/@actions/workflow-parser/dist/model/converter/container.js",".././node_modules/@actions/workflow-parser/dist/model/converter/cron-constants.js",".././node_modules/@actions/workflow-parser/dist/model/converter/cron.js",".././node_modules/@actions/workflow-parser/dist/model/converter/events.js",".././node_modules/@actions/workflow-parser/dist/model/converter/handle-errors.js",".././node_modules/@actions/workflow-parser/dist/model/converter/id-builder.js",".././node_modules/@actions/workflow-parser/dist/model/converter/job.js",".././node_modules/@actions/workflow-parser/dist/model/converter/job/environment.js",".././node_modules/@actions/workflow-parser/dist/model/converter/job/inputs.js",".././node_modules/@actions/workflow-parser/dist/model/converter/job/runs-on.js",".././node_modules/@actions/workflow-parser/dist/model/converter/job/secrets.js",".././node_modules/@actions/workflow-parser/dist/model/converter/jobs.js",".././node_modules/@actions/workflow-parser/dist/model/converter/referencedWorkflow.js",".././node_modules/@actions/workflow-parser/dist/model/converter/steps.js",".././node_modules/@actions/workflow-parser/dist/model/converter/string-list.js",".././node_modules/@actions/workflow-parser/dist/model/converter/workflow-call.js",".././node_modules/@actions/workflow-parser/dist/model/converter/workflow-dispatch.js",".././node_modules/@actions/workflow-parser/dist/model/type-guards.js",".././node_modules/@actions/workflow-parser/dist/model/workflow-template.js",".././node_modules/@actions/workflow-parser/dist/templates/allowed-context.js",".././node_modules/@actions/workflow-parser/dist/templates/json-object-reader.js",".././node_modules/@actions/workflow-parser/dist/templates/parse-event.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/boolean-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/definition-info.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/definition-type.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/index.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/mapping-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/null-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/number-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/one-of-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/property-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/scalar-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/sequence-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/string-definition.js",".././node_modules/@actions/workflow-parser/dist/templates/schema/template-schema.js",".././node_modules/@actions/workflow-parser/dist/templates/template-constants.js",".././node_modules/@actions/workflow-parser/dist/templates/template-context.js",".././node_modules/@actions/workflow-parser/dist/templates/template-reader.js",".././node_modules/@actions/workflow-parser/dist/templates/template-validation-error.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/basic-expression-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/boolean-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/expression-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/index.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/insert-expression-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/key-value-pair.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/literal-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/mapping-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/null-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/number-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/scalar-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/sequence-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/string-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/template-token.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/traversal-state.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/type-guards.js",".././node_modules/@actions/workflow-parser/dist/templates/tokens/types.js",".././node_modules/@actions/workflow-parser/dist/templates/trace-writer.js",".././node_modules/@actions/workflow-parser/dist/workflows/file-reference.js",".././node_modules/@actions/workflow-parser/dist/workflows/workflow-constants.js",".././node_modules/@actions/workflow-parser/dist/workflows/workflow-parser.js",".././node_modules/@actions/workflow-parser/dist/workflows/workflow-schema.js",".././node_modules/@actions/workflow-parser/dist/workflows/yaml-object-reader.js","../webpack/bootstrap","../webpack/runtime/compat get default export","../webpack/runtime/define property getters","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/make namespace object",".././src/index.ts"],"sourcesContent":["\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getIDToken = exports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.notice = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\nconst oidc_utils_1 = require(\"./oidc-utils\");\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode = exports.ExitCode || (exports.ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = utils_1.toCommandValue(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        return file_command_1.issueFileCommand('ENV', file_command_1.prepareKeyValueMessage(name, val));\n    }\n    command_1.issueCommand('set-env', { name }, convertedVal);\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    command_1.issueCommand('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        file_command_1.issueFileCommand('PATH', inputPath);\n    }\n    else {\n        command_1.issueCommand('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    if (options && options.trimWhitespace === false) {\n        return inputs;\n    }\n    return inputs.map(input => input.trim());\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    const filePath = process.env['GITHUB_OUTPUT'] || '';\n    if (filePath) {\n        return file_command_1.issueFileCommand('OUTPUT', file_command_1.prepareKeyValueMessage(name, value));\n    }\n    process.stdout.write(os.EOL);\n    command_1.issueCommand('set-output', { name }, utils_1.toCommandValue(value));\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    command_1.issue('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    command_1.issueCommand('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction error(message, properties = {}) {\n    command_1.issueCommand('error', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds a warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction warning(message, properties = {}) {\n    command_1.issueCommand('warning', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Adds a notice issue\n * @param message notice issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction notice(message, properties = {}) {\n    command_1.issueCommand('notice', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.notice = notice;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    command_1.issue('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    command_1.issue('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    const filePath = process.env['GITHUB_STATE'] || '';\n    if (filePath) {\n        return file_command_1.issueFileCommand('STATE', file_command_1.prepareKeyValueMessage(name, value));\n    }\n    command_1.issueCommand('save-state', { name }, utils_1.toCommandValue(value));\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\nfunction getIDToken(aud) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return yield oidc_utils_1.OidcClient.getIDToken(aud);\n    });\n}\nexports.getIDToken = getIDToken;\n/**\n * Summary exports\n */\nvar summary_1 = require(\"./summary\");\nObject.defineProperty(exports, \"summary\", { enumerable: true, get: function () { return summary_1.summary; } });\n/**\n * @deprecated use core.summary\n */\nvar summary_2 = require(\"./summary\");\nObject.defineProperty(exports, \"markdownSummary\", { enumerable: true, get: function () { return summary_2.markdownSummary; } });\n/**\n * Path exports\n */\nvar path_utils_1 = require(\"./path-utils\");\nObject.defineProperty(exports, \"toPosixPath\", { enumerable: true, get: function () { return path_utils_1.toPosixPath; } });\nObject.defineProperty(exports, \"toWin32Path\", { enumerable: true, get: function () { return path_utils_1.toWin32Path; } });\nObject.defineProperty(exports, \"toPlatformPath\", { enumerable: true, get: function () { return path_utils_1.toPlatformPath; } });\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.prepareKeyValueMessage = exports.issueFileCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst uuid_1 = require(\"uuid\");\nconst utils_1 = require(\"./utils\");\nfunction issueFileCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${utils_1.toCommandValue(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueFileCommand = issueFileCommand;\nfunction prepareKeyValueMessage(key, value) {\n    const delimiter = `ghadelimiter_${uuid_1.v4()}`;\n    const convertedValue = utils_1.toCommandValue(value);\n    // These should realistically never happen, but just in case someone finds a\n    // way to exploit uuid generation let's not allow keys or values that contain\n    // the delimiter.\n    if (key.includes(delimiter)) {\n        throw new Error(`Unexpected input: name should not contain the delimiter \"${delimiter}\"`);\n    }\n    if (convertedValue.includes(delimiter)) {\n        throw new Error(`Unexpected input: value should not contain the delimiter \"${delimiter}\"`);\n    }\n    return `${key}<<${delimiter}${os.EOL}${convertedValue}${os.EOL}${delimiter}`;\n}\nexports.prepareKeyValueMessage = prepareKeyValueMessage;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.OidcClient = void 0;\nconst http_client_1 = require(\"@actions/http-client\");\nconst auth_1 = require(\"@actions/http-client/lib/auth\");\nconst core_1 = require(\"./core\");\nclass OidcClient {\n    static createHttpClient(allowRetry = true, maxRetry = 10) {\n        const requestOptions = {\n            allowRetries: allowRetry,\n            maxRetries: maxRetry\n        };\n        return new http_client_1.HttpClient('actions/oidc-client', [new auth_1.BearerCredentialHandler(OidcClient.getRequestToken())], requestOptions);\n    }\n    static getRequestToken() {\n        const token = process.env['ACTIONS_ID_TOKEN_REQUEST_TOKEN'];\n        if (!token) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_TOKEN env variable');\n        }\n        return token;\n    }\n    static getIDTokenUrl() {\n        const runtimeUrl = process.env['ACTIONS_ID_TOKEN_REQUEST_URL'];\n        if (!runtimeUrl) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable');\n        }\n        return runtimeUrl;\n    }\n    static getCall(id_token_url) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            const httpclient = OidcClient.createHttpClient();\n            const res = yield httpclient\n                .getJson(id_token_url)\n                .catch(error => {\n                throw new Error(`Failed to get ID Token. \\n \n        Error Code : ${error.statusCode}\\n \n        Error Message: ${error.message}`);\n            });\n            const id_token = (_a = res.result) === null || _a === void 0 ? void 0 : _a.value;\n            if (!id_token) {\n                throw new Error('Response json body do not have ID Token field');\n            }\n            return id_token;\n        });\n    }\n    static getIDToken(audience) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // New ID Token is requested from action service\n                let id_token_url = OidcClient.getIDTokenUrl();\n                if (audience) {\n                    const encodedAudience = encodeURIComponent(audience);\n                    id_token_url = `${id_token_url}&audience=${encodedAudience}`;\n                }\n                core_1.debug(`ID token url is ${id_token_url}`);\n                const id_token = yield OidcClient.getCall(id_token_url);\n                core_1.setSecret(id_token);\n                return id_token;\n            }\n            catch (error) {\n                throw new Error(`Error message: ${error.message}`);\n            }\n        });\n    }\n}\nexports.OidcClient = OidcClient;\n//# sourceMappingURL=oidc-utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = void 0;\nconst path = __importStar(require(\"path\"));\n/**\n * toPosixPath converts the given path to the posix form. On Windows, \\\\ will be\n * replaced with /.\n *\n * @param pth. Path to transform.\n * @return string Posix path.\n */\nfunction toPosixPath(pth) {\n    return pth.replace(/[\\\\]/g, '/');\n}\nexports.toPosixPath = toPosixPath;\n/**\n * toWin32Path converts the given path to the win32 form. On Linux, / will be\n * replaced with \\\\.\n *\n * @param pth. Path to transform.\n * @return string Win32 path.\n */\nfunction toWin32Path(pth) {\n    return pth.replace(/[/]/g, '\\\\');\n}\nexports.toWin32Path = toWin32Path;\n/**\n * toPlatformPath converts the given path to a platform-specific path. It does\n * this by replacing instances of / and \\ with the platform-specific path\n * separator.\n *\n * @param pth The path to platformize.\n * @return string The platform-specific path.\n */\nfunction toPlatformPath(pth) {\n    return pth.replace(/[/\\\\]/g, path.sep);\n}\nexports.toPlatformPath = toPlatformPath;\n//# sourceMappingURL=path-utils.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.summary = exports.markdownSummary = exports.SUMMARY_DOCS_URL = exports.SUMMARY_ENV_VAR = void 0;\nconst os_1 = require(\"os\");\nconst fs_1 = require(\"fs\");\nconst { access, appendFile, writeFile } = fs_1.promises;\nexports.SUMMARY_ENV_VAR = 'GITHUB_STEP_SUMMARY';\nexports.SUMMARY_DOCS_URL = 'https://docs.github.com/actions/using-workflows/workflow-commands-for-github-actions#adding-a-job-summary';\nclass Summary {\n    constructor() {\n        this._buffer = '';\n    }\n    /**\n     * Finds the summary file path from the environment, rejects if env var is not found or file does not exist\n     * Also checks r/w permissions.\n     *\n     * @returns step summary file path\n     */\n    filePath() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._filePath) {\n                return this._filePath;\n            }\n            const pathFromEnv = process.env[exports.SUMMARY_ENV_VAR];\n            if (!pathFromEnv) {\n                throw new Error(`Unable to find environment variable for $${exports.SUMMARY_ENV_VAR}. Check if your runtime environment supports job summaries.`);\n            }\n            try {\n                yield access(pathFromEnv, fs_1.constants.R_OK | fs_1.constants.W_OK);\n            }\n            catch (_a) {\n                throw new Error(`Unable to access summary file: '${pathFromEnv}'. Check if the file has correct read/write permissions.`);\n            }\n            this._filePath = pathFromEnv;\n            return this._filePath;\n        });\n    }\n    /**\n     * Wraps content in an HTML tag, adding any HTML attributes\n     *\n     * @param {string} tag HTML tag to wrap\n     * @param {string | null} content content within the tag\n     * @param {[attribute: string]: string} attrs key-value list of HTML attributes to add\n     *\n     * @returns {string} content wrapped in HTML element\n     */\n    wrap(tag, content, attrs = {}) {\n        const htmlAttrs = Object.entries(attrs)\n            .map(([key, value]) => ` ${key}=\"${value}\"`)\n            .join('');\n        if (!content) {\n            return `<${tag}${htmlAttrs}>`;\n        }\n        return `<${tag}${htmlAttrs}>${content}</${tag}>`;\n    }\n    /**\n     * Writes text in the buffer to the summary buffer file and empties buffer. Will append by default.\n     *\n     * @param {SummaryWriteOptions} [options] (optional) options for write operation\n     *\n     * @returns {Promise<Summary>} summary instance\n     */\n    write(options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const overwrite = !!(options === null || options === void 0 ? void 0 : options.overwrite);\n            const filePath = yield this.filePath();\n            const writeFunc = overwrite ? writeFile : appendFile;\n            yield writeFunc(filePath, this._buffer, { encoding: 'utf8' });\n            return this.emptyBuffer();\n        });\n    }\n    /**\n     * Clears the summary buffer and wipes the summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    clear() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.emptyBuffer().write({ overwrite: true });\n        });\n    }\n    /**\n     * Returns the current summary buffer as a string\n     *\n     * @returns {string} string of summary buffer\n     */\n    stringify() {\n        return this._buffer;\n    }\n    /**\n     * If the summary buffer is empty\n     *\n     * @returns {boolen} true if the buffer is empty\n     */\n    isEmptyBuffer() {\n        return this._buffer.length === 0;\n    }\n    /**\n     * Resets the summary buffer without writing to summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    emptyBuffer() {\n        this._buffer = '';\n        return this;\n    }\n    /**\n     * Adds raw text to the summary buffer\n     *\n     * @param {string} text content to add\n     * @param {boolean} [addEOL=false] (optional) append an EOL to the raw text (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addRaw(text, addEOL = false) {\n        this._buffer += text;\n        return addEOL ? this.addEOL() : this;\n    }\n    /**\n     * Adds the operating system-specific end-of-line marker to the buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addEOL() {\n        return this.addRaw(os_1.EOL);\n    }\n    /**\n     * Adds an HTML codeblock to the summary buffer\n     *\n     * @param {string} code content to render within fenced code block\n     * @param {string} lang (optional) language to syntax highlight code\n     *\n     * @returns {Summary} summary instance\n     */\n    addCodeBlock(code, lang) {\n        const attrs = Object.assign({}, (lang && { lang }));\n        const element = this.wrap('pre', this.wrap('code', code), attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML list to the summary buffer\n     *\n     * @param {string[]} items list of items to render\n     * @param {boolean} [ordered=false] (optional) if the rendered list should be ordered or not (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addList(items, ordered = false) {\n        const tag = ordered ? 'ol' : 'ul';\n        const listItems = items.map(item => this.wrap('li', item)).join('');\n        const element = this.wrap(tag, listItems);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML table to the summary buffer\n     *\n     * @param {SummaryTableCell[]} rows table rows\n     *\n     * @returns {Summary} summary instance\n     */\n    addTable(rows) {\n        const tableBody = rows\n            .map(row => {\n            const cells = row\n                .map(cell => {\n                if (typeof cell === 'string') {\n                    return this.wrap('td', cell);\n                }\n                const { header, data, colspan, rowspan } = cell;\n                const tag = header ? 'th' : 'td';\n                const attrs = Object.assign(Object.assign({}, (colspan && { colspan })), (rowspan && { rowspan }));\n                return this.wrap(tag, data, attrs);\n            })\n                .join('');\n            return this.wrap('tr', cells);\n        })\n            .join('');\n        const element = this.wrap('table', tableBody);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds a collapsable HTML details element to the summary buffer\n     *\n     * @param {string} label text for the closed state\n     * @param {string} content collapsable content\n     *\n     * @returns {Summary} summary instance\n     */\n    addDetails(label, content) {\n        const element = this.wrap('details', this.wrap('summary', label) + content);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML image tag to the summary buffer\n     *\n     * @param {string} src path to the image you to embed\n     * @param {string} alt text description of the image\n     * @param {SummaryImageOptions} options (optional) addition image attributes\n     *\n     * @returns {Summary} summary instance\n     */\n    addImage(src, alt, options) {\n        const { width, height } = options || {};\n        const attrs = Object.assign(Object.assign({}, (width && { width })), (height && { height }));\n        const element = this.wrap('img', null, Object.assign({ src, alt }, attrs));\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML section heading element\n     *\n     * @param {string} text heading text\n     * @param {number | string} [level=1] (optional) the heading level, default: 1\n     *\n     * @returns {Summary} summary instance\n     */\n    addHeading(text, level) {\n        const tag = `h${level}`;\n        const allowedTag = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6'].includes(tag)\n            ? tag\n            : 'h1';\n        const element = this.wrap(allowedTag, text);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML thematic break (<hr>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addSeparator() {\n        const element = this.wrap('hr', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML line break (<br>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addBreak() {\n        const element = this.wrap('br', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML blockquote to the summary buffer\n     *\n     * @param {string} text quote text\n     * @param {string} cite (optional) citation url\n     *\n     * @returns {Summary} summary instance\n     */\n    addQuote(text, cite) {\n        const attrs = Object.assign({}, (cite && { cite }));\n        const element = this.wrap('blockquote', text, attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML anchor tag to the summary buffer\n     *\n     * @param {string} text link text/content\n     * @param {string} href hyperlink\n     *\n     * @returns {Summary} summary instance\n     */\n    addLink(text, href) {\n        const element = this.wrap('a', text, { href });\n        return this.addRaw(element).addEOL();\n    }\n}\nconst _summary = new Summary();\n/**\n * @deprecated use `core.summary`\n */\nexports.markdownSummary = _summary;\nexports.summary = _summary;\n//# sourceMappingURL=summary.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandProperties = exports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n/**\n *\n * @param annotationProperties\n * @returns The command properties to send with the actual annotation command\n * See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646\n */\nfunction toCommandProperties(annotationProperties) {\n    if (!Object.keys(annotationProperties).length) {\n        return {};\n    }\n    return {\n        title: annotationProperties.title,\n        file: annotationProperties.file,\n        line: annotationProperties.startLine,\n        endLine: annotationProperties.endLine,\n        col: annotationProperties.startColumn,\n        endColumn: annotationProperties.endColumn\n    };\n}\nexports.toCommandProperties = toCommandProperties;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.PersonalAccessTokenCredentialHandler = exports.BearerCredentialHandler = exports.BasicCredentialHandler = void 0;\nclass BasicCredentialHandler {\n    constructor(username, password) {\n        this.username = username;\n        this.password = password;\n    }\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`${this.username}:${this.password}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BasicCredentialHandler = BasicCredentialHandler;\nclass BearerCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Bearer ${this.token}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BearerCredentialHandler = BearerCredentialHandler;\nclass PersonalAccessTokenCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`PAT:${this.token}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.PersonalAccessTokenCredentialHandler = PersonalAccessTokenCredentialHandler;\n//# sourceMappingURL=auth.js.map","\"use strict\";\n/* eslint-disable @typescript-eslint/no-explicit-any */\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.HttpClient = exports.isHttps = exports.HttpClientResponse = exports.HttpClientError = exports.getProxyUrl = exports.MediaTypes = exports.Headers = exports.HttpCodes = void 0;\nconst http = __importStar(require(\"http\"));\nconst https = __importStar(require(\"https\"));\nconst pm = __importStar(require(\"./proxy\"));\nconst tunnel = __importStar(require(\"tunnel\"));\nvar HttpCodes;\n(function (HttpCodes) {\n    HttpCodes[HttpCodes[\"OK\"] = 200] = \"OK\";\n    HttpCodes[HttpCodes[\"MultipleChoices\"] = 300] = \"MultipleChoices\";\n    HttpCodes[HttpCodes[\"MovedPermanently\"] = 301] = \"MovedPermanently\";\n    HttpCodes[HttpCodes[\"ResourceMoved\"] = 302] = \"ResourceMoved\";\n    HttpCodes[HttpCodes[\"SeeOther\"] = 303] = \"SeeOther\";\n    HttpCodes[HttpCodes[\"NotModified\"] = 304] = \"NotModified\";\n    HttpCodes[HttpCodes[\"UseProxy\"] = 305] = \"UseProxy\";\n    HttpCodes[HttpCodes[\"SwitchProxy\"] = 306] = \"SwitchProxy\";\n    HttpCodes[HttpCodes[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    HttpCodes[HttpCodes[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    HttpCodes[HttpCodes[\"BadRequest\"] = 400] = \"BadRequest\";\n    HttpCodes[HttpCodes[\"Unauthorized\"] = 401] = \"Unauthorized\";\n    HttpCodes[HttpCodes[\"PaymentRequired\"] = 402] = \"PaymentRequired\";\n    HttpCodes[HttpCodes[\"Forbidden\"] = 403] = \"Forbidden\";\n    HttpCodes[HttpCodes[\"NotFound\"] = 404] = \"NotFound\";\n    HttpCodes[HttpCodes[\"MethodNotAllowed\"] = 405] = \"MethodNotAllowed\";\n    HttpCodes[HttpCodes[\"NotAcceptable\"] = 406] = \"NotAcceptable\";\n    HttpCodes[HttpCodes[\"ProxyAuthenticationRequired\"] = 407] = \"ProxyAuthenticationRequired\";\n    HttpCodes[HttpCodes[\"RequestTimeout\"] = 408] = \"RequestTimeout\";\n    HttpCodes[HttpCodes[\"Conflict\"] = 409] = \"Conflict\";\n    HttpCodes[HttpCodes[\"Gone\"] = 410] = \"Gone\";\n    HttpCodes[HttpCodes[\"TooManyRequests\"] = 429] = \"TooManyRequests\";\n    HttpCodes[HttpCodes[\"InternalServerError\"] = 500] = \"InternalServerError\";\n    HttpCodes[HttpCodes[\"NotImplemented\"] = 501] = \"NotImplemented\";\n    HttpCodes[HttpCodes[\"BadGateway\"] = 502] = \"BadGateway\";\n    HttpCodes[HttpCodes[\"ServiceUnavailable\"] = 503] = \"ServiceUnavailable\";\n    HttpCodes[HttpCodes[\"GatewayTimeout\"] = 504] = \"GatewayTimeout\";\n})(HttpCodes = exports.HttpCodes || (exports.HttpCodes = {}));\nvar Headers;\n(function (Headers) {\n    Headers[\"Accept\"] = \"accept\";\n    Headers[\"ContentType\"] = \"content-type\";\n})(Headers = exports.Headers || (exports.Headers = {}));\nvar MediaTypes;\n(function (MediaTypes) {\n    MediaTypes[\"ApplicationJson\"] = \"application/json\";\n})(MediaTypes = exports.MediaTypes || (exports.MediaTypes = {}));\n/**\n * Returns the proxy URL, depending upon the supplied url and proxy environment variables.\n * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n */\nfunction getProxyUrl(serverUrl) {\n    const proxyUrl = pm.getProxyUrl(new URL(serverUrl));\n    return proxyUrl ? proxyUrl.href : '';\n}\nexports.getProxyUrl = getProxyUrl;\nconst HttpRedirectCodes = [\n    HttpCodes.MovedPermanently,\n    HttpCodes.ResourceMoved,\n    HttpCodes.SeeOther,\n    HttpCodes.TemporaryRedirect,\n    HttpCodes.PermanentRedirect\n];\nconst HttpResponseRetryCodes = [\n    HttpCodes.BadGateway,\n    HttpCodes.ServiceUnavailable,\n    HttpCodes.GatewayTimeout\n];\nconst RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];\nconst ExponentialBackoffCeiling = 10;\nconst ExponentialBackoffTimeSlice = 5;\nclass HttpClientError extends Error {\n    constructor(message, statusCode) {\n        super(message);\n        this.name = 'HttpClientError';\n        this.statusCode = statusCode;\n        Object.setPrototypeOf(this, HttpClientError.prototype);\n    }\n}\nexports.HttpClientError = HttpClientError;\nclass HttpClientResponse {\n    constructor(message) {\n        this.message = message;\n    }\n    readBody() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n                let output = Buffer.alloc(0);\n                this.message.on('data', (chunk) => {\n                    output = Buffer.concat([output, chunk]);\n                });\n                this.message.on('end', () => {\n                    resolve(output.toString());\n                });\n            }));\n        });\n    }\n}\nexports.HttpClientResponse = HttpClientResponse;\nfunction isHttps(requestUrl) {\n    const parsedUrl = new URL(requestUrl);\n    return parsedUrl.protocol === 'https:';\n}\nexports.isHttps = isHttps;\nclass HttpClient {\n    constructor(userAgent, handlers, requestOptions) {\n        this._ignoreSslError = false;\n        this._allowRedirects = true;\n        this._allowRedirectDowngrade = false;\n        this._maxRedirects = 50;\n        this._allowRetries = false;\n        this._maxRetries = 1;\n        this._keepAlive = false;\n        this._disposed = false;\n        this.userAgent = userAgent;\n        this.handlers = handlers || [];\n        this.requestOptions = requestOptions;\n        if (requestOptions) {\n            if (requestOptions.ignoreSslError != null) {\n                this._ignoreSslError = requestOptions.ignoreSslError;\n            }\n            this._socketTimeout = requestOptions.socketTimeout;\n            if (requestOptions.allowRedirects != null) {\n                this._allowRedirects = requestOptions.allowRedirects;\n            }\n            if (requestOptions.allowRedirectDowngrade != null) {\n                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;\n            }\n            if (requestOptions.maxRedirects != null) {\n                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);\n            }\n            if (requestOptions.keepAlive != null) {\n                this._keepAlive = requestOptions.keepAlive;\n            }\n            if (requestOptions.allowRetries != null) {\n                this._allowRetries = requestOptions.allowRetries;\n            }\n            if (requestOptions.maxRetries != null) {\n                this._maxRetries = requestOptions.maxRetries;\n            }\n        }\n    }\n    options(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    get(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('GET', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    del(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('DELETE', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    post(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('POST', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    patch(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PATCH', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    put(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PUT', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    head(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('HEAD', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    sendStream(verb, requestUrl, stream, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request(verb, requestUrl, stream, additionalHeaders);\n        });\n    }\n    /**\n     * Gets a typed object from an endpoint\n     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise\n     */\n    getJson(requestUrl, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            const res = yield this.get(requestUrl, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    postJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.post(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    putJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.put(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    patchJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.patch(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    /**\n     * Makes a raw http request.\n     * All other methods such as get, post, patch, and request ultimately call this.\n     * Prefer get, del, post and patch\n     */\n    request(verb, requestUrl, data, headers) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._disposed) {\n                throw new Error('Client has already been disposed.');\n            }\n            const parsedUrl = new URL(requestUrl);\n            let info = this._prepareRequest(verb, parsedUrl, headers);\n            // Only perform retries on reads since writes may not be idempotent.\n            const maxTries = this._allowRetries && RetryableHttpVerbs.includes(verb)\n                ? this._maxRetries + 1\n                : 1;\n            let numTries = 0;\n            let response;\n            do {\n                response = yield this.requestRaw(info, data);\n                // Check if it's an authentication challenge\n                if (response &&\n                    response.message &&\n                    response.message.statusCode === HttpCodes.Unauthorized) {\n                    let authenticationHandler;\n                    for (const handler of this.handlers) {\n                        if (handler.canHandleAuthentication(response)) {\n                            authenticationHandler = handler;\n                            break;\n                        }\n                    }\n                    if (authenticationHandler) {\n                        return authenticationHandler.handleAuthentication(this, info, data);\n                    }\n                    else {\n                        // We have received an unauthorized response but have no handlers to handle it.\n                        // Let the response return to the caller.\n                        return response;\n                    }\n                }\n                let redirectsRemaining = this._maxRedirects;\n                while (response.message.statusCode &&\n                    HttpRedirectCodes.includes(response.message.statusCode) &&\n                    this._allowRedirects &&\n                    redirectsRemaining > 0) {\n                    const redirectUrl = response.message.headers['location'];\n                    if (!redirectUrl) {\n                        // if there's no location to redirect to, we won't\n                        break;\n                    }\n                    const parsedRedirectUrl = new URL(redirectUrl);\n                    if (parsedUrl.protocol === 'https:' &&\n                        parsedUrl.protocol !== parsedRedirectUrl.protocol &&\n                        !this._allowRedirectDowngrade) {\n                        throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');\n                    }\n                    // we need to finish reading the response before reassigning response\n                    // which will leak the open socket.\n                    yield response.readBody();\n                    // strip authorization header if redirected to a different hostname\n                    if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {\n                        for (const header in headers) {\n                            // header names are case insensitive\n                            if (header.toLowerCase() === 'authorization') {\n                                delete headers[header];\n                            }\n                        }\n                    }\n                    // let's make the request with the new redirectUrl\n                    info = this._prepareRequest(verb, parsedRedirectUrl, headers);\n                    response = yield this.requestRaw(info, data);\n                    redirectsRemaining--;\n                }\n                if (!response.message.statusCode ||\n                    !HttpResponseRetryCodes.includes(response.message.statusCode)) {\n                    // If not a retry code, return immediately instead of retrying\n                    return response;\n                }\n                numTries += 1;\n                if (numTries < maxTries) {\n                    yield response.readBody();\n                    yield this._performExponentialBackoff(numTries);\n                }\n            } while (numTries < maxTries);\n            return response;\n        });\n    }\n    /**\n     * Needs to be called if keepAlive is set to true in request options.\n     */\n    dispose() {\n        if (this._agent) {\n            this._agent.destroy();\n        }\n        this._disposed = true;\n    }\n    /**\n     * Raw request.\n     * @param info\n     * @param data\n     */\n    requestRaw(info, data) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => {\n                function callbackForResult(err, res) {\n                    if (err) {\n                        reject(err);\n                    }\n                    else if (!res) {\n                        // If `err` is not passed, then `res` must be passed.\n                        reject(new Error('Unknown error'));\n                    }\n                    else {\n                        resolve(res);\n                    }\n                }\n                this.requestRawWithCallback(info, data, callbackForResult);\n            });\n        });\n    }\n    /**\n     * Raw request with callback.\n     * @param info\n     * @param data\n     * @param onResult\n     */\n    requestRawWithCallback(info, data, onResult) {\n        if (typeof data === 'string') {\n            if (!info.options.headers) {\n                info.options.headers = {};\n            }\n            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');\n        }\n        let callbackCalled = false;\n        function handleResult(err, res) {\n            if (!callbackCalled) {\n                callbackCalled = true;\n                onResult(err, res);\n            }\n        }\n        const req = info.httpModule.request(info.options, (msg) => {\n            const res = new HttpClientResponse(msg);\n            handleResult(undefined, res);\n        });\n        let socket;\n        req.on('socket', sock => {\n            socket = sock;\n        });\n        // If we ever get disconnected, we want the socket to timeout eventually\n        req.setTimeout(this._socketTimeout || 3 * 60000, () => {\n            if (socket) {\n                socket.end();\n            }\n            handleResult(new Error(`Request timeout: ${info.options.path}`));\n        });\n        req.on('error', function (err) {\n            // err has statusCode property\n            // res should have headers\n            handleResult(err);\n        });\n        if (data && typeof data === 'string') {\n            req.write(data, 'utf8');\n        }\n        if (data && typeof data !== 'string') {\n            data.on('close', function () {\n                req.end();\n            });\n            data.pipe(req);\n        }\n        else {\n            req.end();\n        }\n    }\n    /**\n     * Gets an http agent. This function is useful when you need an http agent that handles\n     * routing through a proxy server - depending upon the url and proxy environment variables.\n     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n     */\n    getAgent(serverUrl) {\n        const parsedUrl = new URL(serverUrl);\n        return this._getAgent(parsedUrl);\n    }\n    _prepareRequest(method, requestUrl, headers) {\n        const info = {};\n        info.parsedUrl = requestUrl;\n        const usingSsl = info.parsedUrl.protocol === 'https:';\n        info.httpModule = usingSsl ? https : http;\n        const defaultPort = usingSsl ? 443 : 80;\n        info.options = {};\n        info.options.host = info.parsedUrl.hostname;\n        info.options.port = info.parsedUrl.port\n            ? parseInt(info.parsedUrl.port)\n            : defaultPort;\n        info.options.path =\n            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');\n        info.options.method = method;\n        info.options.headers = this._mergeHeaders(headers);\n        if (this.userAgent != null) {\n            info.options.headers['user-agent'] = this.userAgent;\n        }\n        info.options.agent = this._getAgent(info.parsedUrl);\n        // gives handlers an opportunity to participate\n        if (this.handlers) {\n            for (const handler of this.handlers) {\n                handler.prepareRequest(info.options);\n            }\n        }\n        return info;\n    }\n    _mergeHeaders(headers) {\n        if (this.requestOptions && this.requestOptions.headers) {\n            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers || {}));\n        }\n        return lowercaseKeys(headers || {});\n    }\n    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {\n        let clientHeader;\n        if (this.requestOptions && this.requestOptions.headers) {\n            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];\n        }\n        return additionalHeaders[header] || clientHeader || _default;\n    }\n    _getAgent(parsedUrl) {\n        let agent;\n        const proxyUrl = pm.getProxyUrl(parsedUrl);\n        const useProxy = proxyUrl && proxyUrl.hostname;\n        if (this._keepAlive && useProxy) {\n            agent = this._proxyAgent;\n        }\n        if (this._keepAlive && !useProxy) {\n            agent = this._agent;\n        }\n        // if agent is already assigned use that agent.\n        if (agent) {\n            return agent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        let maxSockets = 100;\n        if (this.requestOptions) {\n            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;\n        }\n        // This is `useProxy` again, but we need to check `proxyURl` directly for TypeScripts's flow analysis.\n        if (proxyUrl && proxyUrl.hostname) {\n            const agentOptions = {\n                maxSockets,\n                keepAlive: this._keepAlive,\n                proxy: Object.assign(Object.assign({}, ((proxyUrl.username || proxyUrl.password) && {\n                    proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`\n                })), { host: proxyUrl.hostname, port: proxyUrl.port })\n            };\n            let tunnelAgent;\n            const overHttps = proxyUrl.protocol === 'https:';\n            if (usingSsl) {\n                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;\n            }\n            else {\n                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;\n            }\n            agent = tunnelAgent(agentOptions);\n            this._proxyAgent = agent;\n        }\n        // if reusing agent across request and tunneling agent isn't assigned create a new agent\n        if (this._keepAlive && !agent) {\n            const options = { keepAlive: this._keepAlive, maxSockets };\n            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);\n            this._agent = agent;\n        }\n        // if not using private agent and tunnel agent isn't setup then use global agent\n        if (!agent) {\n            agent = usingSsl ? https.globalAgent : http.globalAgent;\n        }\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            agent.options = Object.assign(agent.options || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return agent;\n    }\n    _performExponentialBackoff(retryNumber) {\n        return __awaiter(this, void 0, void 0, function* () {\n            retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);\n            const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);\n            return new Promise(resolve => setTimeout(() => resolve(), ms));\n        });\n    }\n    _processResponse(res, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {\n                const statusCode = res.message.statusCode || 0;\n                const response = {\n                    statusCode,\n                    result: null,\n                    headers: {}\n                };\n                // not found leads to null obj returned\n                if (statusCode === HttpCodes.NotFound) {\n                    resolve(response);\n                }\n                // get the result from the body\n                function dateTimeDeserializer(key, value) {\n                    if (typeof value === 'string') {\n                        const a = new Date(value);\n                        if (!isNaN(a.valueOf())) {\n                            return a;\n                        }\n                    }\n                    return value;\n                }\n                let obj;\n                let contents;\n                try {\n                    contents = yield res.readBody();\n                    if (contents && contents.length > 0) {\n                        if (options && options.deserializeDates) {\n                            obj = JSON.parse(contents, dateTimeDeserializer);\n                        }\n                        else {\n                            obj = JSON.parse(contents);\n                        }\n                        response.result = obj;\n                    }\n                    response.headers = res.message.headers;\n                }\n                catch (err) {\n                    // Invalid resource (contents not json);  leaving result obj null\n                }\n                // note that 3xx redirects are handled by the http layer.\n                if (statusCode > 299) {\n                    let msg;\n                    // if exception/error in body, attempt to get better error\n                    if (obj && obj.message) {\n                        msg = obj.message;\n                    }\n                    else if (contents && contents.length > 0) {\n                        // it may be the case that the exception is in the body message as string\n                        msg = contents;\n                    }\n                    else {\n                        msg = `Failed request: (${statusCode})`;\n                    }\n                    const err = new HttpClientError(msg, statusCode);\n                    err.result = response.result;\n                    reject(err);\n                }\n                else {\n                    resolve(response);\n                }\n            }));\n        });\n    }\n}\nexports.HttpClient = HttpClient;\nconst lowercaseKeys = (obj) => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.checkBypass = exports.getProxyUrl = void 0;\nfunction getProxyUrl(reqUrl) {\n    const usingSsl = reqUrl.protocol === 'https:';\n    if (checkBypass(reqUrl)) {\n        return undefined;\n    }\n    const proxyVar = (() => {\n        if (usingSsl) {\n            return process.env['https_proxy'] || process.env['HTTPS_PROXY'];\n        }\n        else {\n            return process.env['http_proxy'] || process.env['HTTP_PROXY'];\n        }\n    })();\n    if (proxyVar) {\n        return new URL(proxyVar);\n    }\n    else {\n        return undefined;\n    }\n}\nexports.getProxyUrl = getProxyUrl;\nfunction checkBypass(reqUrl) {\n    if (!reqUrl.hostname) {\n        return false;\n    }\n    const noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';\n    if (!noProxy) {\n        return false;\n    }\n    // Determine the request port\n    let reqPort;\n    if (reqUrl.port) {\n        reqPort = Number(reqUrl.port);\n    }\n    else if (reqUrl.protocol === 'http:') {\n        reqPort = 80;\n    }\n    else if (reqUrl.protocol === 'https:') {\n        reqPort = 443;\n    }\n    // Format the request hostname and hostname with port\n    const upperReqHosts = [reqUrl.hostname.toUpperCase()];\n    if (typeof reqPort === 'number') {\n        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);\n    }\n    // Compare request host against noproxy\n    for (const upperNoProxyItem of noProxy\n        .split(',')\n        .map(x => x.trim().toUpperCase())\n        .filter(x => x)) {\n        if (upperReqHosts.some(x => x === upperNoProxyItem)) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkBypass = checkBypass;\n//# sourceMappingURL=proxy.js.map","(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"cronstrue\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"cronstrue\"] = factory();\n\telse\n\t\troot[\"cronstrue\"] = factory();\n})(globalThis, () => {\nreturn /******/ (() => { // webpackBootstrap\n/******/ \t\"use strict\";\n/******/ \tvar __webpack_modules__ = ({\n\n/***/ 794:\n/***/ ((__unused_webpack_module, exports, __webpack_require__) => {\n\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CronParser = void 0;\nvar rangeValidator_1 = __webpack_require__(586);\nvar CronParser = (function () {\n    function CronParser(expression, dayOfWeekStartIndexZero, monthStartIndexZero) {\n        if (dayOfWeekStartIndexZero === void 0) { dayOfWeekStartIndexZero = true; }\n        if (monthStartIndexZero === void 0) { monthStartIndexZero = false; }\n        this.expression = expression;\n        this.dayOfWeekStartIndexZero = dayOfWeekStartIndexZero;\n        this.monthStartIndexZero = monthStartIndexZero;\n    }\n    CronParser.prototype.parse = function () {\n        var parsed = this.extractParts(this.expression);\n        this.normalize(parsed);\n        this.validate(parsed);\n        return parsed;\n    };\n    CronParser.prototype.extractParts = function (expression) {\n        if (!this.expression) {\n            throw new Error(\"Expression is empty\");\n        }\n        var parsed = expression.trim().split(/[ ]+/);\n        if (parsed.length < 5) {\n            throw new Error(\"Expression has only \".concat(parsed.length, \" part\").concat(parsed.length == 1 ? \"\" : \"s\", \". At least 5 parts are required.\"));\n        }\n        else if (parsed.length == 5) {\n            parsed.unshift(\"\");\n            parsed.push(\"\");\n        }\n        else if (parsed.length == 6) {\n            var isYearWithNoSecondsPart = /\\d{4}$/.test(parsed[5]) || parsed[4] == \"?\" || parsed[2] == \"?\";\n            if (isYearWithNoSecondsPart) {\n                parsed.unshift(\"\");\n            }\n            else {\n                parsed.push(\"\");\n            }\n        }\n        else if (parsed.length > 7) {\n            throw new Error(\"Expression has \".concat(parsed.length, \" parts; too many!\"));\n        }\n        return parsed;\n    };\n    CronParser.prototype.normalize = function (expressionParts) {\n        var _this = this;\n        expressionParts[3] = expressionParts[3].replace(\"?\", \"*\");\n        expressionParts[5] = expressionParts[5].replace(\"?\", \"*\");\n        expressionParts[2] = expressionParts[2].replace(\"?\", \"*\");\n        if (expressionParts[0].indexOf(\"0/\") == 0) {\n            expressionParts[0] = expressionParts[0].replace(\"0/\", \"*/\");\n        }\n        if (expressionParts[1].indexOf(\"0/\") == 0) {\n            expressionParts[1] = expressionParts[1].replace(\"0/\", \"*/\");\n        }\n        if (expressionParts[2].indexOf(\"0/\") == 0) {\n            expressionParts[2] = expressionParts[2].replace(\"0/\", \"*/\");\n        }\n        if (expressionParts[3].indexOf(\"1/\") == 0) {\n            expressionParts[3] = expressionParts[3].replace(\"1/\", \"*/\");\n        }\n        if (expressionParts[4].indexOf(\"1/\") == 0) {\n            expressionParts[4] = expressionParts[4].replace(\"1/\", \"*/\");\n        }\n        if (expressionParts[6].indexOf(\"1/\") == 0) {\n            expressionParts[6] = expressionParts[6].replace(\"1/\", \"*/\");\n        }\n        expressionParts[5] = expressionParts[5].replace(/(^\\d)|([^#/\\s]\\d)/g, function (t) {\n            var dowDigits = t.replace(/\\D/, \"\");\n            var dowDigitsAdjusted = dowDigits;\n            if (_this.dayOfWeekStartIndexZero) {\n                if (dowDigits == \"7\") {\n                    dowDigitsAdjusted = \"0\";\n                }\n            }\n            else {\n                dowDigitsAdjusted = (parseInt(dowDigits) - 1).toString();\n            }\n            return t.replace(dowDigits, dowDigitsAdjusted);\n        });\n        if (expressionParts[5] == \"L\") {\n            expressionParts[5] = \"6\";\n        }\n        if (expressionParts[3] == \"?\") {\n            expressionParts[3] = \"*\";\n        }\n        if (expressionParts[3].indexOf(\"W\") > -1 &&\n            (expressionParts[3].indexOf(\",\") > -1 || expressionParts[3].indexOf(\"-\") > -1)) {\n            throw new Error(\"The 'W' character can be specified only when the day-of-month is a single day, not a range or list of days.\");\n        }\n        var days = {\n            SUN: 0,\n            MON: 1,\n            TUE: 2,\n            WED: 3,\n            THU: 4,\n            FRI: 5,\n            SAT: 6,\n        };\n        for (var day in days) {\n            expressionParts[5] = expressionParts[5].replace(new RegExp(day, \"gi\"), days[day].toString());\n        }\n        expressionParts[4] = expressionParts[4].replace(/(^\\d{1,2})|([^#/\\s]\\d{1,2})/g, function (t) {\n            var dowDigits = t.replace(/\\D/, \"\");\n            var dowDigitsAdjusted = dowDigits;\n            if (_this.monthStartIndexZero) {\n                dowDigitsAdjusted = (parseInt(dowDigits) + 1).toString();\n            }\n            return t.replace(dowDigits, dowDigitsAdjusted);\n        });\n        var months = {\n            JAN: 1,\n            FEB: 2,\n            MAR: 3,\n            APR: 4,\n            MAY: 5,\n            JUN: 6,\n            JUL: 7,\n            AUG: 8,\n            SEP: 9,\n            OCT: 10,\n            NOV: 11,\n            DEC: 12,\n        };\n        for (var month in months) {\n            expressionParts[4] = expressionParts[4].replace(new RegExp(month, \"gi\"), months[month].toString());\n        }\n        if (expressionParts[0] == \"0\") {\n            expressionParts[0] = \"\";\n        }\n        if (!/\\*|\\-|\\,|\\//.test(expressionParts[2]) &&\n            (/\\*|\\//.test(expressionParts[1]) || /\\*|\\//.test(expressionParts[0]))) {\n            expressionParts[2] += \"-\".concat(expressionParts[2]);\n        }\n        for (var i = 0; i < expressionParts.length; i++) {\n            if (expressionParts[i].indexOf(\",\") != -1) {\n                expressionParts[i] =\n                    expressionParts[i]\n                        .split(\",\")\n                        .filter(function (str) { return str !== \"\"; })\n                        .join(\",\") || \"*\";\n            }\n            if (expressionParts[i] == \"*/1\") {\n                expressionParts[i] = \"*\";\n            }\n            if (expressionParts[i].indexOf(\"/\") > -1 && !/^\\*|\\-|\\,/.test(expressionParts[i])) {\n                var stepRangeThrough = null;\n                switch (i) {\n                    case 4:\n                        stepRangeThrough = \"12\";\n                        break;\n                    case 5:\n                        stepRangeThrough = \"6\";\n                        break;\n                    case 6:\n                        stepRangeThrough = \"9999\";\n                        break;\n                    default:\n                        stepRangeThrough = null;\n                        break;\n                }\n                if (stepRangeThrough !== null) {\n                    var parts = expressionParts[i].split(\"/\");\n                    expressionParts[i] = \"\".concat(parts[0], \"-\").concat(stepRangeThrough, \"/\").concat(parts[1]);\n                }\n            }\n        }\n    };\n    CronParser.prototype.validate = function (parsed) {\n        this.assertNoInvalidCharacters(\"DOW\", parsed[5]);\n        this.assertNoInvalidCharacters(\"DOM\", parsed[3]);\n        this.validateRange(parsed);\n    };\n    CronParser.prototype.validateRange = function (parsed) {\n        rangeValidator_1.default.secondRange(parsed[0]);\n        rangeValidator_1.default.minuteRange(parsed[1]);\n        rangeValidator_1.default.hourRange(parsed[2]);\n        rangeValidator_1.default.dayOfMonthRange(parsed[3]);\n        rangeValidator_1.default.monthRange(parsed[4], this.monthStartIndexZero);\n        rangeValidator_1.default.dayOfWeekRange(parsed[5], this.dayOfWeekStartIndexZero);\n    };\n    CronParser.prototype.assertNoInvalidCharacters = function (partDescription, expression) {\n        var invalidChars = expression.match(/[A-KM-VX-Z]+/gi);\n        if (invalidChars && invalidChars.length) {\n            throw new Error(\"\".concat(partDescription, \" part contains invalid values: '\").concat(invalidChars.toString(), \"'\"));\n        }\n    };\n    return CronParser;\n}());\nexports.CronParser = CronParser;\n\n\n/***/ }),\n\n/***/ 728:\n/***/ ((__unused_webpack_module, exports, __webpack_require__) => {\n\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ExpressionDescriptor = void 0;\nvar stringUtilities_1 = __webpack_require__(910);\nvar cronParser_1 = __webpack_require__(794);\nvar ExpressionDescriptor = (function () {\n    function ExpressionDescriptor(expression, options) {\n        this.expression = expression;\n        this.options = options;\n        this.expressionParts = new Array(5);\n        if (!this.options.locale && ExpressionDescriptor.defaultLocale) {\n            this.options.locale = ExpressionDescriptor.defaultLocale;\n        }\n        if (!ExpressionDescriptor.locales[this.options.locale]) {\n            var fallBackLocale = Object.keys(ExpressionDescriptor.locales)[0];\n            console.warn(\"Locale '\".concat(this.options.locale, \"' could not be found; falling back to '\").concat(fallBackLocale, \"'.\"));\n            this.options.locale = fallBackLocale;\n        }\n        this.i18n = ExpressionDescriptor.locales[this.options.locale];\n        if (options.use24HourTimeFormat === undefined) {\n            options.use24HourTimeFormat = this.i18n.use24HourTimeFormatByDefault();\n        }\n    }\n    ExpressionDescriptor.toString = function (expression, _a) {\n        var _b = _a === void 0 ? {} : _a, _c = _b.throwExceptionOnParseError, throwExceptionOnParseError = _c === void 0 ? true : _c, _d = _b.verbose, verbose = _d === void 0 ? false : _d, _e = _b.dayOfWeekStartIndexZero, dayOfWeekStartIndexZero = _e === void 0 ? true : _e, _f = _b.monthStartIndexZero, monthStartIndexZero = _f === void 0 ? false : _f, use24HourTimeFormat = _b.use24HourTimeFormat, _g = _b.locale, locale = _g === void 0 ? null : _g, _h = _b.tzOffset, tzOffset = _h === void 0 ? 0 : _h;\n        var options = {\n            throwExceptionOnParseError: throwExceptionOnParseError,\n            verbose: verbose,\n            dayOfWeekStartIndexZero: dayOfWeekStartIndexZero,\n            monthStartIndexZero: monthStartIndexZero,\n            use24HourTimeFormat: use24HourTimeFormat,\n            locale: locale,\n            tzOffset: tzOffset\n        };\n        var descripter = new ExpressionDescriptor(expression, options);\n        return descripter.getFullDescription();\n    };\n    ExpressionDescriptor.initialize = function (localesLoader, defaultLocale) {\n        if (defaultLocale === void 0) { defaultLocale = \"en\"; }\n        ExpressionDescriptor.specialCharacters = [\"/\", \"-\", \",\", \"*\"];\n        ExpressionDescriptor.defaultLocale = defaultLocale;\n        localesLoader.load(ExpressionDescriptor.locales);\n    };\n    ExpressionDescriptor.prototype.getFullDescription = function () {\n        var description = \"\";\n        try {\n            var parser = new cronParser_1.CronParser(this.expression, this.options.dayOfWeekStartIndexZero, this.options.monthStartIndexZero);\n            this.expressionParts = parser.parse();\n            var timeSegment = this.getTimeOfDayDescription();\n            var dayOfMonthDesc = this.getDayOfMonthDescription();\n            var monthDesc = this.getMonthDescription();\n            var dayOfWeekDesc = this.getDayOfWeekDescription();\n            var yearDesc = this.getYearDescription();\n            description += timeSegment + dayOfMonthDesc + dayOfWeekDesc + monthDesc + yearDesc;\n            description = this.transformVerbosity(description, !!this.options.verbose);\n            description = description.charAt(0).toLocaleUpperCase() + description.substr(1);\n        }\n        catch (ex) {\n            if (!this.options.throwExceptionOnParseError) {\n                description = this.i18n.anErrorOccuredWhenGeneratingTheExpressionD();\n            }\n            else {\n                throw \"\".concat(ex);\n            }\n        }\n        return description;\n    };\n    ExpressionDescriptor.prototype.getTimeOfDayDescription = function () {\n        var secondsExpression = this.expressionParts[0];\n        var minuteExpression = this.expressionParts[1];\n        var hourExpression = this.expressionParts[2];\n        var description = \"\";\n        if (!stringUtilities_1.StringUtilities.containsAny(minuteExpression, ExpressionDescriptor.specialCharacters) &&\n            !stringUtilities_1.StringUtilities.containsAny(hourExpression, ExpressionDescriptor.specialCharacters) &&\n            !stringUtilities_1.StringUtilities.containsAny(secondsExpression, ExpressionDescriptor.specialCharacters)) {\n            description += this.i18n.atSpace() + this.formatTime(hourExpression, minuteExpression, secondsExpression);\n        }\n        else if (!secondsExpression &&\n            minuteExpression.indexOf(\"-\") > -1 &&\n            !(minuteExpression.indexOf(\",\") > -1) &&\n            !(minuteExpression.indexOf(\"/\") > -1) &&\n            !stringUtilities_1.StringUtilities.containsAny(hourExpression, ExpressionDescriptor.specialCharacters)) {\n            var minuteParts = minuteExpression.split(\"-\");\n            description += stringUtilities_1.StringUtilities.format(this.i18n.everyMinuteBetweenX0AndX1(), this.formatTime(hourExpression, minuteParts[0], \"\"), this.formatTime(hourExpression, minuteParts[1], \"\"));\n        }\n        else if (!secondsExpression &&\n            hourExpression.indexOf(\",\") > -1 &&\n            hourExpression.indexOf(\"-\") == -1 &&\n            hourExpression.indexOf(\"/\") == -1 &&\n            !stringUtilities_1.StringUtilities.containsAny(minuteExpression, ExpressionDescriptor.specialCharacters)) {\n            var hourParts = hourExpression.split(\",\");\n            description += this.i18n.at();\n            for (var i = 0; i < hourParts.length; i++) {\n                description += \" \";\n                description += this.formatTime(hourParts[i], minuteExpression, \"\");\n                if (i < hourParts.length - 2) {\n                    description += \",\";\n                }\n                if (i == hourParts.length - 2) {\n                    description += this.i18n.spaceAnd();\n                }\n            }\n        }\n        else {\n            var secondsDescription = this.getSecondsDescription();\n            var minutesDescription = this.getMinutesDescription();\n            var hoursDescription = this.getHoursDescription();\n            description += secondsDescription;\n            if (description && minutesDescription) {\n                description += \", \";\n            }\n            description += minutesDescription;\n            if (minutesDescription === hoursDescription) {\n                return description;\n            }\n            if (description && hoursDescription) {\n                description += \", \";\n            }\n            description += hoursDescription;\n        }\n        return description;\n    };\n    ExpressionDescriptor.prototype.getSecondsDescription = function () {\n        var _this = this;\n        var description = this.getSegmentDescription(this.expressionParts[0], this.i18n.everySecond(), function (s) {\n            return s;\n        }, function (s) {\n            return stringUtilities_1.StringUtilities.format(_this.i18n.everyX0Seconds(s), s);\n        }, function (s) {\n            return _this.i18n.secondsX0ThroughX1PastTheMinute();\n        }, function (s) {\n            return s == \"0\"\n                ? \"\"\n                : parseInt(s) < 20\n                    ? _this.i18n.atX0SecondsPastTheMinute(s)\n                    : _this.i18n.atX0SecondsPastTheMinuteGt20() || _this.i18n.atX0SecondsPastTheMinute(s);\n        });\n        return description;\n    };\n    ExpressionDescriptor.prototype.getMinutesDescription = function () {\n        var _this = this;\n        var secondsExpression = this.expressionParts[0];\n        var hourExpression = this.expressionParts[2];\n        var description = this.getSegmentDescription(this.expressionParts[1], this.i18n.everyMinute(), function (s) {\n            return s;\n        }, function (s) {\n            return stringUtilities_1.StringUtilities.format(_this.i18n.everyX0Minutes(s), s);\n        }, function (s) {\n            return _this.i18n.minutesX0ThroughX1PastTheHour();\n        }, function (s) {\n            try {\n                return s == \"0\" && hourExpression.indexOf(\"/\") == -1 && secondsExpression == \"\"\n                    ? _this.i18n.everyHour()\n                    : parseInt(s) < 20\n                        ? _this.i18n.atX0MinutesPastTheHour(s)\n                        : _this.i18n.atX0MinutesPastTheHourGt20() || _this.i18n.atX0MinutesPastTheHour(s);\n            }\n            catch (e) {\n                return _this.i18n.atX0MinutesPastTheHour(s);\n            }\n        });\n        return description;\n    };\n    ExpressionDescriptor.prototype.getHoursDescription = function () {\n        var _this = this;\n        var expression = this.expressionParts[2];\n        var description = this.getSegmentDescription(expression, this.i18n.everyHour(), function (s) {\n            return _this.formatTime(s, \"0\", \"\");\n        }, function (s) {\n            return stringUtilities_1.StringUtilities.format(_this.i18n.everyX0Hours(s), s);\n        }, function (s) {\n            return _this.i18n.betweenX0AndX1();\n        }, function (s) {\n            return _this.i18n.atX0();\n        });\n        if (description && expression.includes(\"-\") && this.expressionParts[1] != \"0\") {\n            var atTheHourMatches = Array.from(description.matchAll(/:00/g));\n            if (atTheHourMatches.length > 1) {\n                var lastAtTheHourMatchIndex = atTheHourMatches[atTheHourMatches.length - 1].index;\n                description =\n                    description.substring(0, lastAtTheHourMatchIndex) +\n                        \":59\" +\n                        description.substring(lastAtTheHourMatchIndex + 3);\n            }\n        }\n        return description;\n    };\n    ExpressionDescriptor.prototype.getDayOfWeekDescription = function () {\n        var _this = this;\n        var daysOfWeekNames = this.i18n.daysOfTheWeek();\n        var description = null;\n        if (this.expressionParts[5] == \"*\") {\n            description = \"\";\n        }\n        else {\n            description = this.getSegmentDescription(this.expressionParts[5], this.i18n.commaEveryDay(), function (s, form) {\n                var exp = s;\n                if (s.indexOf(\"#\") > -1) {\n                    exp = s.substring(0, s.indexOf(\"#\"));\n                }\n                else if (s.indexOf(\"L\") > -1) {\n                    exp = exp.replace(\"L\", \"\");\n                }\n                var description = _this.i18n.daysOfTheWeekInCase\n                    ? _this.i18n.daysOfTheWeekInCase(form)[parseInt(exp)]\n                    : daysOfWeekNames[parseInt(exp)];\n                if (s.indexOf(\"#\") > -1) {\n                    var dayOfWeekOfMonthDescription = null;\n                    var dayOfWeekOfMonthNumber = s.substring(s.indexOf(\"#\") + 1);\n                    var dayOfWeekNumber = s.substring(0, s.indexOf(\"#\"));\n                    switch (dayOfWeekOfMonthNumber) {\n                        case \"1\":\n                            dayOfWeekOfMonthDescription = _this.i18n.first(dayOfWeekNumber);\n                            break;\n                        case \"2\":\n                            dayOfWeekOfMonthDescription = _this.i18n.second(dayOfWeekNumber);\n                            break;\n                        case \"3\":\n                            dayOfWeekOfMonthDescription = _this.i18n.third(dayOfWeekNumber);\n                            break;\n                        case \"4\":\n                            dayOfWeekOfMonthDescription = _this.i18n.fourth(dayOfWeekNumber);\n                            break;\n                        case \"5\":\n                            dayOfWeekOfMonthDescription = _this.i18n.fifth(dayOfWeekNumber);\n                            break;\n                    }\n                    description = dayOfWeekOfMonthDescription + \" \" + description;\n                }\n                return description;\n            }, function (s) {\n                if (parseInt(s) == 1) {\n                    return \"\";\n                }\n                else {\n                    return stringUtilities_1.StringUtilities.format(_this.i18n.commaEveryX0DaysOfTheWeek(s), s);\n                }\n            }, function (s) {\n                var beginFrom = s.substring(0, s.indexOf(\"-\"));\n                var domSpecified = _this.expressionParts[3] != \"*\";\n                return domSpecified ? _this.i18n.commaAndX0ThroughX1(beginFrom) : _this.i18n.commaX0ThroughX1(beginFrom);\n            }, function (s) {\n                var format = null;\n                if (s.indexOf(\"#\") > -1) {\n                    var dayOfWeekOfMonthNumber = s.substring(s.indexOf(\"#\") + 1);\n                    format = _this.i18n.commaOnThe(dayOfWeekOfMonthNumber).trim() + _this.i18n.spaceX0OfTheMonth();\n                }\n                else if (s.indexOf(\"L\") > -1) {\n                    format = _this.i18n.commaOnTheLastX0OfTheMonth(s.replace(\"L\", \"\"));\n                }\n                else {\n                    var domSpecified = _this.expressionParts[3] != \"*\";\n                    format = domSpecified ? _this.i18n.commaAndOnX0() : _this.i18n.commaOnlyOnX0(s);\n                }\n                return format;\n            });\n        }\n        return description;\n    };\n    ExpressionDescriptor.prototype.getMonthDescription = function () {\n        var _this = this;\n        var monthNames = this.i18n.monthsOfTheYear();\n        var description = this.getSegmentDescription(this.expressionParts[4], \"\", function (s, form) {\n            return form && _this.i18n.monthsOfTheYearInCase\n                ? _this.i18n.monthsOfTheYearInCase(form)[parseInt(s) - 1]\n                : monthNames[parseInt(s) - 1];\n        }, function (s) {\n            if (parseInt(s) == 1) {\n                return \"\";\n            }\n            else {\n                return stringUtilities_1.StringUtilities.format(_this.i18n.commaEveryX0Months(s), s);\n            }\n        }, function (s) {\n            return _this.i18n.commaMonthX0ThroughMonthX1() || _this.i18n.commaX0ThroughX1();\n        }, function (s) {\n            return _this.i18n.commaOnlyInMonthX0 ? _this.i18n.commaOnlyInMonthX0() : _this.i18n.commaOnlyInX0();\n        });\n        return description;\n    };\n    ExpressionDescriptor.prototype.getDayOfMonthDescription = function () {\n        var _this = this;\n        var description = null;\n        var expression = this.expressionParts[3];\n        switch (expression) {\n            case \"L\":\n                description = this.i18n.commaOnTheLastDayOfTheMonth();\n                break;\n            case \"WL\":\n            case \"LW\":\n                description = this.i18n.commaOnTheLastWeekdayOfTheMonth();\n                break;\n            default:\n                var weekDayNumberMatches = expression.match(/(\\d{1,2}W)|(W\\d{1,2})/);\n                if (weekDayNumberMatches) {\n                    var dayNumber = parseInt(weekDayNumberMatches[0].replace(\"W\", \"\"));\n                    var dayString = dayNumber == 1\n                        ? this.i18n.firstWeekday()\n                        : stringUtilities_1.StringUtilities.format(this.i18n.weekdayNearestDayX0(), dayNumber.toString());\n                    description = stringUtilities_1.StringUtilities.format(this.i18n.commaOnTheX0OfTheMonth(), dayString);\n                    break;\n                }\n                else {\n                    var lastDayOffSetMatches = expression.match(/L-(\\d{1,2})/);\n                    if (lastDayOffSetMatches) {\n                        var offSetDays = lastDayOffSetMatches[1];\n                        description = stringUtilities_1.StringUtilities.format(this.i18n.commaDaysBeforeTheLastDayOfTheMonth(offSetDays), offSetDays);\n                        break;\n                    }\n                    else if (expression == \"*\" && this.expressionParts[5] != \"*\") {\n                        return \"\";\n                    }\n                    else {\n                        description = this.getSegmentDescription(expression, this.i18n.commaEveryDay(), function (s) {\n                            return s == \"L\"\n                                ? _this.i18n.lastDay()\n                                : _this.i18n.dayX0\n                                    ? stringUtilities_1.StringUtilities.format(_this.i18n.dayX0(), s)\n                                    : s;\n                        }, function (s) {\n                            return s == \"1\" ? _this.i18n.commaEveryDay() : _this.i18n.commaEveryX0Days(s);\n                        }, function (s) {\n                            return _this.i18n.commaBetweenDayX0AndX1OfTheMonth(s);\n                        }, function (s) {\n                            return _this.i18n.commaOnDayX0OfTheMonth(s);\n                        });\n                    }\n                    break;\n                }\n        }\n        return description;\n    };\n    ExpressionDescriptor.prototype.getYearDescription = function () {\n        var _this = this;\n        var description = this.getSegmentDescription(this.expressionParts[6], \"\", function (s) {\n            return /^\\d+$/.test(s) ? new Date(parseInt(s), 1).getFullYear().toString() : s;\n        }, function (s) {\n            return stringUtilities_1.StringUtilities.format(_this.i18n.commaEveryX0Years(s), s);\n        }, function (s) {\n            return _this.i18n.commaYearX0ThroughYearX1() || _this.i18n.commaX0ThroughX1();\n        }, function (s) {\n            return _this.i18n.commaOnlyInYearX0 ? _this.i18n.commaOnlyInYearX0() : _this.i18n.commaOnlyInX0();\n        });\n        return description;\n    };\n    ExpressionDescriptor.prototype.getSegmentDescription = function (expression, allDescription, getSingleItemDescription, getIncrementDescriptionFormat, getRangeDescriptionFormat, getDescriptionFormat) {\n        var description = null;\n        var doesExpressionContainIncrement = expression.indexOf(\"/\") > -1;\n        var doesExpressionContainRange = expression.indexOf(\"-\") > -1;\n        var doesExpressionContainMultipleValues = expression.indexOf(\",\") > -1;\n        if (!expression) {\n            description = \"\";\n        }\n        else if (expression === \"*\") {\n            description = allDescription;\n        }\n        else if (!doesExpressionContainIncrement && !doesExpressionContainRange && !doesExpressionContainMultipleValues) {\n            description = stringUtilities_1.StringUtilities.format(getDescriptionFormat(expression), getSingleItemDescription(expression));\n        }\n        else if (doesExpressionContainMultipleValues) {\n            var segments = expression.split(\",\");\n            var descriptionContent = \"\";\n            for (var i = 0; i < segments.length; i++) {\n                if (i > 0 && segments.length > 2) {\n                    descriptionContent += \",\";\n                    if (i < segments.length - 1) {\n                        descriptionContent += \" \";\n                    }\n                }\n                if (i > 0 && segments.length > 1 && (i == segments.length - 1 || segments.length == 2)) {\n                    descriptionContent += \"\".concat(this.i18n.spaceAnd(), \" \");\n                }\n                if (segments[i].indexOf(\"/\") > -1 || segments[i].indexOf(\"-\") > -1) {\n                    var isSegmentRangeWithoutIncrement = segments[i].indexOf(\"-\") > -1 && segments[i].indexOf(\"/\") == -1;\n                    var currentDescriptionContent = this.getSegmentDescription(segments[i], allDescription, getSingleItemDescription, getIncrementDescriptionFormat, isSegmentRangeWithoutIncrement ? this.i18n.commaX0ThroughX1 : getRangeDescriptionFormat, getDescriptionFormat);\n                    if (isSegmentRangeWithoutIncrement) {\n                        currentDescriptionContent = currentDescriptionContent.replace(\", \", \"\");\n                    }\n                    descriptionContent += currentDescriptionContent;\n                }\n                else if (!doesExpressionContainIncrement) {\n                    descriptionContent += getSingleItemDescription(segments[i]);\n                }\n                else {\n                    descriptionContent += this.getSegmentDescription(segments[i], allDescription, getSingleItemDescription, getIncrementDescriptionFormat, getRangeDescriptionFormat, getDescriptionFormat);\n                }\n            }\n            if (!doesExpressionContainIncrement) {\n                description = stringUtilities_1.StringUtilities.format(getDescriptionFormat(expression), descriptionContent);\n            }\n            else {\n                description = descriptionContent;\n            }\n        }\n        else if (doesExpressionContainIncrement) {\n            var segments = expression.split(\"/\");\n            description = stringUtilities_1.StringUtilities.format(getIncrementDescriptionFormat(segments[1]), segments[1]);\n            if (segments[0].indexOf(\"-\") > -1) {\n                var rangeSegmentDescription = this.generateRangeSegmentDescription(segments[0], getRangeDescriptionFormat, getSingleItemDescription);\n                if (rangeSegmentDescription.indexOf(\", \") != 0) {\n                    description += \", \";\n                }\n                description += rangeSegmentDescription;\n            }\n            else if (segments[0].indexOf(\"*\") == -1) {\n                var rangeItemDescription = stringUtilities_1.StringUtilities.format(getDescriptionFormat(segments[0]), getSingleItemDescription(segments[0]));\n                rangeItemDescription = rangeItemDescription.replace(\", \", \"\");\n                description += stringUtilities_1.StringUtilities.format(this.i18n.commaStartingX0(), rangeItemDescription);\n            }\n        }\n        else if (doesExpressionContainRange) {\n            description = this.generateRangeSegmentDescription(expression, getRangeDescriptionFormat, getSingleItemDescription);\n        }\n        return description;\n    };\n    ExpressionDescriptor.prototype.generateRangeSegmentDescription = function (rangeExpression, getRangeDescriptionFormat, getSingleItemDescription) {\n        var description = \"\";\n        var rangeSegments = rangeExpression.split(\"-\");\n        var rangeSegment1Description = getSingleItemDescription(rangeSegments[0], 1);\n        var rangeSegment2Description = getSingleItemDescription(rangeSegments[1], 2);\n        var rangeDescriptionFormat = getRangeDescriptionFormat(rangeExpression);\n        description += stringUtilities_1.StringUtilities.format(rangeDescriptionFormat, rangeSegment1Description, rangeSegment2Description);\n        return description;\n    };\n    ExpressionDescriptor.prototype.formatTime = function (hourExpression, minuteExpression, secondExpression) {\n        var hour = parseInt(hourExpression) + (this.options.tzOffset ? this.options.tzOffset : 0);\n        if (hour >= 24) {\n            hour = hour - 24;\n        }\n        else if (hour < 0) {\n            hour = 24 + hour;\n        }\n        var period = \"\";\n        var setPeriodBeforeTime = false;\n        if (!this.options.use24HourTimeFormat) {\n            setPeriodBeforeTime = !!(this.i18n.setPeriodBeforeTime && this.i18n.setPeriodBeforeTime());\n            period = setPeriodBeforeTime ? \"\".concat(this.getPeriod(hour), \" \") : \" \".concat(this.getPeriod(hour));\n            if (hour > 12) {\n                hour -= 12;\n            }\n            if (hour === 0) {\n                hour = 12;\n            }\n        }\n        var minute = minuteExpression;\n        var second = \"\";\n        if (secondExpression) {\n            second = \":\".concat((\"00\" + secondExpression).substring(secondExpression.length));\n        }\n        return \"\".concat(setPeriodBeforeTime ? period : \"\").concat((\"00\" + hour.toString()).substring(hour.toString().length), \":\").concat((\"00\" + minute.toString()).substring(minute.toString().length)).concat(second).concat(!setPeriodBeforeTime ? period : \"\");\n    };\n    ExpressionDescriptor.prototype.transformVerbosity = function (description, useVerboseFormat) {\n        if (!useVerboseFormat) {\n            description = description.replace(new RegExp(\", \".concat(this.i18n.everyMinute()), \"g\"), \"\");\n            description = description.replace(new RegExp(\", \".concat(this.i18n.everyHour()), \"g\"), \"\");\n            description = description.replace(new RegExp(this.i18n.commaEveryDay(), \"g\"), \"\");\n            description = description.replace(/\\, ?$/, \"\");\n        }\n        return description;\n    };\n    ExpressionDescriptor.prototype.getPeriod = function (hour) {\n        return hour >= 12 ? (this.i18n.pm && this.i18n.pm()) || \"PM\" : (this.i18n.am && this.i18n.am()) || \"AM\";\n    };\n    ExpressionDescriptor.locales = {};\n    return ExpressionDescriptor;\n}());\nexports.ExpressionDescriptor = ExpressionDescriptor;\n\n\n/***/ }),\n\n/***/ 336:\n/***/ ((__unused_webpack_module, exports, __webpack_require__) => {\n\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.enLocaleLoader = void 0;\nvar en_1 = __webpack_require__(751);\nvar enLocaleLoader = (function () {\n    function enLocaleLoader() {\n    }\n    enLocaleLoader.prototype.load = function (availableLocales) {\n        availableLocales[\"en\"] = new en_1.en();\n    };\n    return enLocaleLoader;\n}());\nexports.enLocaleLoader = enLocaleLoader;\n\n\n/***/ }),\n\n/***/ 751:\n/***/ ((__unused_webpack_module, exports) => {\n\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.en = void 0;\nvar en = (function () {\n    function en() {\n    }\n    en.prototype.atX0SecondsPastTheMinuteGt20 = function () {\n        return null;\n    };\n    en.prototype.atX0MinutesPastTheHourGt20 = function () {\n        return null;\n    };\n    en.prototype.commaMonthX0ThroughMonthX1 = function () {\n        return null;\n    };\n    en.prototype.commaYearX0ThroughYearX1 = function () {\n        return null;\n    };\n    en.prototype.use24HourTimeFormatByDefault = function () {\n        return false;\n    };\n    en.prototype.anErrorOccuredWhenGeneratingTheExpressionD = function () {\n        return \"An error occured when generating the expression description.  Check the cron expression syntax.\";\n    };\n    en.prototype.everyMinute = function () {\n        return \"every minute\";\n    };\n    en.prototype.everyHour = function () {\n        return \"every hour\";\n    };\n    en.prototype.atSpace = function () {\n        return \"At \";\n    };\n    en.prototype.everyMinuteBetweenX0AndX1 = function () {\n        return \"Every minute between %s and %s\";\n    };\n    en.prototype.at = function () {\n        return \"At\";\n    };\n    en.prototype.spaceAnd = function () {\n        return \" and\";\n    };\n    en.prototype.everySecond = function () {\n        return \"every second\";\n    };\n    en.prototype.everyX0Seconds = function () {\n        return \"every %s seconds\";\n    };\n    en.prototype.secondsX0ThroughX1PastTheMinute = function () {\n        return \"seconds %s through %s past the minute\";\n    };\n    en.prototype.atX0SecondsPastTheMinute = function () {\n        return \"at %s seconds past the minute\";\n    };\n    en.prototype.everyX0Minutes = function () {\n        return \"every %s minutes\";\n    };\n    en.prototype.minutesX0ThroughX1PastTheHour = function () {\n        return \"minutes %s through %s past the hour\";\n    };\n    en.prototype.atX0MinutesPastTheHour = function () {\n        return \"at %s minutes past the hour\";\n    };\n    en.prototype.everyX0Hours = function () {\n        return \"every %s hours\";\n    };\n    en.prototype.betweenX0AndX1 = function () {\n        return \"between %s and %s\";\n    };\n    en.prototype.atX0 = function () {\n        return \"at %s\";\n    };\n    en.prototype.commaEveryDay = function () {\n        return \", every day\";\n    };\n    en.prototype.commaEveryX0DaysOfTheWeek = function () {\n        return \", every %s days of the week\";\n    };\n    en.prototype.commaX0ThroughX1 = function () {\n        return \", %s through %s\";\n    };\n    en.prototype.commaAndX0ThroughX1 = function () {\n        return \", %s through %s\";\n    };\n    en.prototype.first = function () {\n        return \"first\";\n    };\n    en.prototype.second = function () {\n        return \"second\";\n    };\n    en.prototype.third = function () {\n        return \"third\";\n    };\n    en.prototype.fourth = function () {\n        return \"fourth\";\n    };\n    en.prototype.fifth = function () {\n        return \"fifth\";\n    };\n    en.prototype.commaOnThe = function () {\n        return \", on the \";\n    };\n    en.prototype.spaceX0OfTheMonth = function () {\n        return \" %s of the month\";\n    };\n    en.prototype.lastDay = function () {\n        return \"the last day\";\n    };\n    en.prototype.commaOnTheLastX0OfTheMonth = function () {\n        return \", on the last %s of the month\";\n    };\n    en.prototype.commaOnlyOnX0 = function () {\n        return \", only on %s\";\n    };\n    en.prototype.commaAndOnX0 = function () {\n        return \", and on %s\";\n    };\n    en.prototype.commaEveryX0Months = function () {\n        return \", every %s months\";\n    };\n    en.prototype.commaOnlyInX0 = function () {\n        return \", only in %s\";\n    };\n    en.prototype.commaOnTheLastDayOfTheMonth = function () {\n        return \", on the last day of the month\";\n    };\n    en.prototype.commaOnTheLastWeekdayOfTheMonth = function () {\n        return \", on the last weekday of the month\";\n    };\n    en.prototype.commaDaysBeforeTheLastDayOfTheMonth = function () {\n        return \", %s days before the last day of the month\";\n    };\n    en.prototype.firstWeekday = function () {\n        return \"first weekday\";\n    };\n    en.prototype.weekdayNearestDayX0 = function () {\n        return \"weekday nearest day %s\";\n    };\n    en.prototype.commaOnTheX0OfTheMonth = function () {\n        return \", on the %s of the month\";\n    };\n    en.prototype.commaEveryX0Days = function () {\n        return \", every %s days\";\n    };\n    en.prototype.commaBetweenDayX0AndX1OfTheMonth = function () {\n        return \", between day %s and %s of the month\";\n    };\n    en.prototype.commaOnDayX0OfTheMonth = function () {\n        return \", on day %s of the month\";\n    };\n    en.prototype.commaEveryHour = function () {\n        return \", every hour\";\n    };\n    en.prototype.commaEveryX0Years = function () {\n        return \", every %s years\";\n    };\n    en.prototype.commaStartingX0 = function () {\n        return \", starting %s\";\n    };\n    en.prototype.daysOfTheWeek = function () {\n        return [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"];\n    };\n    en.prototype.monthsOfTheYear = function () {\n        return [\n            \"January\",\n            \"February\",\n            \"March\",\n            \"April\",\n            \"May\",\n            \"June\",\n            \"July\",\n            \"August\",\n            \"September\",\n            \"October\",\n            \"November\",\n            \"December\",\n        ];\n    };\n    return en;\n}());\nexports.en = en;\n\n\n/***/ }),\n\n/***/ 586:\n/***/ ((__unused_webpack_module, exports) => {\n\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nfunction assert(value, message) {\n    if (!value) {\n        throw new Error(message);\n    }\n}\nvar RangeValidator = (function () {\n    function RangeValidator() {\n    }\n    RangeValidator.secondRange = function (parse) {\n        var parsed = parse.split(',');\n        for (var i = 0; i < parsed.length; i++) {\n            if (!isNaN(parseInt(parsed[i], 10))) {\n                var second = parseInt(parsed[i], 10);\n                assert(second >= 0 && second <= 59, 'seconds part must be >= 0 and <= 59');\n            }\n        }\n    };\n    RangeValidator.minuteRange = function (parse) {\n        var parsed = parse.split(',');\n        for (var i = 0; i < parsed.length; i++) {\n            if (!isNaN(parseInt(parsed[i], 10))) {\n                var minute = parseInt(parsed[i], 10);\n                assert(minute >= 0 && minute <= 59, 'minutes part must be >= 0 and <= 59');\n            }\n        }\n    };\n    RangeValidator.hourRange = function (parse) {\n        var parsed = parse.split(',');\n        for (var i = 0; i < parsed.length; i++) {\n            if (!isNaN(parseInt(parsed[i], 10))) {\n                var hour = parseInt(parsed[i], 10);\n                assert(hour >= 0 && hour <= 23, 'hours part must be >= 0 and <= 23');\n            }\n        }\n    };\n    RangeValidator.dayOfMonthRange = function (parse) {\n        var parsed = parse.split(',');\n        for (var i = 0; i < parsed.length; i++) {\n            if (!isNaN(parseInt(parsed[i], 10))) {\n                var dayOfMonth = parseInt(parsed[i], 10);\n                assert(dayOfMonth >= 1 && dayOfMonth <= 31, 'DOM part must be >= 1 and <= 31');\n            }\n        }\n    };\n    RangeValidator.monthRange = function (parse, monthStartIndexZero) {\n        var parsed = parse.split(',');\n        for (var i = 0; i < parsed.length; i++) {\n            if (!isNaN(parseInt(parsed[i], 10))) {\n                var month = parseInt(parsed[i], 10);\n                assert(month >= 1 && month <= 12, monthStartIndexZero ? 'month part must be >= 0 and <= 11' : 'month part must be >= 1 and <= 12');\n            }\n        }\n    };\n    RangeValidator.dayOfWeekRange = function (parse, dayOfWeekStartIndexZero) {\n        var parsed = parse.split(',');\n        for (var i = 0; i < parsed.length; i++) {\n            if (!isNaN(parseInt(parsed[i], 10))) {\n                var dayOfWeek = parseInt(parsed[i], 10);\n                assert(dayOfWeek >= 0 && dayOfWeek <= 6, dayOfWeekStartIndexZero ? 'DOW part must be >= 0 and <= 6' : 'DOW part must be >= 1 and <= 7');\n            }\n        }\n    };\n    return RangeValidator;\n}());\nexports[\"default\"] = RangeValidator;\n\n\n/***/ }),\n\n/***/ 910:\n/***/ ((__unused_webpack_module, exports) => {\n\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StringUtilities = void 0;\nvar StringUtilities = (function () {\n    function StringUtilities() {\n    }\n    StringUtilities.format = function (template) {\n        var values = [];\n        for (var _i = 1; _i < arguments.length; _i++) {\n            values[_i - 1] = arguments[_i];\n        }\n        return template.replace(/%s/g, function (substring) {\n            var args = [];\n            for (var _i = 1; _i < arguments.length; _i++) {\n                args[_i - 1] = arguments[_i];\n            }\n            return values.shift();\n        });\n    };\n    StringUtilities.containsAny = function (text, searchStrings) {\n        return searchStrings.some(function (c) {\n            return text.indexOf(c) > -1;\n        });\n    };\n    return StringUtilities;\n}());\nexports.StringUtilities = StringUtilities;\n\n\n/***/ })\n\n/******/ \t});\n/************************************************************************/\n/******/ \t// The module cache\n/******/ \tvar __webpack_module_cache__ = {};\n/******/ \t\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/ \t\t// Check if module is in cache\n/******/ \t\tvar cachedModule = __webpack_module_cache__[moduleId];\n/******/ \t\tif (cachedModule !== undefined) {\n/******/ \t\t\treturn cachedModule.exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = __webpack_module_cache__[moduleId] = {\n/******/ \t\t\t// no module.id needed\n/******/ \t\t\t// no module.loaded needed\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/ \t\n/******/ \t\t// Execute the module function\n/******/ \t\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n/******/ \t\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/ \t\n/************************************************************************/\nvar __webpack_exports__ = {};\n// This entry need to be wrapped in an IIFE because it need to be isolated against other modules in the chunk.\n(() => {\nvar exports = __webpack_exports__;\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.toString = void 0;\nvar expressionDescriptor_1 = __webpack_require__(728);\nvar enLocaleLoader_1 = __webpack_require__(336);\nexpressionDescriptor_1.ExpressionDescriptor.initialize(new enLocaleLoader_1.enLocaleLoader());\nexports[\"default\"] = expressionDescriptor_1.ExpressionDescriptor;\nvar toString = expressionDescriptor_1.ExpressionDescriptor.toString;\nexports.toString = toString;\n\n})();\n\n/******/ \treturn __webpack_exports__;\n/******/ })()\n;\n});","module.exports = require('./lib/tunnel');\n","'use strict';\n\nvar net = require('net');\nvar tls = require('tls');\nvar http = require('http');\nvar https = require('https');\nvar events = require('events');\nvar assert = require('assert');\nvar util = require('util');\n\n\nexports.httpOverHttp = httpOverHttp;\nexports.httpsOverHttp = httpsOverHttp;\nexports.httpOverHttps = httpOverHttps;\nexports.httpsOverHttps = httpsOverHttps;\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  return agent;\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  return agent;\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this;\n  self.options = options || {};\n  self.proxyOptions = self.options.proxy || {};\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;\n  self.requests = [];\n  self.sockets = [];\n\n  self.on('free', function onFree(socket, host, port, localAddress) {\n    var options = toOptions(host, port, localAddress);\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i];\n      if (pending.host === options.host && pending.port === options.port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1);\n        pending.request.onSocket(socket);\n        return;\n      }\n    }\n    socket.destroy();\n    self.removeSocket(socket);\n  });\n}\nutil.inherits(TunnelingAgent, events.EventEmitter);\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {\n  var self = this;\n  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push(options);\n    return;\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket(options, function(socket) {\n    socket.on('free', onFree);\n    socket.on('close', onCloseOrRemove);\n    socket.on('agentRemove', onCloseOrRemove);\n    req.onSocket(socket);\n\n    function onFree() {\n      self.emit('free', socket, options);\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket);\n      socket.removeListener('free', onFree);\n      socket.removeListener('close', onCloseOrRemove);\n      socket.removeListener('agentRemove', onCloseOrRemove);\n    }\n  });\n};\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this;\n  var placeholder = {};\n  self.sockets.push(placeholder);\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, {\n    method: 'CONNECT',\n    path: options.host + ':' + options.port,\n    agent: false,\n    headers: {\n      host: options.host + ':' + options.port\n    }\n  });\n  if (options.localAddress) {\n    connectOptions.localAddress = options.localAddress;\n  }\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {};\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64');\n  }\n\n  debug('making CONNECT request');\n  var connectReq = self.request(connectOptions);\n  connectReq.useChunkedEncodingByDefault = false; // for v0.6\n  connectReq.once('response', onResponse); // for v0.6\n  connectReq.once('upgrade', onUpgrade);   // for v0.6\n  connectReq.once('connect', onConnect);   // for v0.7 or later\n  connectReq.once('error', onError);\n  connectReq.end();\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true;\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head);\n    });\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners();\n    socket.removeAllListeners();\n\n    if (res.statusCode !== 200) {\n      debug('tunneling socket could not be established, statusCode=%d',\n        res.statusCode);\n      socket.destroy();\n      var error = new Error('tunneling socket could not be established, ' +\n        'statusCode=' + res.statusCode);\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    if (head.length > 0) {\n      debug('got illegal response body from proxy');\n      socket.destroy();\n      var error = new Error('got illegal response body from proxy');\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    debug('tunneling connection has established');\n    self.sockets[self.sockets.indexOf(placeholder)] = socket;\n    return cb(socket);\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners();\n\n    debug('tunneling socket could not be established, cause=%s\\n',\n          cause.message, cause.stack);\n    var error = new Error('tunneling socket could not be established, ' +\n                          'cause=' + cause.message);\n    error.code = 'ECONNRESET';\n    options.request.emit('error', error);\n    self.removeSocket(placeholder);\n  }\n};\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) {\n    return;\n  }\n  this.sockets.splice(pos, 1);\n\n  var pending = this.requests.shift();\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket);\n    });\n  }\n};\n\nfunction createSecureSocket(options, cb) {\n  var self = this;\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    var hostHeader = options.request.getHeader('host');\n    var tlsOptions = mergeOptions({}, self.options, {\n      socket: socket,\n      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host\n    });\n\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, tlsOptions);\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket;\n    cb(secureSocket);\n  });\n}\n\n\nfunction toOptions(host, port, localAddress) {\n  if (typeof host === 'string') { // since v0.10\n    return {\n      host: host,\n      port: port,\n      localAddress: localAddress\n    };\n  }\n  return host; // for v0.11 or later\n}\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i];\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides);\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j];\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k];\n        }\n      }\n    }\n  }\n  return target;\n}\n\n\nvar debug;\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments);\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0];\n    } else {\n      args.unshift('TUNNEL:');\n    }\n    console.error.apply(console, args);\n  }\n} else {\n  debug = function() {};\n}\nexports.debug = debug; // for test\n","export { default as v1 } from './v1.js';\nexport { default as v3 } from './v3.js';\nexport { default as v4 } from './v4.js';\nexport { default as v5 } from './v5.js';\nexport { default as NIL } from './nil.js';\nexport { default as version } from './version.js';\nexport { default as validate } from './validate.js';\nexport { default as stringify } from './stringify.js';\nexport { default as parse } from './parse.js';","import crypto from 'crypto';\n\nfunction md5(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n\n  return crypto.createHash('md5').update(bytes).digest();\n}\n\nexport default md5;","export default '00000000-0000-0000-0000-000000000000';","import validate from './validate.js';\n\nfunction parse(uuid) {\n  if (!validate(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  let v;\n  const arr = new Uint8Array(16); // Parse ########-....-....-....-............\n\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff; // Parse ........-####-....-....-............\n\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff; // Parse ........-....-####-....-............\n\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff; // Parse ........-....-....-####-............\n\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff; // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\n\nexport default parse;","export default /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;","import crypto from 'crypto';\nconst rnds8Pool = new Uint8Array(256); // # of random values to pre-allocate\n\nlet poolPtr = rnds8Pool.length;\nexport default function rng() {\n  if (poolPtr > rnds8Pool.length - 16) {\n    crypto.randomFillSync(rnds8Pool);\n    poolPtr = 0;\n  }\n\n  return rnds8Pool.slice(poolPtr, poolPtr += 16);\n}","import crypto from 'crypto';\n\nfunction sha1(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n\n  return crypto.createHash('sha1').update(bytes).digest();\n}\n\nexport default sha1;","import validate from './validate.js';\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nconst byteToHex = [];\n\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).substr(1));\n}\n\nfunction stringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  const uuid = (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase(); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!validate(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\nexport default stringify;","import rng from './rng.js';\nimport stringify from './stringify.js'; // **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nlet _nodeId;\n\nlet _clockseq; // Previous uuid creation time\n\n\nlet _lastMSecs = 0;\nlet _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details\n\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node || _nodeId;\n  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || rng)();\n\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n    }\n\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n\n\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)\n\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression\n\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n\n\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  } // Per 4.2.1.2 Throw error if too many uuids are requested\n\n\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n\n  msecs += 12219292800000; // `time_low`\n\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff; // `time_mid`\n\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff; // `time_high_and_version`\n\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n\n  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n\n  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`\n\n  b[i++] = clockseq & 0xff; // `node`\n\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf || stringify(b);\n}\n\nexport default v1;","import v35 from './v35.js';\nimport md5 from './md5.js';\nconst v3 = v35('v3', 0x30, md5);\nexport default v3;","import stringify from './stringify.js';\nimport parse from './parse.js';\n\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n\n  return bytes;\n}\n\nexport const DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nexport const URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nexport default function (name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n\n    if (typeof namespace === 'string') {\n      namespace = parse(namespace);\n    }\n\n    if (namespace.length !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    } // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n\n\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n\n    if (buf) {\n      offset = offset || 0;\n\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n\n      return buf;\n    }\n\n    return stringify(bytes);\n  } // Function#name is not settable on some platforms (#270)\n\n\n  try {\n    generateUUID.name = name; // eslint-disable-next-line no-empty\n  } catch (err) {} // For CommonJS default export support\n\n\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}","import rng from './rng.js';\nimport stringify from './stringify.js';\n\nfunction v4(options, buf, offset) {\n  options = options || {};\n  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return stringify(rnds);\n}\n\nexport default v4;","import v35 from './v35.js';\nimport sha1 from './sha1.js';\nconst v5 = v35('v5', 0x50, sha1);\nexport default v5;","import REGEX from './regex.js';\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && REGEX.test(uuid);\n}\n\nexport default validate;","import validate from './validate.js';\n\nfunction version(uuid) {\n  if (!validate(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  return parseInt(uuid.substr(14, 1), 16);\n}\n\nexport default version;","module.exports = require(\"assert\");","module.exports = require(\"crypto\");","module.exports = require(\"events\");","module.exports = require(\"fs\");","module.exports = require(\"http\");","module.exports = require(\"https\");","module.exports = require(\"net\");","module.exports = require(\"os\");","module.exports = require(\"path\");","module.exports = require(\"tls\");","module.exports = require(\"util\");","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\nvar YAMLMap = require('../nodes/YAMLMap.js');\nvar YAMLSeq = require('../nodes/YAMLSeq.js');\nvar resolveBlockMap = require('./resolve-block-map.js');\nvar resolveBlockSeq = require('./resolve-block-seq.js');\nvar resolveFlowCollection = require('./resolve-flow-collection.js');\n\nfunction resolveCollection(CN, ctx, token, onError, tagName, tag) {\n    const coll = token.type === 'block-map'\n        ? resolveBlockMap.resolveBlockMap(CN, ctx, token, onError, tag)\n        : token.type === 'block-seq'\n            ? resolveBlockSeq.resolveBlockSeq(CN, ctx, token, onError, tag)\n            : resolveFlowCollection.resolveFlowCollection(CN, ctx, token, onError, tag);\n    const Coll = coll.constructor;\n    // If we got a tagName matching the class, or the tag name is '!',\n    // then use the tagName from the node class used to create it.\n    if (tagName === '!' || tagName === Coll.tagName) {\n        coll.tag = Coll.tagName;\n        return coll;\n    }\n    if (tagName)\n        coll.tag = tagName;\n    return coll;\n}\nfunction composeCollection(CN, ctx, token, tagToken, onError) {\n    const tagName = !tagToken\n        ? null\n        : ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg));\n    const expType = token.type === 'block-map'\n        ? 'map'\n        : token.type === 'block-seq'\n            ? 'seq'\n            : token.start.source === '{'\n                ? 'map'\n                : 'seq';\n    // shortcut: check if it's a generic YAMLMap or YAMLSeq\n    // before jumping into the custom tag logic.\n    if (!tagToken ||\n        !tagName ||\n        tagName === '!' ||\n        (tagName === YAMLMap.YAMLMap.tagName && expType === 'map') ||\n        (tagName === YAMLSeq.YAMLSeq.tagName && expType === 'seq') ||\n        !expType) {\n        return resolveCollection(CN, ctx, token, onError, tagName);\n    }\n    let tag = ctx.schema.tags.find(t => t.tag === tagName && t.collection === expType);\n    if (!tag) {\n        const kt = ctx.schema.knownTags[tagName];\n        if (kt && kt.collection === expType) {\n            ctx.schema.tags.push(Object.assign({}, kt, { default: false }));\n            tag = kt;\n        }\n        else {\n            if (kt?.collection) {\n                onError(tagToken, 'BAD_COLLECTION_TYPE', `${kt.tag} used for ${expType} collection, but expects ${kt.collection}`, true);\n            }\n            else {\n                onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, true);\n            }\n            return resolveCollection(CN, ctx, token, onError, tagName);\n        }\n    }\n    const coll = resolveCollection(CN, ctx, token, onError, tagName, tag);\n    const res = tag.resolve?.(coll, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg), ctx.options) ?? coll;\n    const node = identity.isNode(res)\n        ? res\n        : new Scalar.Scalar(res);\n    node.range = coll.range;\n    node.tag = tagName;\n    if (tag?.format)\n        node.format = tag.format;\n    return node;\n}\n\nexports.composeCollection = composeCollection;\n","'use strict';\n\nvar Document = require('../doc/Document.js');\nvar composeNode = require('./compose-node.js');\nvar resolveEnd = require('./resolve-end.js');\nvar resolveProps = require('./resolve-props.js');\n\nfunction composeDoc(options, directives, { offset, start, value, end }, onError) {\n    const opts = Object.assign({ _directives: directives }, options);\n    const doc = new Document.Document(undefined, opts);\n    const ctx = {\n        atRoot: true,\n        directives: doc.directives,\n        options: doc.options,\n        schema: doc.schema\n    };\n    const props = resolveProps.resolveProps(start, {\n        indicator: 'doc-start',\n        next: value ?? end?.[0],\n        offset,\n        onError,\n        startOnNewline: true\n    });\n    if (props.found) {\n        doc.directives.docStart = true;\n        if (value &&\n            (value.type === 'block-map' || value.type === 'block-seq') &&\n            !props.hasNewline)\n            onError(props.end, 'MISSING_CHAR', 'Block collection cannot start on same line with directives-end marker');\n    }\n    // @ts-expect-error If Contents is set, let's trust the user\n    doc.contents = value\n        ? composeNode.composeNode(ctx, value, props, onError)\n        : composeNode.composeEmptyNode(ctx, props.end, start, null, props, onError);\n    const contentEnd = doc.contents.range[2];\n    const re = resolveEnd.resolveEnd(end, contentEnd, false, onError);\n    if (re.comment)\n        doc.comment = re.comment;\n    doc.range = [offset, contentEnd, re.offset];\n    return doc;\n}\n\nexports.composeDoc = composeDoc;\n","'use strict';\n\nvar Alias = require('../nodes/Alias.js');\nvar composeCollection = require('./compose-collection.js');\nvar composeScalar = require('./compose-scalar.js');\nvar resolveEnd = require('./resolve-end.js');\nvar utilEmptyScalarPosition = require('./util-empty-scalar-position.js');\n\nconst CN = { composeNode, composeEmptyNode };\nfunction composeNode(ctx, token, props, onError) {\n    const { spaceBefore, comment, anchor, tag } = props;\n    let node;\n    let isSrcToken = true;\n    switch (token.type) {\n        case 'alias':\n            node = composeAlias(ctx, token, onError);\n            if (anchor || tag)\n                onError(token, 'ALIAS_PROPS', 'An alias node must not specify any properties');\n            break;\n        case 'scalar':\n        case 'single-quoted-scalar':\n        case 'double-quoted-scalar':\n        case 'block-scalar':\n            node = composeScalar.composeScalar(ctx, token, tag, onError);\n            if (anchor)\n                node.anchor = anchor.source.substring(1);\n            break;\n        case 'block-map':\n        case 'block-seq':\n        case 'flow-collection':\n            node = composeCollection.composeCollection(CN, ctx, token, tag, onError);\n            if (anchor)\n                node.anchor = anchor.source.substring(1);\n            break;\n        default: {\n            const message = token.type === 'error'\n                ? token.message\n                : `Unsupported token (type: ${token.type})`;\n            onError(token, 'UNEXPECTED_TOKEN', message);\n            node = composeEmptyNode(ctx, token.offset, undefined, null, props, onError);\n            isSrcToken = false;\n        }\n    }\n    if (anchor && node.anchor === '')\n        onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');\n    if (spaceBefore)\n        node.spaceBefore = true;\n    if (comment) {\n        if (token.type === 'scalar' && token.source === '')\n            node.comment = comment;\n        else\n            node.commentBefore = comment;\n    }\n    // @ts-expect-error Type checking misses meaning of isSrcToken\n    if (ctx.options.keepSourceTokens && isSrcToken)\n        node.srcToken = token;\n    return node;\n}\nfunction composeEmptyNode(ctx, offset, before, pos, { spaceBefore, comment, anchor, tag, end }, onError) {\n    const token = {\n        type: 'scalar',\n        offset: utilEmptyScalarPosition.emptyScalarPosition(offset, before, pos),\n        indent: -1,\n        source: ''\n    };\n    const node = composeScalar.composeScalar(ctx, token, tag, onError);\n    if (anchor) {\n        node.anchor = anchor.source.substring(1);\n        if (node.anchor === '')\n            onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');\n    }\n    if (spaceBefore)\n        node.spaceBefore = true;\n    if (comment) {\n        node.comment = comment;\n        node.range[2] = end;\n    }\n    return node;\n}\nfunction composeAlias({ options }, { offset, source, end }, onError) {\n    const alias = new Alias.Alias(source.substring(1));\n    if (alias.source === '')\n        onError(offset, 'BAD_ALIAS', 'Alias cannot be an empty string');\n    if (alias.source.endsWith(':'))\n        onError(offset + source.length - 1, 'BAD_ALIAS', 'Alias ending in : is ambiguous', true);\n    const valueEnd = offset + source.length;\n    const re = resolveEnd.resolveEnd(end, valueEnd, options.strict, onError);\n    alias.range = [offset, valueEnd, re.offset];\n    if (re.comment)\n        alias.comment = re.comment;\n    return alias;\n}\n\nexports.composeEmptyNode = composeEmptyNode;\nexports.composeNode = composeNode;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\nvar resolveBlockScalar = require('./resolve-block-scalar.js');\nvar resolveFlowScalar = require('./resolve-flow-scalar.js');\n\nfunction composeScalar(ctx, token, tagToken, onError) {\n    const { value, type, comment, range } = token.type === 'block-scalar'\n        ? resolveBlockScalar.resolveBlockScalar(token, ctx.options.strict, onError)\n        : resolveFlowScalar.resolveFlowScalar(token, ctx.options.strict, onError);\n    const tagName = tagToken\n        ? ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg))\n        : null;\n    const tag = tagToken && tagName\n        ? findScalarTagByName(ctx.schema, value, tagName, tagToken, onError)\n        : token.type === 'scalar'\n            ? findScalarTagByTest(ctx, value, token, onError)\n            : ctx.schema[identity.SCALAR];\n    let scalar;\n    try {\n        const res = tag.resolve(value, msg => onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg), ctx.options);\n        scalar = identity.isScalar(res) ? res : new Scalar.Scalar(res);\n    }\n    catch (error) {\n        const msg = error instanceof Error ? error.message : String(error);\n        onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg);\n        scalar = new Scalar.Scalar(value);\n    }\n    scalar.range = range;\n    scalar.source = value;\n    if (type)\n        scalar.type = type;\n    if (tagName)\n        scalar.tag = tagName;\n    if (tag.format)\n        scalar.format = tag.format;\n    if (comment)\n        scalar.comment = comment;\n    return scalar;\n}\nfunction findScalarTagByName(schema, value, tagName, tagToken, onError) {\n    if (tagName === '!')\n        return schema[identity.SCALAR]; // non-specific tag\n    const matchWithTest = [];\n    for (const tag of schema.tags) {\n        if (!tag.collection && tag.tag === tagName) {\n            if (tag.default && tag.test)\n                matchWithTest.push(tag);\n            else\n                return tag;\n        }\n    }\n    for (const tag of matchWithTest)\n        if (tag.test?.test(value))\n            return tag;\n    const kt = schema.knownTags[tagName];\n    if (kt && !kt.collection) {\n        // Ensure that the known tag is available for stringifying,\n        // but does not get used by default.\n        schema.tags.push(Object.assign({}, kt, { default: false, test: undefined }));\n        return kt;\n    }\n    onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, tagName !== 'tag:yaml.org,2002:str');\n    return schema[identity.SCALAR];\n}\nfunction findScalarTagByTest({ directives, schema }, value, token, onError) {\n    const tag = schema.tags.find(tag => tag.default && tag.test?.test(value)) || schema[identity.SCALAR];\n    if (schema.compat) {\n        const compat = schema.compat.find(tag => tag.default && tag.test?.test(value)) ??\n            schema[identity.SCALAR];\n        if (tag.tag !== compat.tag) {\n            const ts = directives.tagString(tag.tag);\n            const cs = directives.tagString(compat.tag);\n            const msg = `Value may be parsed as either ${ts} or ${cs}`;\n            onError(token, 'TAG_RESOLVE_FAILED', msg, true);\n        }\n    }\n    return tag;\n}\n\nexports.composeScalar = composeScalar;\n","'use strict';\n\nvar directives = require('../doc/directives.js');\nvar Document = require('../doc/Document.js');\nvar errors = require('../errors.js');\nvar identity = require('../nodes/identity.js');\nvar composeDoc = require('./compose-doc.js');\nvar resolveEnd = require('./resolve-end.js');\n\nfunction getErrorPos(src) {\n    if (typeof src === 'number')\n        return [src, src + 1];\n    if (Array.isArray(src))\n        return src.length === 2 ? src : [src[0], src[1]];\n    const { offset, source } = src;\n    return [offset, offset + (typeof source === 'string' ? source.length : 1)];\n}\nfunction parsePrelude(prelude) {\n    let comment = '';\n    let atComment = false;\n    let afterEmptyLine = false;\n    for (let i = 0; i < prelude.length; ++i) {\n        const source = prelude[i];\n        switch (source[0]) {\n            case '#':\n                comment +=\n                    (comment === '' ? '' : afterEmptyLine ? '\\n\\n' : '\\n') +\n                        (source.substring(1) || ' ');\n                atComment = true;\n                afterEmptyLine = false;\n                break;\n            case '%':\n                if (prelude[i + 1]?.[0] !== '#')\n                    i += 1;\n                atComment = false;\n                break;\n            default:\n                // This may be wrong after doc-end, but in that case it doesn't matter\n                if (!atComment)\n                    afterEmptyLine = true;\n                atComment = false;\n        }\n    }\n    return { comment, afterEmptyLine };\n}\n/**\n * Compose a stream of CST nodes into a stream of YAML Documents.\n *\n * ```ts\n * import { Composer, Parser } from 'yaml'\n *\n * const src: string = ...\n * const tokens = new Parser().parse(src)\n * const docs = new Composer().compose(tokens)\n * ```\n */\nclass Composer {\n    constructor(options = {}) {\n        this.doc = null;\n        this.atDirectives = false;\n        this.prelude = [];\n        this.errors = [];\n        this.warnings = [];\n        this.onError = (source, code, message, warning) => {\n            const pos = getErrorPos(source);\n            if (warning)\n                this.warnings.push(new errors.YAMLWarning(pos, code, message));\n            else\n                this.errors.push(new errors.YAMLParseError(pos, code, message));\n        };\n        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n        this.directives = new directives.Directives({ version: options.version || '1.2' });\n        this.options = options;\n    }\n    decorate(doc, afterDoc) {\n        const { comment, afterEmptyLine } = parsePrelude(this.prelude);\n        //console.log({ dc: doc.comment, prelude, comment })\n        if (comment) {\n            const dc = doc.contents;\n            if (afterDoc) {\n                doc.comment = doc.comment ? `${doc.comment}\\n${comment}` : comment;\n            }\n            else if (afterEmptyLine || doc.directives.docStart || !dc) {\n                doc.commentBefore = comment;\n            }\n            else if (identity.isCollection(dc) && !dc.flow && dc.items.length > 0) {\n                let it = dc.items[0];\n                if (identity.isPair(it))\n                    it = it.key;\n                const cb = it.commentBefore;\n                it.commentBefore = cb ? `${comment}\\n${cb}` : comment;\n            }\n            else {\n                const cb = dc.commentBefore;\n                dc.commentBefore = cb ? `${comment}\\n${cb}` : comment;\n            }\n        }\n        if (afterDoc) {\n            Array.prototype.push.apply(doc.errors, this.errors);\n            Array.prototype.push.apply(doc.warnings, this.warnings);\n        }\n        else {\n            doc.errors = this.errors;\n            doc.warnings = this.warnings;\n        }\n        this.prelude = [];\n        this.errors = [];\n        this.warnings = [];\n    }\n    /**\n     * Current stream status information.\n     *\n     * Mostly useful at the end of input for an empty stream.\n     */\n    streamInfo() {\n        return {\n            comment: parsePrelude(this.prelude).comment,\n            directives: this.directives,\n            errors: this.errors,\n            warnings: this.warnings\n        };\n    }\n    /**\n     * Compose tokens into documents.\n     *\n     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.\n     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.\n     */\n    *compose(tokens, forceDoc = false, endOffset = -1) {\n        for (const token of tokens)\n            yield* this.next(token);\n        yield* this.end(forceDoc, endOffset);\n    }\n    /** Advance the composer by one CST token. */\n    *next(token) {\n        if (process.env.LOG_STREAM)\n            console.dir(token, { depth: null });\n        switch (token.type) {\n            case 'directive':\n                this.directives.add(token.source, (offset, message, warning) => {\n                    const pos = getErrorPos(token);\n                    pos[0] += offset;\n                    this.onError(pos, 'BAD_DIRECTIVE', message, warning);\n                });\n                this.prelude.push(token.source);\n                this.atDirectives = true;\n                break;\n            case 'document': {\n                const doc = composeDoc.composeDoc(this.options, this.directives, token, this.onError);\n                if (this.atDirectives && !doc.directives.docStart)\n                    this.onError(token, 'MISSING_CHAR', 'Missing directives-end/doc-start indicator line');\n                this.decorate(doc, false);\n                if (this.doc)\n                    yield this.doc;\n                this.doc = doc;\n                this.atDirectives = false;\n                break;\n            }\n            case 'byte-order-mark':\n            case 'space':\n                break;\n            case 'comment':\n            case 'newline':\n                this.prelude.push(token.source);\n                break;\n            case 'error': {\n                const msg = token.source\n                    ? `${token.message}: ${JSON.stringify(token.source)}`\n                    : token.message;\n                const error = new errors.YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg);\n                if (this.atDirectives || !this.doc)\n                    this.errors.push(error);\n                else\n                    this.doc.errors.push(error);\n                break;\n            }\n            case 'doc-end': {\n                if (!this.doc) {\n                    const msg = 'Unexpected doc-end without preceding document';\n                    this.errors.push(new errors.YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg));\n                    break;\n                }\n                this.doc.directives.docEnd = true;\n                const end = resolveEnd.resolveEnd(token.end, token.offset + token.source.length, this.doc.options.strict, this.onError);\n                this.decorate(this.doc, true);\n                if (end.comment) {\n                    const dc = this.doc.comment;\n                    this.doc.comment = dc ? `${dc}\\n${end.comment}` : end.comment;\n                }\n                this.doc.range[2] = end.offset;\n                break;\n            }\n            default:\n                this.errors.push(new errors.YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', `Unsupported token ${token.type}`));\n        }\n    }\n    /**\n     * Call at end of input to yield any remaining document.\n     *\n     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.\n     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.\n     */\n    *end(forceDoc = false, endOffset = -1) {\n        if (this.doc) {\n            this.decorate(this.doc, true);\n            yield this.doc;\n            this.doc = null;\n        }\n        else if (forceDoc) {\n            const opts = Object.assign({ _directives: this.directives }, this.options);\n            const doc = new Document.Document(undefined, opts);\n            if (this.atDirectives)\n                this.onError(endOffset, 'MISSING_CHAR', 'Missing directives-end indicator line');\n            doc.range = [0, endOffset, endOffset];\n            this.decorate(doc, false);\n            yield doc;\n        }\n    }\n}\n\nexports.Composer = Composer;\n","'use strict';\n\nvar Pair = require('../nodes/Pair.js');\nvar YAMLMap = require('../nodes/YAMLMap.js');\nvar resolveProps = require('./resolve-props.js');\nvar utilContainsNewline = require('./util-contains-newline.js');\nvar utilFlowIndentCheck = require('./util-flow-indent-check.js');\nvar utilMapIncludes = require('./util-map-includes.js');\n\nconst startColMsg = 'All mapping items must start at the same column';\nfunction resolveBlockMap({ composeNode, composeEmptyNode }, ctx, bm, onError, tag) {\n    const NodeClass = tag?.nodeClass ?? YAMLMap.YAMLMap;\n    const map = new NodeClass(ctx.schema);\n    if (ctx.atRoot)\n        ctx.atRoot = false;\n    let offset = bm.offset;\n    let commentEnd = null;\n    for (const collItem of bm.items) {\n        const { start, key, sep, value } = collItem;\n        // key properties\n        const keyProps = resolveProps.resolveProps(start, {\n            indicator: 'explicit-key-ind',\n            next: key ?? sep?.[0],\n            offset,\n            onError,\n            startOnNewline: true\n        });\n        const implicitKey = !keyProps.found;\n        if (implicitKey) {\n            if (key) {\n                if (key.type === 'block-seq')\n                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'A block sequence may not be used as an implicit map key');\n                else if ('indent' in key && key.indent !== bm.indent)\n                    onError(offset, 'BAD_INDENT', startColMsg);\n            }\n            if (!keyProps.anchor && !keyProps.tag && !sep) {\n                commentEnd = keyProps.end;\n                if (keyProps.comment) {\n                    if (map.comment)\n                        map.comment += '\\n' + keyProps.comment;\n                    else\n                        map.comment = keyProps.comment;\n                }\n                continue;\n            }\n            if (keyProps.hasNewlineAfterProp || utilContainsNewline.containsNewline(key)) {\n                onError(key ?? start[start.length - 1], 'MULTILINE_IMPLICIT_KEY', 'Implicit keys need to be on a single line');\n            }\n        }\n        else if (keyProps.found?.indent !== bm.indent) {\n            onError(offset, 'BAD_INDENT', startColMsg);\n        }\n        // key value\n        const keyStart = keyProps.end;\n        const keyNode = key\n            ? composeNode(ctx, key, keyProps, onError)\n            : composeEmptyNode(ctx, keyStart, start, null, keyProps, onError);\n        if (ctx.schema.compat)\n            utilFlowIndentCheck.flowIndentCheck(bm.indent, key, onError);\n        if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode))\n            onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');\n        // value properties\n        const valueProps = resolveProps.resolveProps(sep ?? [], {\n            indicator: 'map-value-ind',\n            next: value,\n            offset: keyNode.range[2],\n            onError,\n            startOnNewline: !key || key.type === 'block-scalar'\n        });\n        offset = valueProps.end;\n        if (valueProps.found) {\n            if (implicitKey) {\n                if (value?.type === 'block-map' && !valueProps.hasNewline)\n                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'Nested mappings are not allowed in compact mappings');\n                if (ctx.options.strict &&\n                    keyProps.start < valueProps.found.offset - 1024)\n                    onError(keyNode.range, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit block mapping key');\n            }\n            // value value\n            const valueNode = value\n                ? composeNode(ctx, value, valueProps, onError)\n                : composeEmptyNode(ctx, offset, sep, null, valueProps, onError);\n            if (ctx.schema.compat)\n                utilFlowIndentCheck.flowIndentCheck(bm.indent, value, onError);\n            offset = valueNode.range[2];\n            const pair = new Pair.Pair(keyNode, valueNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            map.items.push(pair);\n        }\n        else {\n            // key with no value\n            if (implicitKey)\n                onError(keyNode.range, 'MISSING_CHAR', 'Implicit map keys need to be followed by map values');\n            if (valueProps.comment) {\n                if (keyNode.comment)\n                    keyNode.comment += '\\n' + valueProps.comment;\n                else\n                    keyNode.comment = valueProps.comment;\n            }\n            const pair = new Pair.Pair(keyNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            map.items.push(pair);\n        }\n    }\n    if (commentEnd && commentEnd < offset)\n        onError(commentEnd, 'IMPOSSIBLE', 'Map comment with trailing content');\n    map.range = [bm.offset, offset, commentEnd ?? offset];\n    return map;\n}\n\nexports.resolveBlockMap = resolveBlockMap;\n","'use strict';\n\nvar Scalar = require('../nodes/Scalar.js');\n\nfunction resolveBlockScalar(scalar, strict, onError) {\n    const start = scalar.offset;\n    const header = parseBlockScalarHeader(scalar, strict, onError);\n    if (!header)\n        return { value: '', type: null, comment: '', range: [start, start, start] };\n    const type = header.mode === '>' ? Scalar.Scalar.BLOCK_FOLDED : Scalar.Scalar.BLOCK_LITERAL;\n    const lines = scalar.source ? splitLines(scalar.source) : [];\n    // determine the end of content & start of chomping\n    let chompStart = lines.length;\n    for (let i = lines.length - 1; i >= 0; --i) {\n        const content = lines[i][1];\n        if (content === '' || content === '\\r')\n            chompStart = i;\n        else\n            break;\n    }\n    // shortcut for empty contents\n    if (chompStart === 0) {\n        const value = header.chomp === '+' && lines.length > 0\n            ? '\\n'.repeat(Math.max(1, lines.length - 1))\n            : '';\n        let end = start + header.length;\n        if (scalar.source)\n            end += scalar.source.length;\n        return { value, type, comment: header.comment, range: [start, end, end] };\n    }\n    // find the indentation level to trim from start\n    let trimIndent = scalar.indent + header.indent;\n    let offset = scalar.offset + header.length;\n    let contentStart = 0;\n    for (let i = 0; i < chompStart; ++i) {\n        const [indent, content] = lines[i];\n        if (content === '' || content === '\\r') {\n            if (header.indent === 0 && indent.length > trimIndent)\n                trimIndent = indent.length;\n        }\n        else {\n            if (indent.length < trimIndent) {\n                const message = 'Block scalars with more-indented leading empty lines must use an explicit indentation indicator';\n                onError(offset + indent.length, 'MISSING_CHAR', message);\n            }\n            if (header.indent === 0)\n                trimIndent = indent.length;\n            contentStart = i;\n            break;\n        }\n        offset += indent.length + content.length + 1;\n    }\n    // include trailing more-indented empty lines in content\n    for (let i = lines.length - 1; i >= chompStart; --i) {\n        if (lines[i][0].length > trimIndent)\n            chompStart = i + 1;\n    }\n    let value = '';\n    let sep = '';\n    let prevMoreIndented = false;\n    // leading whitespace is kept intact\n    for (let i = 0; i < contentStart; ++i)\n        value += lines[i][0].slice(trimIndent) + '\\n';\n    for (let i = contentStart; i < chompStart; ++i) {\n        let [indent, content] = lines[i];\n        offset += indent.length + content.length + 1;\n        const crlf = content[content.length - 1] === '\\r';\n        if (crlf)\n            content = content.slice(0, -1);\n        /* istanbul ignore if already caught in lexer */\n        if (content && indent.length < trimIndent) {\n            const src = header.indent\n                ? 'explicit indentation indicator'\n                : 'first line';\n            const message = `Block scalar lines must not be less indented than their ${src}`;\n            onError(offset - content.length - (crlf ? 2 : 1), 'BAD_INDENT', message);\n            indent = '';\n        }\n        if (type === Scalar.Scalar.BLOCK_LITERAL) {\n            value += sep + indent.slice(trimIndent) + content;\n            sep = '\\n';\n        }\n        else if (indent.length > trimIndent || content[0] === '\\t') {\n            // more-indented content within a folded block\n            if (sep === ' ')\n                sep = '\\n';\n            else if (!prevMoreIndented && sep === '\\n')\n                sep = '\\n\\n';\n            value += sep + indent.slice(trimIndent) + content;\n            sep = '\\n';\n            prevMoreIndented = true;\n        }\n        else if (content === '') {\n            // empty line\n            if (sep === '\\n')\n                value += '\\n';\n            else\n                sep = '\\n';\n        }\n        else {\n            value += sep + content;\n            sep = ' ';\n            prevMoreIndented = false;\n        }\n    }\n    switch (header.chomp) {\n        case '-':\n            break;\n        case '+':\n            for (let i = chompStart; i < lines.length; ++i)\n                value += '\\n' + lines[i][0].slice(trimIndent);\n            if (value[value.length - 1] !== '\\n')\n                value += '\\n';\n            break;\n        default:\n            value += '\\n';\n    }\n    const end = start + header.length + scalar.source.length;\n    return { value, type, comment: header.comment, range: [start, end, end] };\n}\nfunction parseBlockScalarHeader({ offset, props }, strict, onError) {\n    /* istanbul ignore if should not happen */\n    if (props[0].type !== 'block-scalar-header') {\n        onError(props[0], 'IMPOSSIBLE', 'Block scalar header not found');\n        return null;\n    }\n    const { source } = props[0];\n    const mode = source[0];\n    let indent = 0;\n    let chomp = '';\n    let error = -1;\n    for (let i = 1; i < source.length; ++i) {\n        const ch = source[i];\n        if (!chomp && (ch === '-' || ch === '+'))\n            chomp = ch;\n        else {\n            const n = Number(ch);\n            if (!indent && n)\n                indent = n;\n            else if (error === -1)\n                error = offset + i;\n        }\n    }\n    if (error !== -1)\n        onError(error, 'UNEXPECTED_TOKEN', `Block scalar header includes extra characters: ${source}`);\n    let hasSpace = false;\n    let comment = '';\n    let length = source.length;\n    for (let i = 1; i < props.length; ++i) {\n        const token = props[i];\n        switch (token.type) {\n            case 'space':\n                hasSpace = true;\n            // fallthrough\n            case 'newline':\n                length += token.source.length;\n                break;\n            case 'comment':\n                if (strict && !hasSpace) {\n                    const message = 'Comments must be separated from other tokens by white space characters';\n                    onError(token, 'MISSING_CHAR', message);\n                }\n                length += token.source.length;\n                comment = token.source.substring(1);\n                break;\n            case 'error':\n                onError(token, 'UNEXPECTED_TOKEN', token.message);\n                length += token.source.length;\n                break;\n            /* istanbul ignore next should not happen */\n            default: {\n                const message = `Unexpected token in block scalar header: ${token.type}`;\n                onError(token, 'UNEXPECTED_TOKEN', message);\n                const ts = token.source;\n                if (ts && typeof ts === 'string')\n                    length += ts.length;\n            }\n        }\n    }\n    return { mode, indent, chomp, comment, length };\n}\n/** @returns Array of lines split up as `[indent, content]` */\nfunction splitLines(source) {\n    const split = source.split(/\\n( *)/);\n    const first = split[0];\n    const m = first.match(/^( *)/);\n    const line0 = m?.[1]\n        ? [m[1], first.slice(m[1].length)]\n        : ['', first];\n    const lines = [line0];\n    for (let i = 1; i < split.length; i += 2)\n        lines.push([split[i], split[i + 1]]);\n    return lines;\n}\n\nexports.resolveBlockScalar = resolveBlockScalar;\n","'use strict';\n\nvar YAMLSeq = require('../nodes/YAMLSeq.js');\nvar resolveProps = require('./resolve-props.js');\nvar utilFlowIndentCheck = require('./util-flow-indent-check.js');\n\nfunction resolveBlockSeq({ composeNode, composeEmptyNode }, ctx, bs, onError, tag) {\n    const NodeClass = tag?.nodeClass ?? YAMLSeq.YAMLSeq;\n    const seq = new NodeClass(ctx.schema);\n    if (ctx.atRoot)\n        ctx.atRoot = false;\n    let offset = bs.offset;\n    let commentEnd = null;\n    for (const { start, value } of bs.items) {\n        const props = resolveProps.resolveProps(start, {\n            indicator: 'seq-item-ind',\n            next: value,\n            offset,\n            onError,\n            startOnNewline: true\n        });\n        if (!props.found) {\n            if (props.anchor || props.tag || value) {\n                if (value && value.type === 'block-seq')\n                    onError(props.end, 'BAD_INDENT', 'All sequence items must start at the same column');\n                else\n                    onError(offset, 'MISSING_CHAR', 'Sequence item without - indicator');\n            }\n            else {\n                commentEnd = props.end;\n                if (props.comment)\n                    seq.comment = props.comment;\n                continue;\n            }\n        }\n        const node = value\n            ? composeNode(ctx, value, props, onError)\n            : composeEmptyNode(ctx, props.end, start, null, props, onError);\n        if (ctx.schema.compat)\n            utilFlowIndentCheck.flowIndentCheck(bs.indent, value, onError);\n        offset = node.range[2];\n        seq.items.push(node);\n    }\n    seq.range = [bs.offset, offset, commentEnd ?? offset];\n    return seq;\n}\n\nexports.resolveBlockSeq = resolveBlockSeq;\n","'use strict';\n\nfunction resolveEnd(end, offset, reqSpace, onError) {\n    let comment = '';\n    if (end) {\n        let hasSpace = false;\n        let sep = '';\n        for (const token of end) {\n            const { source, type } = token;\n            switch (type) {\n                case 'space':\n                    hasSpace = true;\n                    break;\n                case 'comment': {\n                    if (reqSpace && !hasSpace)\n                        onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');\n                    const cb = source.substring(1) || ' ';\n                    if (!comment)\n                        comment = cb;\n                    else\n                        comment += sep + cb;\n                    sep = '';\n                    break;\n                }\n                case 'newline':\n                    if (comment)\n                        sep += source;\n                    hasSpace = true;\n                    break;\n                default:\n                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${type} at node end`);\n            }\n            offset += source.length;\n        }\n    }\n    return { comment, offset };\n}\n\nexports.resolveEnd = resolveEnd;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Pair = require('../nodes/Pair.js');\nvar YAMLMap = require('../nodes/YAMLMap.js');\nvar YAMLSeq = require('../nodes/YAMLSeq.js');\nvar resolveEnd = require('./resolve-end.js');\nvar resolveProps = require('./resolve-props.js');\nvar utilContainsNewline = require('./util-contains-newline.js');\nvar utilMapIncludes = require('./util-map-includes.js');\n\nconst blockMsg = 'Block collections are not allowed within flow collections';\nconst isBlock = (token) => token && (token.type === 'block-map' || token.type === 'block-seq');\nfunction resolveFlowCollection({ composeNode, composeEmptyNode }, ctx, fc, onError, tag) {\n    const isMap = fc.start.source === '{';\n    const fcName = isMap ? 'flow map' : 'flow sequence';\n    const NodeClass = (tag?.nodeClass ?? (isMap ? YAMLMap.YAMLMap : YAMLSeq.YAMLSeq));\n    const coll = new NodeClass(ctx.schema);\n    coll.flow = true;\n    const atRoot = ctx.atRoot;\n    if (atRoot)\n        ctx.atRoot = false;\n    let offset = fc.offset + fc.start.source.length;\n    for (let i = 0; i < fc.items.length; ++i) {\n        const collItem = fc.items[i];\n        const { start, key, sep, value } = collItem;\n        const props = resolveProps.resolveProps(start, {\n            flow: fcName,\n            indicator: 'explicit-key-ind',\n            next: key ?? sep?.[0],\n            offset,\n            onError,\n            startOnNewline: false\n        });\n        if (!props.found) {\n            if (!props.anchor && !props.tag && !sep && !value) {\n                if (i === 0 && props.comma)\n                    onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);\n                else if (i < fc.items.length - 1)\n                    onError(props.start, 'UNEXPECTED_TOKEN', `Unexpected empty item in ${fcName}`);\n                if (props.comment) {\n                    if (coll.comment)\n                        coll.comment += '\\n' + props.comment;\n                    else\n                        coll.comment = props.comment;\n                }\n                offset = props.end;\n                continue;\n            }\n            if (!isMap && ctx.options.strict && utilContainsNewline.containsNewline(key))\n                onError(key, // checked by containsNewline()\n                'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');\n        }\n        if (i === 0) {\n            if (props.comma)\n                onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);\n        }\n        else {\n            if (!props.comma)\n                onError(props.start, 'MISSING_CHAR', `Missing , between ${fcName} items`);\n            if (props.comment) {\n                let prevItemComment = '';\n                loop: for (const st of start) {\n                    switch (st.type) {\n                        case 'comma':\n                        case 'space':\n                            break;\n                        case 'comment':\n                            prevItemComment = st.source.substring(1);\n                            break loop;\n                        default:\n                            break loop;\n                    }\n                }\n                if (prevItemComment) {\n                    let prev = coll.items[coll.items.length - 1];\n                    if (identity.isPair(prev))\n                        prev = prev.value ?? prev.key;\n                    if (prev.comment)\n                        prev.comment += '\\n' + prevItemComment;\n                    else\n                        prev.comment = prevItemComment;\n                    props.comment = props.comment.substring(prevItemComment.length + 1);\n                }\n            }\n        }\n        if (!isMap && !sep && !props.found) {\n            // item is a value in a seq\n            //  key & sep are empty, start does not include ? or :\n            const valueNode = value\n                ? composeNode(ctx, value, props, onError)\n                : composeEmptyNode(ctx, props.end, sep, null, props, onError);\n            coll.items.push(valueNode);\n            offset = valueNode.range[2];\n            if (isBlock(value))\n                onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);\n        }\n        else {\n            // item is a key+value pair\n            // key value\n            const keyStart = props.end;\n            const keyNode = key\n                ? composeNode(ctx, key, props, onError)\n                : composeEmptyNode(ctx, keyStart, start, null, props, onError);\n            if (isBlock(key))\n                onError(keyNode.range, 'BLOCK_IN_FLOW', blockMsg);\n            // value properties\n            const valueProps = resolveProps.resolveProps(sep ?? [], {\n                flow: fcName,\n                indicator: 'map-value-ind',\n                next: value,\n                offset: keyNode.range[2],\n                onError,\n                startOnNewline: false\n            });\n            if (valueProps.found) {\n                if (!isMap && !props.found && ctx.options.strict) {\n                    if (sep)\n                        for (const st of sep) {\n                            if (st === valueProps.found)\n                                break;\n                            if (st.type === 'newline') {\n                                onError(st, 'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');\n                                break;\n                            }\n                        }\n                    if (props.start < valueProps.found.offset - 1024)\n                        onError(valueProps.found, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit flow sequence key');\n                }\n            }\n            else if (value) {\n                if ('source' in value && value.source && value.source[0] === ':')\n                    onError(value, 'MISSING_CHAR', `Missing space after : in ${fcName}`);\n                else\n                    onError(valueProps.start, 'MISSING_CHAR', `Missing , or : between ${fcName} items`);\n            }\n            // value value\n            const valueNode = value\n                ? composeNode(ctx, value, valueProps, onError)\n                : valueProps.found\n                    ? composeEmptyNode(ctx, valueProps.end, sep, null, valueProps, onError)\n                    : null;\n            if (valueNode) {\n                if (isBlock(value))\n                    onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);\n            }\n            else if (valueProps.comment) {\n                if (keyNode.comment)\n                    keyNode.comment += '\\n' + valueProps.comment;\n                else\n                    keyNode.comment = valueProps.comment;\n            }\n            const pair = new Pair.Pair(keyNode, valueNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            if (isMap) {\n                const map = coll;\n                if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode))\n                    onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');\n                map.items.push(pair);\n            }\n            else {\n                const map = new YAMLMap.YAMLMap(ctx.schema);\n                map.flow = true;\n                map.items.push(pair);\n                coll.items.push(map);\n            }\n            offset = valueNode ? valueNode.range[2] : valueProps.end;\n        }\n    }\n    const expectedEnd = isMap ? '}' : ']';\n    const [ce, ...ee] = fc.end;\n    let cePos = offset;\n    if (ce && ce.source === expectedEnd)\n        cePos = ce.offset + ce.source.length;\n    else {\n        const name = fcName[0].toUpperCase() + fcName.substring(1);\n        const msg = atRoot\n            ? `${name} must end with a ${expectedEnd}`\n            : `${name} in block collection must be sufficiently indented and end with a ${expectedEnd}`;\n        onError(offset, atRoot ? 'MISSING_CHAR' : 'BAD_INDENT', msg);\n        if (ce && ce.source.length !== 1)\n            ee.unshift(ce);\n    }\n    if (ee.length > 0) {\n        const end = resolveEnd.resolveEnd(ee, cePos, ctx.options.strict, onError);\n        if (end.comment) {\n            if (coll.comment)\n                coll.comment += '\\n' + end.comment;\n            else\n                coll.comment = end.comment;\n        }\n        coll.range = [fc.offset, cePos, end.offset];\n    }\n    else {\n        coll.range = [fc.offset, cePos, cePos];\n    }\n    return coll;\n}\n\nexports.resolveFlowCollection = resolveFlowCollection;\n","'use strict';\n\nvar Scalar = require('../nodes/Scalar.js');\nvar resolveEnd = require('./resolve-end.js');\n\nfunction resolveFlowScalar(scalar, strict, onError) {\n    const { offset, type, source, end } = scalar;\n    let _type;\n    let value;\n    const _onError = (rel, code, msg) => onError(offset + rel, code, msg);\n    switch (type) {\n        case 'scalar':\n            _type = Scalar.Scalar.PLAIN;\n            value = plainValue(source, _onError);\n            break;\n        case 'single-quoted-scalar':\n            _type = Scalar.Scalar.QUOTE_SINGLE;\n            value = singleQuotedValue(source, _onError);\n            break;\n        case 'double-quoted-scalar':\n            _type = Scalar.Scalar.QUOTE_DOUBLE;\n            value = doubleQuotedValue(source, _onError);\n            break;\n        /* istanbul ignore next should not happen */\n        default:\n            onError(scalar, 'UNEXPECTED_TOKEN', `Expected a flow scalar value, but found: ${type}`);\n            return {\n                value: '',\n                type: null,\n                comment: '',\n                range: [offset, offset + source.length, offset + source.length]\n            };\n    }\n    const valueEnd = offset + source.length;\n    const re = resolveEnd.resolveEnd(end, valueEnd, strict, onError);\n    return {\n        value,\n        type: _type,\n        comment: re.comment,\n        range: [offset, valueEnd, re.offset]\n    };\n}\nfunction plainValue(source, onError) {\n    let badChar = '';\n    switch (source[0]) {\n        /* istanbul ignore next should not happen */\n        case '\\t':\n            badChar = 'a tab character';\n            break;\n        case ',':\n            badChar = 'flow indicator character ,';\n            break;\n        case '%':\n            badChar = 'directive indicator character %';\n            break;\n        case '|':\n        case '>': {\n            badChar = `block scalar indicator ${source[0]}`;\n            break;\n        }\n        case '@':\n        case '`': {\n            badChar = `reserved character ${source[0]}`;\n            break;\n        }\n    }\n    if (badChar)\n        onError(0, 'BAD_SCALAR_START', `Plain value cannot start with ${badChar}`);\n    return foldLines(source);\n}\nfunction singleQuotedValue(source, onError) {\n    if (source[source.length - 1] !== \"'\" || source.length === 1)\n        onError(source.length, 'MISSING_CHAR', \"Missing closing 'quote\");\n    return foldLines(source.slice(1, -1)).replace(/''/g, \"'\");\n}\nfunction foldLines(source) {\n    /**\n     * The negative lookbehind here and in the `re` RegExp is to\n     * prevent causing a polynomial search time in certain cases.\n     *\n     * The try-catch is for Safari, which doesn't support this yet:\n     * https://caniuse.com/js-regexp-lookbehind\n     */\n    let first, line;\n    try {\n        first = new RegExp('(.*?)(?<![ \\t])[ \\t]*\\r?\\n', 'sy');\n        line = new RegExp('[ \\t]*(.*?)(?:(?<![ \\t])[ \\t]*)?\\r?\\n', 'sy');\n    }\n    catch (_) {\n        first = /(.*?)[ \\t]*\\r?\\n/sy;\n        line = /[ \\t]*(.*?)[ \\t]*\\r?\\n/sy;\n    }\n    let match = first.exec(source);\n    if (!match)\n        return source;\n    let res = match[1];\n    let sep = ' ';\n    let pos = first.lastIndex;\n    line.lastIndex = pos;\n    while ((match = line.exec(source))) {\n        if (match[1] === '') {\n            if (sep === '\\n')\n                res += sep;\n            else\n                sep = '\\n';\n        }\n        else {\n            res += sep + match[1];\n            sep = ' ';\n        }\n        pos = line.lastIndex;\n    }\n    const last = /[ \\t]*(.*)/sy;\n    last.lastIndex = pos;\n    match = last.exec(source);\n    return res + sep + (match?.[1] ?? '');\n}\nfunction doubleQuotedValue(source, onError) {\n    let res = '';\n    for (let i = 1; i < source.length - 1; ++i) {\n        const ch = source[i];\n        if (ch === '\\r' && source[i + 1] === '\\n')\n            continue;\n        if (ch === '\\n') {\n            const { fold, offset } = foldNewline(source, i);\n            res += fold;\n            i = offset;\n        }\n        else if (ch === '\\\\') {\n            let next = source[++i];\n            const cc = escapeCodes[next];\n            if (cc)\n                res += cc;\n            else if (next === '\\n') {\n                // skip escaped newlines, but still trim the following line\n                next = source[i + 1];\n                while (next === ' ' || next === '\\t')\n                    next = source[++i + 1];\n            }\n            else if (next === '\\r' && source[i + 1] === '\\n') {\n                // skip escaped CRLF newlines, but still trim the following line\n                next = source[++i + 1];\n                while (next === ' ' || next === '\\t')\n                    next = source[++i + 1];\n            }\n            else if (next === 'x' || next === 'u' || next === 'U') {\n                const length = { x: 2, u: 4, U: 8 }[next];\n                res += parseCharCode(source, i + 1, length, onError);\n                i += length;\n            }\n            else {\n                const raw = source.substr(i - 1, 2);\n                onError(i - 1, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);\n                res += raw;\n            }\n        }\n        else if (ch === ' ' || ch === '\\t') {\n            // trim trailing whitespace\n            const wsStart = i;\n            let next = source[i + 1];\n            while (next === ' ' || next === '\\t')\n                next = source[++i + 1];\n            if (next !== '\\n' && !(next === '\\r' && source[i + 2] === '\\n'))\n                res += i > wsStart ? source.slice(wsStart, i + 1) : ch;\n        }\n        else {\n            res += ch;\n        }\n    }\n    if (source[source.length - 1] !== '\"' || source.length === 1)\n        onError(source.length, 'MISSING_CHAR', 'Missing closing \"quote');\n    return res;\n}\n/**\n * Fold a single newline into a space, multiple newlines to N - 1 newlines.\n * Presumes `source[offset] === '\\n'`\n */\nfunction foldNewline(source, offset) {\n    let fold = '';\n    let ch = source[offset + 1];\n    while (ch === ' ' || ch === '\\t' || ch === '\\n' || ch === '\\r') {\n        if (ch === '\\r' && source[offset + 2] !== '\\n')\n            break;\n        if (ch === '\\n')\n            fold += '\\n';\n        offset += 1;\n        ch = source[offset + 1];\n    }\n    if (!fold)\n        fold = ' ';\n    return { fold, offset };\n}\nconst escapeCodes = {\n    '0': '\\0',\n    a: '\\x07',\n    b: '\\b',\n    e: '\\x1b',\n    f: '\\f',\n    n: '\\n',\n    r: '\\r',\n    t: '\\t',\n    v: '\\v',\n    N: '\\u0085',\n    _: '\\u00a0',\n    L: '\\u2028',\n    P: '\\u2029',\n    ' ': ' ',\n    '\"': '\"',\n    '/': '/',\n    '\\\\': '\\\\',\n    '\\t': '\\t'\n};\nfunction parseCharCode(source, offset, length, onError) {\n    const cc = source.substr(offset, length);\n    const ok = cc.length === length && /^[0-9a-fA-F]+$/.test(cc);\n    const code = ok ? parseInt(cc, 16) : NaN;\n    if (isNaN(code)) {\n        const raw = source.substr(offset - 2, length + 2);\n        onError(offset - 2, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);\n        return raw;\n    }\n    return String.fromCodePoint(code);\n}\n\nexports.resolveFlowScalar = resolveFlowScalar;\n","'use strict';\n\nfunction resolveProps(tokens, { flow, indicator, next, offset, onError, startOnNewline }) {\n    let spaceBefore = false;\n    let atNewline = startOnNewline;\n    let hasSpace = startOnNewline;\n    let comment = '';\n    let commentSep = '';\n    let hasNewline = false;\n    let hasNewlineAfterProp = false;\n    let reqSpace = false;\n    let anchor = null;\n    let tag = null;\n    let comma = null;\n    let found = null;\n    let start = null;\n    for (const token of tokens) {\n        if (reqSpace) {\n            if (token.type !== 'space' &&\n                token.type !== 'newline' &&\n                token.type !== 'comma')\n                onError(token.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');\n            reqSpace = false;\n        }\n        switch (token.type) {\n            case 'space':\n                // At the doc level, tabs at line start may be parsed\n                // as leading white space rather than indentation.\n                // In a flow collection, only the parser handles indent.\n                if (!flow &&\n                    atNewline &&\n                    indicator !== 'doc-start' &&\n                    token.source[0] === '\\t')\n                    onError(token, 'TAB_AS_INDENT', 'Tabs are not allowed as indentation');\n                hasSpace = true;\n                break;\n            case 'comment': {\n                if (!hasSpace)\n                    onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');\n                const cb = token.source.substring(1) || ' ';\n                if (!comment)\n                    comment = cb;\n                else\n                    comment += commentSep + cb;\n                commentSep = '';\n                atNewline = false;\n                break;\n            }\n            case 'newline':\n                if (atNewline) {\n                    if (comment)\n                        comment += token.source;\n                    else\n                        spaceBefore = true;\n                }\n                else\n                    commentSep += token.source;\n                atNewline = true;\n                hasNewline = true;\n                if (anchor || tag)\n                    hasNewlineAfterProp = true;\n                hasSpace = true;\n                break;\n            case 'anchor':\n                if (anchor)\n                    onError(token, 'MULTIPLE_ANCHORS', 'A node can have at most one anchor');\n                if (token.source.endsWith(':'))\n                    onError(token.offset + token.source.length - 1, 'BAD_ALIAS', 'Anchor ending in : is ambiguous', true);\n                anchor = token;\n                if (start === null)\n                    start = token.offset;\n                atNewline = false;\n                hasSpace = false;\n                reqSpace = true;\n                break;\n            case 'tag': {\n                if (tag)\n                    onError(token, 'MULTIPLE_TAGS', 'A node can have at most one tag');\n                tag = token;\n                if (start === null)\n                    start = token.offset;\n                atNewline = false;\n                hasSpace = false;\n                reqSpace = true;\n                break;\n            }\n            case indicator:\n                // Could here handle preceding comments differently\n                if (anchor || tag)\n                    onError(token, 'BAD_PROP_ORDER', `Anchors and tags must be after the ${token.source} indicator`);\n                if (found)\n                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.source} in ${flow ?? 'collection'}`);\n                found = token;\n                atNewline = false;\n                hasSpace = false;\n                break;\n            case 'comma':\n                if (flow) {\n                    if (comma)\n                        onError(token, 'UNEXPECTED_TOKEN', `Unexpected , in ${flow}`);\n                    comma = token;\n                    atNewline = false;\n                    hasSpace = false;\n                    break;\n                }\n            // else fallthrough\n            default:\n                onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.type} token`);\n                atNewline = false;\n                hasSpace = false;\n        }\n    }\n    const last = tokens[tokens.length - 1];\n    const end = last ? last.offset + last.source.length : offset;\n    if (reqSpace &&\n        next &&\n        next.type !== 'space' &&\n        next.type !== 'newline' &&\n        next.type !== 'comma' &&\n        (next.type !== 'scalar' || next.source !== ''))\n        onError(next.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');\n    return {\n        comma,\n        found,\n        spaceBefore,\n        comment,\n        hasNewline,\n        hasNewlineAfterProp,\n        anchor,\n        tag,\n        end,\n        start: start ?? end\n    };\n}\n\nexports.resolveProps = resolveProps;\n","'use strict';\n\nfunction containsNewline(key) {\n    if (!key)\n        return null;\n    switch (key.type) {\n        case 'alias':\n        case 'scalar':\n        case 'double-quoted-scalar':\n        case 'single-quoted-scalar':\n            if (key.source.includes('\\n'))\n                return true;\n            if (key.end)\n                for (const st of key.end)\n                    if (st.type === 'newline')\n                        return true;\n            return false;\n        case 'flow-collection':\n            for (const it of key.items) {\n                for (const st of it.start)\n                    if (st.type === 'newline')\n                        return true;\n                if (it.sep)\n                    for (const st of it.sep)\n                        if (st.type === 'newline')\n                            return true;\n                if (containsNewline(it.key) || containsNewline(it.value))\n                    return true;\n            }\n            return false;\n        default:\n            return true;\n    }\n}\n\nexports.containsNewline = containsNewline;\n","'use strict';\n\nfunction emptyScalarPosition(offset, before, pos) {\n    if (before) {\n        if (pos === null)\n            pos = before.length;\n        for (let i = pos - 1; i >= 0; --i) {\n            let st = before[i];\n            switch (st.type) {\n                case 'space':\n                case 'comment':\n                case 'newline':\n                    offset -= st.source.length;\n                    continue;\n            }\n            // Technically, an empty scalar is immediately after the last non-empty\n            // node, but it's more useful to place it after any whitespace.\n            st = before[++i];\n            while (st?.type === 'space') {\n                offset += st.source.length;\n                st = before[++i];\n            }\n            break;\n        }\n    }\n    return offset;\n}\n\nexports.emptyScalarPosition = emptyScalarPosition;\n","'use strict';\n\nvar utilContainsNewline = require('./util-contains-newline.js');\n\nfunction flowIndentCheck(indent, fc, onError) {\n    if (fc?.type === 'flow-collection') {\n        const end = fc.end[0];\n        if (end.indent === indent &&\n            (end.source === ']' || end.source === '}') &&\n            utilContainsNewline.containsNewline(fc)) {\n            const msg = 'Flow end indicator should be more indented than parent';\n            onError(end, 'BAD_INDENT', msg, true);\n        }\n    }\n}\n\nexports.flowIndentCheck = flowIndentCheck;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\n\nfunction mapIncludes(ctx, items, search) {\n    const { uniqueKeys } = ctx.options;\n    if (uniqueKeys === false)\n        return false;\n    const isEqual = typeof uniqueKeys === 'function'\n        ? uniqueKeys\n        : (a, b) => a === b ||\n            (identity.isScalar(a) &&\n                identity.isScalar(b) &&\n                a.value === b.value &&\n                !(a.value === '<<' && ctx.schema.merge));\n    return items.some(pair => isEqual(pair.key, search));\n}\n\nexports.mapIncludes = mapIncludes;\n","'use strict';\n\nvar Alias = require('../nodes/Alias.js');\nvar Collection = require('../nodes/Collection.js');\nvar identity = require('../nodes/identity.js');\nvar Pair = require('../nodes/Pair.js');\nvar toJS = require('../nodes/toJS.js');\nvar Schema = require('../schema/Schema.js');\nvar stringifyDocument = require('../stringify/stringifyDocument.js');\nvar anchors = require('./anchors.js');\nvar applyReviver = require('./applyReviver.js');\nvar createNode = require('./createNode.js');\nvar directives = require('./directives.js');\n\nclass Document {\n    constructor(value, replacer, options) {\n        /** A comment before this Document */\n        this.commentBefore = null;\n        /** A comment immediately after this Document */\n        this.comment = null;\n        /** Errors encountered during parsing. */\n        this.errors = [];\n        /** Warnings encountered during parsing. */\n        this.warnings = [];\n        Object.defineProperty(this, identity.NODE_TYPE, { value: identity.DOC });\n        let _replacer = null;\n        if (typeof replacer === 'function' || Array.isArray(replacer)) {\n            _replacer = replacer;\n        }\n        else if (options === undefined && replacer) {\n            options = replacer;\n            replacer = undefined;\n        }\n        const opt = Object.assign({\n            intAsBigInt: false,\n            keepSourceTokens: false,\n            logLevel: 'warn',\n            prettyErrors: true,\n            strict: true,\n            uniqueKeys: true,\n            version: '1.2'\n        }, options);\n        this.options = opt;\n        let { version } = opt;\n        if (options?._directives) {\n            this.directives = options._directives.atDocument();\n            if (this.directives.yaml.explicit)\n                version = this.directives.yaml.version;\n        }\n        else\n            this.directives = new directives.Directives({ version });\n        this.setSchema(version, options);\n        // @ts-expect-error We can't really know that this matches Contents.\n        this.contents =\n            value === undefined ? null : this.createNode(value, _replacer, options);\n    }\n    /**\n     * Create a deep copy of this Document and its contents.\n     *\n     * Custom Node values that inherit from `Object` still refer to their original instances.\n     */\n    clone() {\n        const copy = Object.create(Document.prototype, {\n            [identity.NODE_TYPE]: { value: identity.DOC }\n        });\n        copy.commentBefore = this.commentBefore;\n        copy.comment = this.comment;\n        copy.errors = this.errors.slice();\n        copy.warnings = this.warnings.slice();\n        copy.options = Object.assign({}, this.options);\n        if (this.directives)\n            copy.directives = this.directives.clone();\n        copy.schema = this.schema.clone();\n        // @ts-expect-error We can't really know that this matches Contents.\n        copy.contents = identity.isNode(this.contents)\n            ? this.contents.clone(copy.schema)\n            : this.contents;\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /** Adds a value to the document. */\n    add(value) {\n        if (assertCollection(this.contents))\n            this.contents.add(value);\n    }\n    /** Adds a value to the document. */\n    addIn(path, value) {\n        if (assertCollection(this.contents))\n            this.contents.addIn(path, value);\n    }\n    /**\n     * Create a new `Alias` node, ensuring that the target `node` has the required anchor.\n     *\n     * If `node` already has an anchor, `name` is ignored.\n     * Otherwise, the `node.anchor` value will be set to `name`,\n     * or if an anchor with that name is already present in the document,\n     * `name` will be used as a prefix for a new unique anchor.\n     * If `name` is undefined, the generated anchor will use 'a' as a prefix.\n     */\n    createAlias(node, name) {\n        if (!node.anchor) {\n            const prev = anchors.anchorNames(this);\n            node.anchor =\n                // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n                !name || prev.has(name) ? anchors.findNewAnchor(name || 'a', prev) : name;\n        }\n        return new Alias.Alias(node.anchor);\n    }\n    createNode(value, replacer, options) {\n        let _replacer = undefined;\n        if (typeof replacer === 'function') {\n            value = replacer.call({ '': value }, '', value);\n            _replacer = replacer;\n        }\n        else if (Array.isArray(replacer)) {\n            const keyToStr = (v) => typeof v === 'number' || v instanceof String || v instanceof Number;\n            const asStr = replacer.filter(keyToStr).map(String);\n            if (asStr.length > 0)\n                replacer = replacer.concat(asStr);\n            _replacer = replacer;\n        }\n        else if (options === undefined && replacer) {\n            options = replacer;\n            replacer = undefined;\n        }\n        const { aliasDuplicateObjects, anchorPrefix, flow, keepUndefined, onTagObj, tag } = options ?? {};\n        const { onAnchor, setAnchors, sourceObjects } = anchors.createNodeAnchors(this, \n        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n        anchorPrefix || 'a');\n        const ctx = {\n            aliasDuplicateObjects: aliasDuplicateObjects ?? true,\n            keepUndefined: keepUndefined ?? false,\n            onAnchor,\n            onTagObj,\n            replacer: _replacer,\n            schema: this.schema,\n            sourceObjects\n        };\n        const node = createNode.createNode(value, tag, ctx);\n        if (flow && identity.isCollection(node))\n            node.flow = true;\n        setAnchors();\n        return node;\n    }\n    /**\n     * Convert a key and a value into a `Pair` using the current schema,\n     * recursively wrapping all values as `Scalar` or `Collection` nodes.\n     */\n    createPair(key, value, options = {}) {\n        const k = this.createNode(key, null, options);\n        const v = this.createNode(value, null, options);\n        return new Pair.Pair(k, v);\n    }\n    /**\n     * Removes a value from the document.\n     * @returns `true` if the item was found and removed.\n     */\n    delete(key) {\n        return assertCollection(this.contents) ? this.contents.delete(key) : false;\n    }\n    /**\n     * Removes a value from the document.\n     * @returns `true` if the item was found and removed.\n     */\n    deleteIn(path) {\n        if (Collection.isEmptyPath(path)) {\n            if (this.contents == null)\n                return false;\n            // @ts-expect-error Presumed impossible if Strict extends false\n            this.contents = null;\n            return true;\n        }\n        return assertCollection(this.contents)\n            ? this.contents.deleteIn(path)\n            : false;\n    }\n    /**\n     * Returns item at `key`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    get(key, keepScalar) {\n        return identity.isCollection(this.contents)\n            ? this.contents.get(key, keepScalar)\n            : undefined;\n    }\n    /**\n     * Returns item at `path`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    getIn(path, keepScalar) {\n        if (Collection.isEmptyPath(path))\n            return !keepScalar && identity.isScalar(this.contents)\n                ? this.contents.value\n                : this.contents;\n        return identity.isCollection(this.contents)\n            ? this.contents.getIn(path, keepScalar)\n            : undefined;\n    }\n    /**\n     * Checks if the document includes a value with the key `key`.\n     */\n    has(key) {\n        return identity.isCollection(this.contents) ? this.contents.has(key) : false;\n    }\n    /**\n     * Checks if the document includes a value at `path`.\n     */\n    hasIn(path) {\n        if (Collection.isEmptyPath(path))\n            return this.contents !== undefined;\n        return identity.isCollection(this.contents) ? this.contents.hasIn(path) : false;\n    }\n    /**\n     * Sets a value in this document. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    set(key, value) {\n        if (this.contents == null) {\n            // @ts-expect-error We can't really know that this matches Contents.\n            this.contents = Collection.collectionFromPath(this.schema, [key], value);\n        }\n        else if (assertCollection(this.contents)) {\n            this.contents.set(key, value);\n        }\n    }\n    /**\n     * Sets a value in this document. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    setIn(path, value) {\n        if (Collection.isEmptyPath(path)) {\n            // @ts-expect-error We can't really know that this matches Contents.\n            this.contents = value;\n        }\n        else if (this.contents == null) {\n            // @ts-expect-error We can't really know that this matches Contents.\n            this.contents = Collection.collectionFromPath(this.schema, Array.from(path), value);\n        }\n        else if (assertCollection(this.contents)) {\n            this.contents.setIn(path, value);\n        }\n    }\n    /**\n     * Change the YAML version and schema used by the document.\n     * A `null` version disables support for directives, explicit tags, anchors, and aliases.\n     * It also requires the `schema` option to be given as a `Schema` instance value.\n     *\n     * Overrides all previously set schema options.\n     */\n    setSchema(version, options = {}) {\n        if (typeof version === 'number')\n            version = String(version);\n        let opt;\n        switch (version) {\n            case '1.1':\n                if (this.directives)\n                    this.directives.yaml.version = '1.1';\n                else\n                    this.directives = new directives.Directives({ version: '1.1' });\n                opt = { merge: true, resolveKnownTags: false, schema: 'yaml-1.1' };\n                break;\n            case '1.2':\n            case 'next':\n                if (this.directives)\n                    this.directives.yaml.version = version;\n                else\n                    this.directives = new directives.Directives({ version });\n                opt = { merge: false, resolveKnownTags: true, schema: 'core' };\n                break;\n            case null:\n                if (this.directives)\n                    delete this.directives;\n                opt = null;\n                break;\n            default: {\n                const sv = JSON.stringify(version);\n                throw new Error(`Expected '1.1', '1.2' or null as first argument, but found: ${sv}`);\n            }\n        }\n        // Not using `instanceof Schema` to allow for duck typing\n        if (options.schema instanceof Object)\n            this.schema = options.schema;\n        else if (opt)\n            this.schema = new Schema.Schema(Object.assign(opt, options));\n        else\n            throw new Error(`With a null YAML version, the { schema: Schema } option is required`);\n    }\n    // json & jsonArg are only used from toJSON()\n    toJS({ json, jsonArg, mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {\n        const ctx = {\n            anchors: new Map(),\n            doc: this,\n            keep: !json,\n            mapAsMap: mapAsMap === true,\n            mapKeyWarned: false,\n            maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100\n        };\n        const res = toJS.toJS(this.contents, jsonArg ?? '', ctx);\n        if (typeof onAnchor === 'function')\n            for (const { count, res } of ctx.anchors.values())\n                onAnchor(res, count);\n        return typeof reviver === 'function'\n            ? applyReviver.applyReviver(reviver, { '': res }, '', res)\n            : res;\n    }\n    /**\n     * A JSON representation of the document `contents`.\n     *\n     * @param jsonArg Used by `JSON.stringify` to indicate the array index or\n     *   property name.\n     */\n    toJSON(jsonArg, onAnchor) {\n        return this.toJS({ json: true, jsonArg, mapAsMap: false, onAnchor });\n    }\n    /** A YAML representation of the document. */\n    toString(options = {}) {\n        if (this.errors.length > 0)\n            throw new Error('Document with errors cannot be stringified');\n        if ('indent' in options &&\n            (!Number.isInteger(options.indent) || Number(options.indent) <= 0)) {\n            const s = JSON.stringify(options.indent);\n            throw new Error(`\"indent\" option must be a positive integer, not ${s}`);\n        }\n        return stringifyDocument.stringifyDocument(this, options);\n    }\n}\nfunction assertCollection(contents) {\n    if (identity.isCollection(contents))\n        return true;\n    throw new Error('Expected a YAML collection as document contents');\n}\n\nexports.Document = Document;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar visit = require('../visit.js');\n\n/**\n * Verify that the input string is a valid anchor.\n *\n * Will throw on errors.\n */\nfunction anchorIsValid(anchor) {\n    if (/[\\x00-\\x19\\s,[\\]{}]/.test(anchor)) {\n        const sa = JSON.stringify(anchor);\n        const msg = `Anchor must not contain whitespace or control characters: ${sa}`;\n        throw new Error(msg);\n    }\n    return true;\n}\nfunction anchorNames(root) {\n    const anchors = new Set();\n    visit.visit(root, {\n        Value(_key, node) {\n            if (node.anchor)\n                anchors.add(node.anchor);\n        }\n    });\n    return anchors;\n}\n/** Find a new anchor name with the given `prefix` and a one-indexed suffix. */\nfunction findNewAnchor(prefix, exclude) {\n    for (let i = 1; true; ++i) {\n        const name = `${prefix}${i}`;\n        if (!exclude.has(name))\n            return name;\n    }\n}\nfunction createNodeAnchors(doc, prefix) {\n    const aliasObjects = [];\n    const sourceObjects = new Map();\n    let prevAnchors = null;\n    return {\n        onAnchor: (source) => {\n            aliasObjects.push(source);\n            if (!prevAnchors)\n                prevAnchors = anchorNames(doc);\n            const anchor = findNewAnchor(prefix, prevAnchors);\n            prevAnchors.add(anchor);\n            return anchor;\n        },\n        /**\n         * With circular references, the source node is only resolved after all\n         * of its child nodes are. This is why anchors are set only after all of\n         * the nodes have been created.\n         */\n        setAnchors: () => {\n            for (const source of aliasObjects) {\n                const ref = sourceObjects.get(source);\n                if (typeof ref === 'object' &&\n                    ref.anchor &&\n                    (identity.isScalar(ref.node) || identity.isCollection(ref.node))) {\n                    ref.node.anchor = ref.anchor;\n                }\n                else {\n                    const error = new Error('Failed to resolve repeated object (this should not happen)');\n                    error.source = source;\n                    throw error;\n                }\n            }\n        },\n        sourceObjects\n    };\n}\n\nexports.anchorIsValid = anchorIsValid;\nexports.anchorNames = anchorNames;\nexports.createNodeAnchors = createNodeAnchors;\nexports.findNewAnchor = findNewAnchor;\n","'use strict';\n\n/**\n * Applies the JSON.parse reviver algorithm as defined in the ECMA-262 spec,\n * in section 24.5.1.1 \"Runtime Semantics: InternalizeJSONProperty\" of the\n * 2021 edition: https://tc39.es/ecma262/#sec-json.parse\n *\n * Includes extensions for handling Map and Set objects.\n */\nfunction applyReviver(reviver, obj, key, val) {\n    if (val && typeof val === 'object') {\n        if (Array.isArray(val)) {\n            for (let i = 0, len = val.length; i < len; ++i) {\n                const v0 = val[i];\n                const v1 = applyReviver(reviver, val, String(i), v0);\n                if (v1 === undefined)\n                    delete val[i];\n                else if (v1 !== v0)\n                    val[i] = v1;\n            }\n        }\n        else if (val instanceof Map) {\n            for (const k of Array.from(val.keys())) {\n                const v0 = val.get(k);\n                const v1 = applyReviver(reviver, val, k, v0);\n                if (v1 === undefined)\n                    val.delete(k);\n                else if (v1 !== v0)\n                    val.set(k, v1);\n            }\n        }\n        else if (val instanceof Set) {\n            for (const v0 of Array.from(val)) {\n                const v1 = applyReviver(reviver, val, v0, v0);\n                if (v1 === undefined)\n                    val.delete(v0);\n                else if (v1 !== v0) {\n                    val.delete(v0);\n                    val.add(v1);\n                }\n            }\n        }\n        else {\n            for (const [k, v0] of Object.entries(val)) {\n                const v1 = applyReviver(reviver, val, k, v0);\n                if (v1 === undefined)\n                    delete val[k];\n                else if (v1 !== v0)\n                    val[k] = v1;\n            }\n        }\n    }\n    return reviver.call(obj, key, val);\n}\n\nexports.applyReviver = applyReviver;\n","'use strict';\n\nvar Alias = require('../nodes/Alias.js');\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\n\nconst defaultTagPrefix = 'tag:yaml.org,2002:';\nfunction findTagObject(value, tagName, tags) {\n    if (tagName) {\n        const match = tags.filter(t => t.tag === tagName);\n        const tagObj = match.find(t => !t.format) ?? match[0];\n        if (!tagObj)\n            throw new Error(`Tag ${tagName} not found`);\n        return tagObj;\n    }\n    return tags.find(t => t.identify?.(value) && !t.format);\n}\nfunction createNode(value, tagName, ctx) {\n    if (identity.isDocument(value))\n        value = value.contents;\n    if (identity.isNode(value))\n        return value;\n    if (identity.isPair(value)) {\n        const map = ctx.schema[identity.MAP].createNode?.(ctx.schema, null, ctx);\n        map.items.push(value);\n        return map;\n    }\n    if (value instanceof String ||\n        value instanceof Number ||\n        value instanceof Boolean ||\n        (typeof BigInt !== 'undefined' && value instanceof BigInt) // not supported everywhere\n    ) {\n        // https://tc39.es/ecma262/#sec-serializejsonproperty\n        value = value.valueOf();\n    }\n    const { aliasDuplicateObjects, onAnchor, onTagObj, schema, sourceObjects } = ctx;\n    // Detect duplicate references to the same object & use Alias nodes for all\n    // after first. The `ref` wrapper allows for circular references to resolve.\n    let ref = undefined;\n    if (aliasDuplicateObjects && value && typeof value === 'object') {\n        ref = sourceObjects.get(value);\n        if (ref) {\n            if (!ref.anchor)\n                ref.anchor = onAnchor(value);\n            return new Alias.Alias(ref.anchor);\n        }\n        else {\n            ref = { anchor: null, node: null };\n            sourceObjects.set(value, ref);\n        }\n    }\n    if (tagName?.startsWith('!!'))\n        tagName = defaultTagPrefix + tagName.slice(2);\n    let tagObj = findTagObject(value, tagName, schema.tags);\n    if (!tagObj) {\n        if (value && typeof value.toJSON === 'function') {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-call\n            value = value.toJSON();\n        }\n        if (!value || typeof value !== 'object') {\n            const node = new Scalar.Scalar(value);\n            if (ref)\n                ref.node = node;\n            return node;\n        }\n        tagObj =\n            value instanceof Map\n                ? schema[identity.MAP]\n                : Symbol.iterator in Object(value)\n                    ? schema[identity.SEQ]\n                    : schema[identity.MAP];\n    }\n    if (onTagObj) {\n        onTagObj(tagObj);\n        delete ctx.onTagObj;\n    }\n    const node = tagObj?.createNode\n        ? tagObj.createNode(ctx.schema, value, ctx)\n        : typeof tagObj?.nodeClass?.from === 'function'\n            ? tagObj.nodeClass.from(ctx.schema, value, ctx)\n            : new Scalar.Scalar(value);\n    if (tagName)\n        node.tag = tagName;\n    else if (!tagObj.default)\n        node.tag = tagObj.tag;\n    if (ref)\n        ref.node = node;\n    return node;\n}\n\nexports.createNode = createNode;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar visit = require('../visit.js');\n\nconst escapeChars = {\n    '!': '%21',\n    ',': '%2C',\n    '[': '%5B',\n    ']': '%5D',\n    '{': '%7B',\n    '}': '%7D'\n};\nconst escapeTagName = (tn) => tn.replace(/[!,[\\]{}]/g, ch => escapeChars[ch]);\nclass Directives {\n    constructor(yaml, tags) {\n        /**\n         * The directives-end/doc-start marker `---`. If `null`, a marker may still be\n         * included in the document's stringified representation.\n         */\n        this.docStart = null;\n        /** The doc-end marker `...`.  */\n        this.docEnd = false;\n        this.yaml = Object.assign({}, Directives.defaultYaml, yaml);\n        this.tags = Object.assign({}, Directives.defaultTags, tags);\n    }\n    clone() {\n        const copy = new Directives(this.yaml, this.tags);\n        copy.docStart = this.docStart;\n        return copy;\n    }\n    /**\n     * During parsing, get a Directives instance for the current document and\n     * update the stream state according to the current version's spec.\n     */\n    atDocument() {\n        const res = new Directives(this.yaml, this.tags);\n        switch (this.yaml.version) {\n            case '1.1':\n                this.atNextDocument = true;\n                break;\n            case '1.2':\n                this.atNextDocument = false;\n                this.yaml = {\n                    explicit: Directives.defaultYaml.explicit,\n                    version: '1.2'\n                };\n                this.tags = Object.assign({}, Directives.defaultTags);\n                break;\n        }\n        return res;\n    }\n    /**\n     * @param onError - May be called even if the action was successful\n     * @returns `true` on success\n     */\n    add(line, onError) {\n        if (this.atNextDocument) {\n            this.yaml = { explicit: Directives.defaultYaml.explicit, version: '1.1' };\n            this.tags = Object.assign({}, Directives.defaultTags);\n            this.atNextDocument = false;\n        }\n        const parts = line.trim().split(/[ \\t]+/);\n        const name = parts.shift();\n        switch (name) {\n            case '%TAG': {\n                if (parts.length !== 2) {\n                    onError(0, '%TAG directive should contain exactly two parts');\n                    if (parts.length < 2)\n                        return false;\n                }\n                const [handle, prefix] = parts;\n                this.tags[handle] = prefix;\n                return true;\n            }\n            case '%YAML': {\n                this.yaml.explicit = true;\n                if (parts.length !== 1) {\n                    onError(0, '%YAML directive should contain exactly one part');\n                    return false;\n                }\n                const [version] = parts;\n                if (version === '1.1' || version === '1.2') {\n                    this.yaml.version = version;\n                    return true;\n                }\n                else {\n                    const isValid = /^\\d+\\.\\d+$/.test(version);\n                    onError(6, `Unsupported YAML version ${version}`, isValid);\n                    return false;\n                }\n            }\n            default:\n                onError(0, `Unknown directive ${name}`, true);\n                return false;\n        }\n    }\n    /**\n     * Resolves a tag, matching handles to those defined in %TAG directives.\n     *\n     * @returns Resolved tag, which may also be the non-specific tag `'!'` or a\n     *   `'!local'` tag, or `null` if unresolvable.\n     */\n    tagName(source, onError) {\n        if (source === '!')\n            return '!'; // non-specific tag\n        if (source[0] !== '!') {\n            onError(`Not a valid tag: ${source}`);\n            return null;\n        }\n        if (source[1] === '<') {\n            const verbatim = source.slice(2, -1);\n            if (verbatim === '!' || verbatim === '!!') {\n                onError(`Verbatim tags aren't resolved, so ${source} is invalid.`);\n                return null;\n            }\n            if (source[source.length - 1] !== '>')\n                onError('Verbatim tags must end with a >');\n            return verbatim;\n        }\n        const [, handle, suffix] = source.match(/^(.*!)([^!]*)$/);\n        if (!suffix)\n            onError(`The ${source} tag has no suffix`);\n        const prefix = this.tags[handle];\n        if (prefix)\n            return prefix + decodeURIComponent(suffix);\n        if (handle === '!')\n            return source; // local tag\n        onError(`Could not resolve tag: ${source}`);\n        return null;\n    }\n    /**\n     * Given a fully resolved tag, returns its printable string form,\n     * taking into account current tag prefixes and defaults.\n     */\n    tagString(tag) {\n        for (const [handle, prefix] of Object.entries(this.tags)) {\n            if (tag.startsWith(prefix))\n                return handle + escapeTagName(tag.substring(prefix.length));\n        }\n        return tag[0] === '!' ? tag : `!<${tag}>`;\n    }\n    toString(doc) {\n        const lines = this.yaml.explicit\n            ? [`%YAML ${this.yaml.version || '1.2'}`]\n            : [];\n        const tagEntries = Object.entries(this.tags);\n        let tagNames;\n        if (doc && tagEntries.length > 0 && identity.isNode(doc.contents)) {\n            const tags = {};\n            visit.visit(doc.contents, (_key, node) => {\n                if (identity.isNode(node) && node.tag)\n                    tags[node.tag] = true;\n            });\n            tagNames = Object.keys(tags);\n        }\n        else\n            tagNames = [];\n        for (const [handle, prefix] of tagEntries) {\n            if (handle === '!!' && prefix === 'tag:yaml.org,2002:')\n                continue;\n            if (!doc || tagNames.some(tn => tn.startsWith(prefix)))\n                lines.push(`%TAG ${handle} ${prefix}`);\n        }\n        return lines.join('\\n');\n    }\n}\nDirectives.defaultYaml = { explicit: false, version: '1.2' };\nDirectives.defaultTags = { '!!': 'tag:yaml.org,2002:' };\n\nexports.Directives = Directives;\n","'use strict';\n\nclass YAMLError extends Error {\n    constructor(name, pos, code, message) {\n        super();\n        this.name = name;\n        this.code = code;\n        this.message = message;\n        this.pos = pos;\n    }\n}\nclass YAMLParseError extends YAMLError {\n    constructor(pos, code, message) {\n        super('YAMLParseError', pos, code, message);\n    }\n}\nclass YAMLWarning extends YAMLError {\n    constructor(pos, code, message) {\n        super('YAMLWarning', pos, code, message);\n    }\n}\nconst prettifyError = (src, lc) => (error) => {\n    if (error.pos[0] === -1)\n        return;\n    error.linePos = error.pos.map(pos => lc.linePos(pos));\n    const { line, col } = error.linePos[0];\n    error.message += ` at line ${line}, column ${col}`;\n    let ci = col - 1;\n    let lineStr = src\n        .substring(lc.lineStarts[line - 1], lc.lineStarts[line])\n        .replace(/[\\n\\r]+$/, '');\n    // Trim to max 80 chars, keeping col position near the middle\n    if (ci >= 60 && lineStr.length > 80) {\n        const trimStart = Math.min(ci - 39, lineStr.length - 79);\n        lineStr = '' + lineStr.substring(trimStart);\n        ci -= trimStart - 1;\n    }\n    if (lineStr.length > 80)\n        lineStr = lineStr.substring(0, 79) + '';\n    // Include previous line in context if pointing at line start\n    if (line > 1 && /^ *$/.test(lineStr.substring(0, ci))) {\n        // Regexp won't match if start is trimmed\n        let prev = src.substring(lc.lineStarts[line - 2], lc.lineStarts[line - 1]);\n        if (prev.length > 80)\n            prev = prev.substring(0, 79) + '\\n';\n        lineStr = prev + lineStr;\n    }\n    if (/[^ ]/.test(lineStr)) {\n        let count = 1;\n        const end = error.linePos[1];\n        if (end && end.line === line && end.col > col) {\n            count = Math.max(1, Math.min(end.col - col, 80 - ci));\n        }\n        const pointer = ' '.repeat(ci) + '^'.repeat(count);\n        error.message += `:\\n\\n${lineStr}\\n${pointer}\\n`;\n    }\n};\n\nexports.YAMLError = YAMLError;\nexports.YAMLParseError = YAMLParseError;\nexports.YAMLWarning = YAMLWarning;\nexports.prettifyError = prettifyError;\n","'use strict';\n\nvar composer = require('./compose/composer.js');\nvar Document = require('./doc/Document.js');\nvar Schema = require('./schema/Schema.js');\nvar errors = require('./errors.js');\nvar Alias = require('./nodes/Alias.js');\nvar identity = require('./nodes/identity.js');\nvar Pair = require('./nodes/Pair.js');\nvar Scalar = require('./nodes/Scalar.js');\nvar YAMLMap = require('./nodes/YAMLMap.js');\nvar YAMLSeq = require('./nodes/YAMLSeq.js');\nvar cst = require('./parse/cst.js');\nvar lexer = require('./parse/lexer.js');\nvar lineCounter = require('./parse/line-counter.js');\nvar parser = require('./parse/parser.js');\nvar publicApi = require('./public-api.js');\nvar visit = require('./visit.js');\n\n\n\nexports.Composer = composer.Composer;\nexports.Document = Document.Document;\nexports.Schema = Schema.Schema;\nexports.YAMLError = errors.YAMLError;\nexports.YAMLParseError = errors.YAMLParseError;\nexports.YAMLWarning = errors.YAMLWarning;\nexports.Alias = Alias.Alias;\nexports.isAlias = identity.isAlias;\nexports.isCollection = identity.isCollection;\nexports.isDocument = identity.isDocument;\nexports.isMap = identity.isMap;\nexports.isNode = identity.isNode;\nexports.isPair = identity.isPair;\nexports.isScalar = identity.isScalar;\nexports.isSeq = identity.isSeq;\nexports.Pair = Pair.Pair;\nexports.Scalar = Scalar.Scalar;\nexports.YAMLMap = YAMLMap.YAMLMap;\nexports.YAMLSeq = YAMLSeq.YAMLSeq;\nexports.CST = cst;\nexports.Lexer = lexer.Lexer;\nexports.LineCounter = lineCounter.LineCounter;\nexports.Parser = parser.Parser;\nexports.parse = publicApi.parse;\nexports.parseAllDocuments = publicApi.parseAllDocuments;\nexports.parseDocument = publicApi.parseDocument;\nexports.stringify = publicApi.stringify;\nexports.visit = visit.visit;\nexports.visitAsync = visit.visitAsync;\n","'use strict';\n\nfunction debug(logLevel, ...messages) {\n    if (logLevel === 'debug')\n        console.log(...messages);\n}\nfunction warn(logLevel, warning) {\n    if (logLevel === 'debug' || logLevel === 'warn') {\n        // https://github.com/typescript-eslint/typescript-eslint/issues/7478\n        // eslint-disable-next-line @typescript-eslint/prefer-optional-chain\n        if (typeof process !== 'undefined' && process.emitWarning)\n            process.emitWarning(warning);\n        else\n            console.warn(warning);\n    }\n}\n\nexports.debug = debug;\nexports.warn = warn;\n","'use strict';\n\nvar anchors = require('../doc/anchors.js');\nvar visit = require('../visit.js');\nvar identity = require('./identity.js');\nvar Node = require('./Node.js');\nvar toJS = require('./toJS.js');\n\nclass Alias extends Node.NodeBase {\n    constructor(source) {\n        super(identity.ALIAS);\n        this.source = source;\n        Object.defineProperty(this, 'tag', {\n            set() {\n                throw new Error('Alias nodes cannot have tags');\n            }\n        });\n    }\n    /**\n     * Resolve the value of this alias within `doc`, finding the last\n     * instance of the `source` anchor before this node.\n     */\n    resolve(doc) {\n        let found = undefined;\n        visit.visit(doc, {\n            Node: (_key, node) => {\n                if (node === this)\n                    return visit.visit.BREAK;\n                if (node.anchor === this.source)\n                    found = node;\n            }\n        });\n        return found;\n    }\n    toJSON(_arg, ctx) {\n        if (!ctx)\n            return { source: this.source };\n        const { anchors, doc, maxAliasCount } = ctx;\n        const source = this.resolve(doc);\n        if (!source) {\n            const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;\n            throw new ReferenceError(msg);\n        }\n        let data = anchors.get(source);\n        if (!data) {\n            // Resolve anchors for Node.prototype.toJS()\n            toJS.toJS(source, null, ctx);\n            data = anchors.get(source);\n        }\n        /* istanbul ignore if */\n        if (!data || data.res === undefined) {\n            const msg = 'This should not happen: Alias anchor was not resolved?';\n            throw new ReferenceError(msg);\n        }\n        if (maxAliasCount >= 0) {\n            data.count += 1;\n            if (data.aliasCount === 0)\n                data.aliasCount = getAliasCount(doc, source, anchors);\n            if (data.count * data.aliasCount > maxAliasCount) {\n                const msg = 'Excessive alias count indicates a resource exhaustion attack';\n                throw new ReferenceError(msg);\n            }\n        }\n        return data.res;\n    }\n    toString(ctx, _onComment, _onChompKeep) {\n        const src = `*${this.source}`;\n        if (ctx) {\n            anchors.anchorIsValid(this.source);\n            if (ctx.options.verifyAliasOrder && !ctx.anchors.has(this.source)) {\n                const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;\n                throw new Error(msg);\n            }\n            if (ctx.implicitKey)\n                return `${src} `;\n        }\n        return src;\n    }\n}\nfunction getAliasCount(doc, node, anchors) {\n    if (identity.isAlias(node)) {\n        const source = node.resolve(doc);\n        const anchor = anchors && source && anchors.get(source);\n        return anchor ? anchor.count * anchor.aliasCount : 0;\n    }\n    else if (identity.isCollection(node)) {\n        let count = 0;\n        for (const item of node.items) {\n            const c = getAliasCount(doc, item, anchors);\n            if (c > count)\n                count = c;\n        }\n        return count;\n    }\n    else if (identity.isPair(node)) {\n        const kc = getAliasCount(doc, node.key, anchors);\n        const vc = getAliasCount(doc, node.value, anchors);\n        return Math.max(kc, vc);\n    }\n    return 1;\n}\n\nexports.Alias = Alias;\n","'use strict';\n\nvar createNode = require('../doc/createNode.js');\nvar identity = require('./identity.js');\nvar Node = require('./Node.js');\n\nfunction collectionFromPath(schema, path, value) {\n    let v = value;\n    for (let i = path.length - 1; i >= 0; --i) {\n        const k = path[i];\n        if (typeof k === 'number' && Number.isInteger(k) && k >= 0) {\n            const a = [];\n            a[k] = v;\n            v = a;\n        }\n        else {\n            v = new Map([[k, v]]);\n        }\n    }\n    return createNode.createNode(v, undefined, {\n        aliasDuplicateObjects: false,\n        keepUndefined: false,\n        onAnchor: () => {\n            throw new Error('This should not happen, please report a bug.');\n        },\n        schema,\n        sourceObjects: new Map()\n    });\n}\n// Type guard is intentionally a little wrong so as to be more useful,\n// as it does not cover untypable empty non-string iterables (e.g. []).\nconst isEmptyPath = (path) => path == null ||\n    (typeof path === 'object' && !!path[Symbol.iterator]().next().done);\nclass Collection extends Node.NodeBase {\n    constructor(type, schema) {\n        super(type);\n        Object.defineProperty(this, 'schema', {\n            value: schema,\n            configurable: true,\n            enumerable: false,\n            writable: true\n        });\n    }\n    /**\n     * Create a copy of this collection.\n     *\n     * @param schema - If defined, overwrites the original's schema\n     */\n    clone(schema) {\n        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));\n        if (schema)\n            copy.schema = schema;\n        copy.items = copy.items.map(it => identity.isNode(it) || identity.isPair(it) ? it.clone(schema) : it);\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /**\n     * Adds a value to the collection. For `!!map` and `!!omap` the value must\n     * be a Pair instance or a `{ key, value }` object, which may not have a key\n     * that already exists in the map.\n     */\n    addIn(path, value) {\n        if (isEmptyPath(path))\n            this.add(value);\n        else {\n            const [key, ...rest] = path;\n            const node = this.get(key, true);\n            if (identity.isCollection(node))\n                node.addIn(rest, value);\n            else if (node === undefined && this.schema)\n                this.set(key, collectionFromPath(this.schema, rest, value));\n            else\n                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n        }\n    }\n    /**\n     * Removes a value from the collection.\n     * @returns `true` if the item was found and removed.\n     */\n    deleteIn(path) {\n        const [key, ...rest] = path;\n        if (rest.length === 0)\n            return this.delete(key);\n        const node = this.get(key, true);\n        if (identity.isCollection(node))\n            return node.deleteIn(rest);\n        else\n            throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n    }\n    /**\n     * Returns item at `key`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    getIn(path, keepScalar) {\n        const [key, ...rest] = path;\n        const node = this.get(key, true);\n        if (rest.length === 0)\n            return !keepScalar && identity.isScalar(node) ? node.value : node;\n        else\n            return identity.isCollection(node) ? node.getIn(rest, keepScalar) : undefined;\n    }\n    hasAllNullValues(allowScalar) {\n        return this.items.every(node => {\n            if (!identity.isPair(node))\n                return false;\n            const n = node.value;\n            return (n == null ||\n                (allowScalar &&\n                    identity.isScalar(n) &&\n                    n.value == null &&\n                    !n.commentBefore &&\n                    !n.comment &&\n                    !n.tag));\n        });\n    }\n    /**\n     * Checks if the collection includes a value with the key `key`.\n     */\n    hasIn(path) {\n        const [key, ...rest] = path;\n        if (rest.length === 0)\n            return this.has(key);\n        const node = this.get(key, true);\n        return identity.isCollection(node) ? node.hasIn(rest) : false;\n    }\n    /**\n     * Sets a value in this collection. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    setIn(path, value) {\n        const [key, ...rest] = path;\n        if (rest.length === 0) {\n            this.set(key, value);\n        }\n        else {\n            const node = this.get(key, true);\n            if (identity.isCollection(node))\n                node.setIn(rest, value);\n            else if (node === undefined && this.schema)\n                this.set(key, collectionFromPath(this.schema, rest, value));\n            else\n                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n        }\n    }\n}\nCollection.maxFlowStringSingleLineLength = 60;\n\nexports.Collection = Collection;\nexports.collectionFromPath = collectionFromPath;\nexports.isEmptyPath = isEmptyPath;\n","'use strict';\n\nvar applyReviver = require('../doc/applyReviver.js');\nvar identity = require('./identity.js');\nvar toJS = require('./toJS.js');\n\nclass NodeBase {\n    constructor(type) {\n        Object.defineProperty(this, identity.NODE_TYPE, { value: type });\n    }\n    /** Create a copy of this node.  */\n    clone() {\n        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /** A plain JavaScript representation of this node. */\n    toJS(doc, { mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {\n        if (!identity.isDocument(doc))\n            throw new TypeError('A document argument is required');\n        const ctx = {\n            anchors: new Map(),\n            doc,\n            keep: true,\n            mapAsMap: mapAsMap === true,\n            mapKeyWarned: false,\n            maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100\n        };\n        const res = toJS.toJS(this, '', ctx);\n        if (typeof onAnchor === 'function')\n            for (const { count, res } of ctx.anchors.values())\n                onAnchor(res, count);\n        return typeof reviver === 'function'\n            ? applyReviver.applyReviver(reviver, { '': res }, '', res)\n            : res;\n    }\n}\n\nexports.NodeBase = NodeBase;\n","'use strict';\n\nvar createNode = require('../doc/createNode.js');\nvar stringifyPair = require('../stringify/stringifyPair.js');\nvar addPairToJSMap = require('./addPairToJSMap.js');\nvar identity = require('./identity.js');\n\nfunction createPair(key, value, ctx) {\n    const k = createNode.createNode(key, undefined, ctx);\n    const v = createNode.createNode(value, undefined, ctx);\n    return new Pair(k, v);\n}\nclass Pair {\n    constructor(key, value = null) {\n        Object.defineProperty(this, identity.NODE_TYPE, { value: identity.PAIR });\n        this.key = key;\n        this.value = value;\n    }\n    clone(schema) {\n        let { key, value } = this;\n        if (identity.isNode(key))\n            key = key.clone(schema);\n        if (identity.isNode(value))\n            value = value.clone(schema);\n        return new Pair(key, value);\n    }\n    toJSON(_, ctx) {\n        const pair = ctx?.mapAsMap ? new Map() : {};\n        return addPairToJSMap.addPairToJSMap(ctx, pair, this);\n    }\n    toString(ctx, onComment, onChompKeep) {\n        return ctx?.doc\n            ? stringifyPair.stringifyPair(this, ctx, onComment, onChompKeep)\n            : JSON.stringify(this);\n    }\n}\n\nexports.Pair = Pair;\nexports.createPair = createPair;\n","'use strict';\n\nvar identity = require('./identity.js');\nvar Node = require('./Node.js');\nvar toJS = require('./toJS.js');\n\nconst isScalarValue = (value) => !value || (typeof value !== 'function' && typeof value !== 'object');\nclass Scalar extends Node.NodeBase {\n    constructor(value) {\n        super(identity.SCALAR);\n        this.value = value;\n    }\n    toJSON(arg, ctx) {\n        return ctx?.keep ? this.value : toJS.toJS(this.value, arg, ctx);\n    }\n    toString() {\n        return String(this.value);\n    }\n}\nScalar.BLOCK_FOLDED = 'BLOCK_FOLDED';\nScalar.BLOCK_LITERAL = 'BLOCK_LITERAL';\nScalar.PLAIN = 'PLAIN';\nScalar.QUOTE_DOUBLE = 'QUOTE_DOUBLE';\nScalar.QUOTE_SINGLE = 'QUOTE_SINGLE';\n\nexports.Scalar = Scalar;\nexports.isScalarValue = isScalarValue;\n","'use strict';\n\nvar stringifyCollection = require('../stringify/stringifyCollection.js');\nvar addPairToJSMap = require('./addPairToJSMap.js');\nvar Collection = require('./Collection.js');\nvar identity = require('./identity.js');\nvar Pair = require('./Pair.js');\nvar Scalar = require('./Scalar.js');\n\nfunction findPair(items, key) {\n    const k = identity.isScalar(key) ? key.value : key;\n    for (const it of items) {\n        if (identity.isPair(it)) {\n            if (it.key === key || it.key === k)\n                return it;\n            if (identity.isScalar(it.key) && it.key.value === k)\n                return it;\n        }\n    }\n    return undefined;\n}\nclass YAMLMap extends Collection.Collection {\n    static get tagName() {\n        return 'tag:yaml.org,2002:map';\n    }\n    constructor(schema) {\n        super(identity.MAP, schema);\n        this.items = [];\n    }\n    /**\n     * A generic collection parsing method that can be extended\n     * to other node classes that inherit from YAMLMap\n     */\n    static from(schema, obj, ctx) {\n        const { keepUndefined, replacer } = ctx;\n        const map = new this(schema);\n        const add = (key, value) => {\n            if (typeof replacer === 'function')\n                value = replacer.call(obj, key, value);\n            else if (Array.isArray(replacer) && !replacer.includes(key))\n                return;\n            if (value !== undefined || keepUndefined)\n                map.items.push(Pair.createPair(key, value, ctx));\n        };\n        if (obj instanceof Map) {\n            for (const [key, value] of obj)\n                add(key, value);\n        }\n        else if (obj && typeof obj === 'object') {\n            for (const key of Object.keys(obj))\n                add(key, obj[key]);\n        }\n        if (typeof schema.sortMapEntries === 'function') {\n            map.items.sort(schema.sortMapEntries);\n        }\n        return map;\n    }\n    /**\n     * Adds a value to the collection.\n     *\n     * @param overwrite - If not set `true`, using a key that is already in the\n     *   collection will throw. Otherwise, overwrites the previous value.\n     */\n    add(pair, overwrite) {\n        let _pair;\n        if (identity.isPair(pair))\n            _pair = pair;\n        else if (!pair || typeof pair !== 'object' || !('key' in pair)) {\n            // In TypeScript, this never happens.\n            _pair = new Pair.Pair(pair, pair?.value);\n        }\n        else\n            _pair = new Pair.Pair(pair.key, pair.value);\n        const prev = findPair(this.items, _pair.key);\n        const sortEntries = this.schema?.sortMapEntries;\n        if (prev) {\n            if (!overwrite)\n                throw new Error(`Key ${_pair.key} already set`);\n            // For scalars, keep the old node & its comments and anchors\n            if (identity.isScalar(prev.value) && Scalar.isScalarValue(_pair.value))\n                prev.value.value = _pair.value;\n            else\n                prev.value = _pair.value;\n        }\n        else if (sortEntries) {\n            const i = this.items.findIndex(item => sortEntries(_pair, item) < 0);\n            if (i === -1)\n                this.items.push(_pair);\n            else\n                this.items.splice(i, 0, _pair);\n        }\n        else {\n            this.items.push(_pair);\n        }\n    }\n    delete(key) {\n        const it = findPair(this.items, key);\n        if (!it)\n            return false;\n        const del = this.items.splice(this.items.indexOf(it), 1);\n        return del.length > 0;\n    }\n    get(key, keepScalar) {\n        const it = findPair(this.items, key);\n        const node = it?.value;\n        return (!keepScalar && identity.isScalar(node) ? node.value : node) ?? undefined;\n    }\n    has(key) {\n        return !!findPair(this.items, key);\n    }\n    set(key, value) {\n        this.add(new Pair.Pair(key, value), true);\n    }\n    /**\n     * @param ctx - Conversion context, originally set in Document#toJS()\n     * @param {Class} Type - If set, forces the returned collection type\n     * @returns Instance of Type, Map, or Object\n     */\n    toJSON(_, ctx, Type) {\n        const map = Type ? new Type() : ctx?.mapAsMap ? new Map() : {};\n        if (ctx?.onCreate)\n            ctx.onCreate(map);\n        for (const item of this.items)\n            addPairToJSMap.addPairToJSMap(ctx, map, item);\n        return map;\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        for (const item of this.items) {\n            if (!identity.isPair(item))\n                throw new Error(`Map items must all be pairs; found ${JSON.stringify(item)} instead`);\n        }\n        if (!ctx.allNullValues && this.hasAllNullValues(false))\n            ctx = Object.assign({}, ctx, { allNullValues: true });\n        return stringifyCollection.stringifyCollection(this, ctx, {\n            blockItemPrefix: '',\n            flowChars: { start: '{', end: '}' },\n            itemIndent: ctx.indent || '',\n            onChompKeep,\n            onComment\n        });\n    }\n}\n\nexports.YAMLMap = YAMLMap;\nexports.findPair = findPair;\n","'use strict';\n\nvar createNode = require('../doc/createNode.js');\nvar stringifyCollection = require('../stringify/stringifyCollection.js');\nvar Collection = require('./Collection.js');\nvar identity = require('./identity.js');\nvar Scalar = require('./Scalar.js');\nvar toJS = require('./toJS.js');\n\nclass YAMLSeq extends Collection.Collection {\n    static get tagName() {\n        return 'tag:yaml.org,2002:seq';\n    }\n    constructor(schema) {\n        super(identity.SEQ, schema);\n        this.items = [];\n    }\n    add(value) {\n        this.items.push(value);\n    }\n    /**\n     * Removes a value from the collection.\n     *\n     * `key` must contain a representation of an integer for this to succeed.\n     * It may be wrapped in a `Scalar`.\n     *\n     * @returns `true` if the item was found and removed.\n     */\n    delete(key) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            return false;\n        const del = this.items.splice(idx, 1);\n        return del.length > 0;\n    }\n    get(key, keepScalar) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            return undefined;\n        const it = this.items[idx];\n        return !keepScalar && identity.isScalar(it) ? it.value : it;\n    }\n    /**\n     * Checks if the collection includes a value with the key `key`.\n     *\n     * `key` must contain a representation of an integer for this to succeed.\n     * It may be wrapped in a `Scalar`.\n     */\n    has(key) {\n        const idx = asItemIndex(key);\n        return typeof idx === 'number' && idx < this.items.length;\n    }\n    /**\n     * Sets a value in this collection. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     *\n     * If `key` does not contain a representation of an integer, this will throw.\n     * It may be wrapped in a `Scalar`.\n     */\n    set(key, value) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            throw new Error(`Expected a valid index, not ${key}.`);\n        const prev = this.items[idx];\n        if (identity.isScalar(prev) && Scalar.isScalarValue(value))\n            prev.value = value;\n        else\n            this.items[idx] = value;\n    }\n    toJSON(_, ctx) {\n        const seq = [];\n        if (ctx?.onCreate)\n            ctx.onCreate(seq);\n        let i = 0;\n        for (const item of this.items)\n            seq.push(toJS.toJS(item, String(i++), ctx));\n        return seq;\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        return stringifyCollection.stringifyCollection(this, ctx, {\n            blockItemPrefix: '- ',\n            flowChars: { start: '[', end: ']' },\n            itemIndent: (ctx.indent || '') + '  ',\n            onChompKeep,\n            onComment\n        });\n    }\n    static from(schema, obj, ctx) {\n        const { replacer } = ctx;\n        const seq = new this(schema);\n        if (obj && Symbol.iterator in Object(obj)) {\n            let i = 0;\n            for (let it of obj) {\n                if (typeof replacer === 'function') {\n                    const key = obj instanceof Set ? it : String(i++);\n                    it = replacer.call(obj, key, it);\n                }\n                seq.items.push(createNode.createNode(it, undefined, ctx));\n            }\n        }\n        return seq;\n    }\n}\nfunction asItemIndex(key) {\n    let idx = identity.isScalar(key) ? key.value : key;\n    if (idx && typeof idx === 'string')\n        idx = Number(idx);\n    return typeof idx === 'number' && Number.isInteger(idx) && idx >= 0\n        ? idx\n        : null;\n}\n\nexports.YAMLSeq = YAMLSeq;\n","'use strict';\n\nvar log = require('../log.js');\nvar stringify = require('../stringify/stringify.js');\nvar identity = require('./identity.js');\nvar Scalar = require('./Scalar.js');\nvar toJS = require('./toJS.js');\n\nconst MERGE_KEY = '<<';\nfunction addPairToJSMap(ctx, map, { key, value }) {\n    if (ctx?.doc.schema.merge && isMergeKey(key)) {\n        value = identity.isAlias(value) ? value.resolve(ctx.doc) : value;\n        if (identity.isSeq(value))\n            for (const it of value.items)\n                mergeToJSMap(ctx, map, it);\n        else if (Array.isArray(value))\n            for (const it of value)\n                mergeToJSMap(ctx, map, it);\n        else\n            mergeToJSMap(ctx, map, value);\n    }\n    else {\n        const jsKey = toJS.toJS(key, '', ctx);\n        if (map instanceof Map) {\n            map.set(jsKey, toJS.toJS(value, jsKey, ctx));\n        }\n        else if (map instanceof Set) {\n            map.add(jsKey);\n        }\n        else {\n            const stringKey = stringifyKey(key, jsKey, ctx);\n            const jsValue = toJS.toJS(value, stringKey, ctx);\n            if (stringKey in map)\n                Object.defineProperty(map, stringKey, {\n                    value: jsValue,\n                    writable: true,\n                    enumerable: true,\n                    configurable: true\n                });\n            else\n                map[stringKey] = jsValue;\n        }\n    }\n    return map;\n}\nconst isMergeKey = (key) => key === MERGE_KEY ||\n    (identity.isScalar(key) &&\n        key.value === MERGE_KEY &&\n        (!key.type || key.type === Scalar.Scalar.PLAIN));\n// If the value associated with a merge key is a single mapping node, each of\n// its key/value pairs is inserted into the current mapping, unless the key\n// already exists in it. If the value associated with the merge key is a\n// sequence, then this sequence is expected to contain mapping nodes and each\n// of these nodes is merged in turn according to its order in the sequence.\n// Keys in mapping nodes earlier in the sequence override keys specified in\n// later mapping nodes. -- http://yaml.org/type/merge.html\nfunction mergeToJSMap(ctx, map, value) {\n    const source = ctx && identity.isAlias(value) ? value.resolve(ctx.doc) : value;\n    if (!identity.isMap(source))\n        throw new Error('Merge sources must be maps or map aliases');\n    const srcMap = source.toJSON(null, ctx, Map);\n    for (const [key, value] of srcMap) {\n        if (map instanceof Map) {\n            if (!map.has(key))\n                map.set(key, value);\n        }\n        else if (map instanceof Set) {\n            map.add(key);\n        }\n        else if (!Object.prototype.hasOwnProperty.call(map, key)) {\n            Object.defineProperty(map, key, {\n                value,\n                writable: true,\n                enumerable: true,\n                configurable: true\n            });\n        }\n    }\n    return map;\n}\nfunction stringifyKey(key, jsKey, ctx) {\n    if (jsKey === null)\n        return '';\n    if (typeof jsKey !== 'object')\n        return String(jsKey);\n    if (identity.isNode(key) && ctx?.doc) {\n        const strCtx = stringify.createStringifyContext(ctx.doc, {});\n        strCtx.anchors = new Set();\n        for (const node of ctx.anchors.keys())\n            strCtx.anchors.add(node.anchor);\n        strCtx.inFlow = true;\n        strCtx.inStringifyKey = true;\n        const strKey = key.toString(strCtx);\n        if (!ctx.mapKeyWarned) {\n            let jsonStr = JSON.stringify(strKey);\n            if (jsonStr.length > 40)\n                jsonStr = jsonStr.substring(0, 36) + '...\"';\n            log.warn(ctx.doc.options.logLevel, `Keys with collection values will be stringified due to JS Object restrictions: ${jsonStr}. Set mapAsMap: true to use object keys.`);\n            ctx.mapKeyWarned = true;\n        }\n        return strKey;\n    }\n    return JSON.stringify(jsKey);\n}\n\nexports.addPairToJSMap = addPairToJSMap;\n","'use strict';\n\nconst ALIAS = Symbol.for('yaml.alias');\nconst DOC = Symbol.for('yaml.document');\nconst MAP = Symbol.for('yaml.map');\nconst PAIR = Symbol.for('yaml.pair');\nconst SCALAR = Symbol.for('yaml.scalar');\nconst SEQ = Symbol.for('yaml.seq');\nconst NODE_TYPE = Symbol.for('yaml.node.type');\nconst isAlias = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === ALIAS;\nconst isDocument = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === DOC;\nconst isMap = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === MAP;\nconst isPair = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === PAIR;\nconst isScalar = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SCALAR;\nconst isSeq = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SEQ;\nfunction isCollection(node) {\n    if (node && typeof node === 'object')\n        switch (node[NODE_TYPE]) {\n            case MAP:\n            case SEQ:\n                return true;\n        }\n    return false;\n}\nfunction isNode(node) {\n    if (node && typeof node === 'object')\n        switch (node[NODE_TYPE]) {\n            case ALIAS:\n            case MAP:\n            case SCALAR:\n            case SEQ:\n                return true;\n        }\n    return false;\n}\nconst hasAnchor = (node) => (isScalar(node) || isCollection(node)) && !!node.anchor;\n\nexports.ALIAS = ALIAS;\nexports.DOC = DOC;\nexports.MAP = MAP;\nexports.NODE_TYPE = NODE_TYPE;\nexports.PAIR = PAIR;\nexports.SCALAR = SCALAR;\nexports.SEQ = SEQ;\nexports.hasAnchor = hasAnchor;\nexports.isAlias = isAlias;\nexports.isCollection = isCollection;\nexports.isDocument = isDocument;\nexports.isMap = isMap;\nexports.isNode = isNode;\nexports.isPair = isPair;\nexports.isScalar = isScalar;\nexports.isSeq = isSeq;\n","'use strict';\n\nvar identity = require('./identity.js');\n\n/**\n * Recursively convert any node or its contents to native JavaScript\n *\n * @param value - The input value\n * @param arg - If `value` defines a `toJSON()` method, use this\n *   as its first argument\n * @param ctx - Conversion context, originally set in Document#toJS(). If\n *   `{ keep: true }` is not set, output should be suitable for JSON\n *   stringification.\n */\nfunction toJS(value, arg, ctx) {\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n    if (Array.isArray(value))\n        return value.map((v, i) => toJS(v, String(i), ctx));\n    if (value && typeof value.toJSON === 'function') {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-call\n        if (!ctx || !identity.hasAnchor(value))\n            return value.toJSON(arg, ctx);\n        const data = { aliasCount: 0, count: 1, res: undefined };\n        ctx.anchors.set(value, data);\n        ctx.onCreate = res => {\n            data.res = res;\n            delete ctx.onCreate;\n        };\n        const res = value.toJSON(arg, ctx);\n        if (ctx.onCreate)\n            ctx.onCreate(res);\n        return res;\n    }\n    if (typeof value === 'bigint' && !ctx?.keep)\n        return Number(value);\n    return value;\n}\n\nexports.toJS = toJS;\n","'use strict';\n\nvar resolveBlockScalar = require('../compose/resolve-block-scalar.js');\nvar resolveFlowScalar = require('../compose/resolve-flow-scalar.js');\nvar errors = require('../errors.js');\nvar stringifyString = require('../stringify/stringifyString.js');\n\nfunction resolveAsScalar(token, strict = true, onError) {\n    if (token) {\n        const _onError = (pos, code, message) => {\n            const offset = typeof pos === 'number' ? pos : Array.isArray(pos) ? pos[0] : pos.offset;\n            if (onError)\n                onError(offset, code, message);\n            else\n                throw new errors.YAMLParseError([offset, offset + 1], code, message);\n        };\n        switch (token.type) {\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return resolveFlowScalar.resolveFlowScalar(token, strict, _onError);\n            case 'block-scalar':\n                return resolveBlockScalar.resolveBlockScalar(token, strict, _onError);\n        }\n    }\n    return null;\n}\n/**\n * Create a new scalar token with `value`\n *\n * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,\n * as this function does not support any schema operations and won't check for such conflicts.\n *\n * @param value The string representation of the value, which will have its content properly indented.\n * @param context.end Comments and whitespace after the end of the value, or after the block scalar header. If undefined, a newline will be added.\n * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.\n * @param context.indent The indent level of the token.\n * @param context.inFlow Is this scalar within a flow collection? This may affect the resolved type of the token's value.\n * @param context.offset The offset position of the token.\n * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.\n */\nfunction createScalarToken(value, context) {\n    const { implicitKey = false, indent, inFlow = false, offset = -1, type = 'PLAIN' } = context;\n    const source = stringifyString.stringifyString({ type, value }, {\n        implicitKey,\n        indent: indent > 0 ? ' '.repeat(indent) : '',\n        inFlow,\n        options: { blockQuote: true, lineWidth: -1 }\n    });\n    const end = context.end ?? [\n        { type: 'newline', offset: -1, indent, source: '\\n' }\n    ];\n    switch (source[0]) {\n        case '|':\n        case '>': {\n            const he = source.indexOf('\\n');\n            const head = source.substring(0, he);\n            const body = source.substring(he + 1) + '\\n';\n            const props = [\n                { type: 'block-scalar-header', offset, indent, source: head }\n            ];\n            if (!addEndtoBlockProps(props, end))\n                props.push({ type: 'newline', offset: -1, indent, source: '\\n' });\n            return { type: 'block-scalar', offset, indent, props, source: body };\n        }\n        case '\"':\n            return { type: 'double-quoted-scalar', offset, indent, source, end };\n        case \"'\":\n            return { type: 'single-quoted-scalar', offset, indent, source, end };\n        default:\n            return { type: 'scalar', offset, indent, source, end };\n    }\n}\n/**\n * Set the value of `token` to the given string `value`, overwriting any previous contents and type that it may have.\n *\n * Best efforts are made to retain any comments previously associated with the `token`,\n * though all contents within a collection's `items` will be overwritten.\n *\n * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,\n * as this function does not support any schema operations and won't check for such conflicts.\n *\n * @param token Any token. If it does not include an `indent` value, the value will be stringified as if it were an implicit key.\n * @param value The string representation of the value, which will have its content properly indented.\n * @param context.afterKey In most cases, values after a key should have an additional level of indentation.\n * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.\n * @param context.inFlow Being within a flow collection may affect the resolved type of the token's value.\n * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.\n */\nfunction setScalarValue(token, value, context = {}) {\n    let { afterKey = false, implicitKey = false, inFlow = false, type } = context;\n    let indent = 'indent' in token ? token.indent : null;\n    if (afterKey && typeof indent === 'number')\n        indent += 2;\n    if (!type)\n        switch (token.type) {\n            case 'single-quoted-scalar':\n                type = 'QUOTE_SINGLE';\n                break;\n            case 'double-quoted-scalar':\n                type = 'QUOTE_DOUBLE';\n                break;\n            case 'block-scalar': {\n                const header = token.props[0];\n                if (header.type !== 'block-scalar-header')\n                    throw new Error('Invalid block scalar header');\n                type = header.source[0] === '>' ? 'BLOCK_FOLDED' : 'BLOCK_LITERAL';\n                break;\n            }\n            default:\n                type = 'PLAIN';\n        }\n    const source = stringifyString.stringifyString({ type, value }, {\n        implicitKey: implicitKey || indent === null,\n        indent: indent !== null && indent > 0 ? ' '.repeat(indent) : '',\n        inFlow,\n        options: { blockQuote: true, lineWidth: -1 }\n    });\n    switch (source[0]) {\n        case '|':\n        case '>':\n            setBlockScalarValue(token, source);\n            break;\n        case '\"':\n            setFlowScalarValue(token, source, 'double-quoted-scalar');\n            break;\n        case \"'\":\n            setFlowScalarValue(token, source, 'single-quoted-scalar');\n            break;\n        default:\n            setFlowScalarValue(token, source, 'scalar');\n    }\n}\nfunction setBlockScalarValue(token, source) {\n    const he = source.indexOf('\\n');\n    const head = source.substring(0, he);\n    const body = source.substring(he + 1) + '\\n';\n    if (token.type === 'block-scalar') {\n        const header = token.props[0];\n        if (header.type !== 'block-scalar-header')\n            throw new Error('Invalid block scalar header');\n        header.source = head;\n        token.source = body;\n    }\n    else {\n        const { offset } = token;\n        const indent = 'indent' in token ? token.indent : -1;\n        const props = [\n            { type: 'block-scalar-header', offset, indent, source: head }\n        ];\n        if (!addEndtoBlockProps(props, 'end' in token ? token.end : undefined))\n            props.push({ type: 'newline', offset: -1, indent, source: '\\n' });\n        for (const key of Object.keys(token))\n            if (key !== 'type' && key !== 'offset')\n                delete token[key];\n        Object.assign(token, { type: 'block-scalar', indent, props, source: body });\n    }\n}\n/** @returns `true` if last token is a newline */\nfunction addEndtoBlockProps(props, end) {\n    if (end)\n        for (const st of end)\n            switch (st.type) {\n                case 'space':\n                case 'comment':\n                    props.push(st);\n                    break;\n                case 'newline':\n                    props.push(st);\n                    return true;\n            }\n    return false;\n}\nfunction setFlowScalarValue(token, source, type) {\n    switch (token.type) {\n        case 'scalar':\n        case 'double-quoted-scalar':\n        case 'single-quoted-scalar':\n            token.type = type;\n            token.source = source;\n            break;\n        case 'block-scalar': {\n            const end = token.props.slice(1);\n            let oa = source.length;\n            if (token.props[0].type === 'block-scalar-header')\n                oa -= token.props[0].source.length;\n            for (const tok of end)\n                tok.offset += oa;\n            delete token.props;\n            Object.assign(token, { type, source, end });\n            break;\n        }\n        case 'block-map':\n        case 'block-seq': {\n            const offset = token.offset + source.length;\n            const nl = { type: 'newline', offset, indent: token.indent, source: '\\n' };\n            delete token.items;\n            Object.assign(token, { type, source, end: [nl] });\n            break;\n        }\n        default: {\n            const indent = 'indent' in token ? token.indent : -1;\n            const end = 'end' in token && Array.isArray(token.end)\n                ? token.end.filter(st => st.type === 'space' ||\n                    st.type === 'comment' ||\n                    st.type === 'newline')\n                : [];\n            for (const key of Object.keys(token))\n                if (key !== 'type' && key !== 'offset')\n                    delete token[key];\n            Object.assign(token, { type, indent, source, end });\n        }\n    }\n}\n\nexports.createScalarToken = createScalarToken;\nexports.resolveAsScalar = resolveAsScalar;\nexports.setScalarValue = setScalarValue;\n","'use strict';\n\n/**\n * Stringify a CST document, token, or collection item\n *\n * Fair warning: This applies no validation whatsoever, and\n * simply concatenates the sources in their logical order.\n */\nconst stringify = (cst) => 'type' in cst ? stringifyToken(cst) : stringifyItem(cst);\nfunction stringifyToken(token) {\n    switch (token.type) {\n        case 'block-scalar': {\n            let res = '';\n            for (const tok of token.props)\n                res += stringifyToken(tok);\n            return res + token.source;\n        }\n        case 'block-map':\n        case 'block-seq': {\n            let res = '';\n            for (const item of token.items)\n                res += stringifyItem(item);\n            return res;\n        }\n        case 'flow-collection': {\n            let res = token.start.source;\n            for (const item of token.items)\n                res += stringifyItem(item);\n            for (const st of token.end)\n                res += st.source;\n            return res;\n        }\n        case 'document': {\n            let res = stringifyItem(token);\n            if (token.end)\n                for (const st of token.end)\n                    res += st.source;\n            return res;\n        }\n        default: {\n            let res = token.source;\n            if ('end' in token && token.end)\n                for (const st of token.end)\n                    res += st.source;\n            return res;\n        }\n    }\n}\nfunction stringifyItem({ start, key, sep, value }) {\n    let res = '';\n    for (const st of start)\n        res += st.source;\n    if (key)\n        res += stringifyToken(key);\n    if (sep)\n        for (const st of sep)\n            res += st.source;\n    if (value)\n        res += stringifyToken(value);\n    return res;\n}\n\nexports.stringify = stringify;\n","'use strict';\n\nconst BREAK = Symbol('break visit');\nconst SKIP = Symbol('skip children');\nconst REMOVE = Symbol('remove item');\n/**\n * Apply a visitor to a CST document or item.\n *\n * Walks through the tree (depth-first) starting from the root, calling a\n * `visitor` function with two arguments when entering each item:\n *   - `item`: The current item, which included the following members:\n *     - `start: SourceToken[]`  Source tokens before the key or value,\n *       possibly including its anchor or tag.\n *     - `key?: Token | null`  Set for pair values. May then be `null`, if\n *       the key before the `:` separator is empty.\n *     - `sep?: SourceToken[]`  Source tokens between the key and the value,\n *       which should include the `:` map value indicator if `value` is set.\n *     - `value?: Token`  The value of a sequence item, or of a map pair.\n *   - `path`: The steps from the root to the current node, as an array of\n *     `['key' | 'value', number]` tuples.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this token, continue with\n *      next sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current item, then continue with the next one\n *   - `number`: Set the index of the next step. This is useful especially if\n *     the index of the current token has changed.\n *   - `function`: Define the next visitor for this item. After the original\n *     visitor is called on item entry, next visitors are called after handling\n *     a non-empty `key` and when exiting the item.\n */\nfunction visit(cst, visitor) {\n    if ('type' in cst && cst.type === 'document')\n        cst = { start: cst.start, value: cst.value };\n    _visit(Object.freeze([]), cst, visitor);\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisit.BREAK = BREAK;\n/** Do not visit the children of the current item */\nvisit.SKIP = SKIP;\n/** Remove the current item */\nvisit.REMOVE = REMOVE;\n/** Find the item at `path` from `cst` as the root */\nvisit.itemAtPath = (cst, path) => {\n    let item = cst;\n    for (const [field, index] of path) {\n        const tok = item?.[field];\n        if (tok && 'items' in tok) {\n            item = tok.items[index];\n        }\n        else\n            return undefined;\n    }\n    return item;\n};\n/**\n * Get the immediate parent collection of the item at `path` from `cst` as the root.\n *\n * Throws an error if the collection is not found, which should never happen if the item itself exists.\n */\nvisit.parentCollection = (cst, path) => {\n    const parent = visit.itemAtPath(cst, path.slice(0, -1));\n    const field = path[path.length - 1][0];\n    const coll = parent?.[field];\n    if (coll && 'items' in coll)\n        return coll;\n    throw new Error('Parent collection not found');\n};\nfunction _visit(path, item, visitor) {\n    let ctrl = visitor(item, path);\n    if (typeof ctrl === 'symbol')\n        return ctrl;\n    for (const field of ['key', 'value']) {\n        const token = item[field];\n        if (token && 'items' in token) {\n            for (let i = 0; i < token.items.length; ++i) {\n                const ci = _visit(Object.freeze(path.concat([[field, i]])), token.items[i], visitor);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK)\n                    return BREAK;\n                else if (ci === REMOVE) {\n                    token.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n            if (typeof ctrl === 'function' && field === 'key')\n                ctrl = ctrl(item, path);\n        }\n    }\n    return typeof ctrl === 'function' ? ctrl(item, path) : ctrl;\n}\n\nexports.visit = visit;\n","'use strict';\n\nvar cstScalar = require('./cst-scalar.js');\nvar cstStringify = require('./cst-stringify.js');\nvar cstVisit = require('./cst-visit.js');\n\n/** The byte order mark */\nconst BOM = '\\u{FEFF}';\n/** Start of doc-mode */\nconst DOCUMENT = '\\x02'; // C0: Start of Text\n/** Unexpected end of flow-mode */\nconst FLOW_END = '\\x18'; // C0: Cancel\n/** Next token is a scalar value */\nconst SCALAR = '\\x1f'; // C0: Unit Separator\n/** @returns `true` if `token` is a flow or block collection */\nconst isCollection = (token) => !!token && 'items' in token;\n/** @returns `true` if `token` is a flow or block scalar; not an alias */\nconst isScalar = (token) => !!token &&\n    (token.type === 'scalar' ||\n        token.type === 'single-quoted-scalar' ||\n        token.type === 'double-quoted-scalar' ||\n        token.type === 'block-scalar');\n/* istanbul ignore next */\n/** Get a printable representation of a lexer token */\nfunction prettyToken(token) {\n    switch (token) {\n        case BOM:\n            return '<BOM>';\n        case DOCUMENT:\n            return '<DOC>';\n        case FLOW_END:\n            return '<FLOW_END>';\n        case SCALAR:\n            return '<SCALAR>';\n        default:\n            return JSON.stringify(token);\n    }\n}\n/** Identify the type of a lexer token. May return `null` for unknown tokens. */\nfunction tokenType(source) {\n    switch (source) {\n        case BOM:\n            return 'byte-order-mark';\n        case DOCUMENT:\n            return 'doc-mode';\n        case FLOW_END:\n            return 'flow-error-end';\n        case SCALAR:\n            return 'scalar';\n        case '---':\n            return 'doc-start';\n        case '...':\n            return 'doc-end';\n        case '':\n        case '\\n':\n        case '\\r\\n':\n            return 'newline';\n        case '-':\n            return 'seq-item-ind';\n        case '?':\n            return 'explicit-key-ind';\n        case ':':\n            return 'map-value-ind';\n        case '{':\n            return 'flow-map-start';\n        case '}':\n            return 'flow-map-end';\n        case '[':\n            return 'flow-seq-start';\n        case ']':\n            return 'flow-seq-end';\n        case ',':\n            return 'comma';\n    }\n    switch (source[0]) {\n        case ' ':\n        case '\\t':\n            return 'space';\n        case '#':\n            return 'comment';\n        case '%':\n            return 'directive-line';\n        case '*':\n            return 'alias';\n        case '&':\n            return 'anchor';\n        case '!':\n            return 'tag';\n        case \"'\":\n            return 'single-quoted-scalar';\n        case '\"':\n            return 'double-quoted-scalar';\n        case '|':\n        case '>':\n            return 'block-scalar-header';\n    }\n    return null;\n}\n\nexports.createScalarToken = cstScalar.createScalarToken;\nexports.resolveAsScalar = cstScalar.resolveAsScalar;\nexports.setScalarValue = cstScalar.setScalarValue;\nexports.stringify = cstStringify.stringify;\nexports.visit = cstVisit.visit;\nexports.BOM = BOM;\nexports.DOCUMENT = DOCUMENT;\nexports.FLOW_END = FLOW_END;\nexports.SCALAR = SCALAR;\nexports.isCollection = isCollection;\nexports.isScalar = isScalar;\nexports.prettyToken = prettyToken;\nexports.tokenType = tokenType;\n","'use strict';\n\nvar cst = require('./cst.js');\n\n/*\nSTART -> stream\n\nstream\n  directive -> line-end -> stream\n  indent + line-end -> stream\n  [else] -> line-start\n\nline-end\n  comment -> line-end\n  newline -> .\n  input-end -> END\n\nline-start\n  doc-start -> doc\n  doc-end -> stream\n  [else] -> indent -> block-start\n\nblock-start\n  seq-item-start -> block-start\n  explicit-key-start -> block-start\n  map-value-start -> block-start\n  [else] -> doc\n\ndoc\n  line-end -> line-start\n  spaces -> doc\n  anchor -> doc\n  tag -> doc\n  flow-start -> flow -> doc\n  flow-end -> error -> doc\n  seq-item-start -> error -> doc\n  explicit-key-start -> error -> doc\n  map-value-start -> doc\n  alias -> doc\n  quote-start -> quoted-scalar -> doc\n  block-scalar-header -> line-end -> block-scalar(min) -> line-start\n  [else] -> plain-scalar(false, min) -> doc\n\nflow\n  line-end -> flow\n  spaces -> flow\n  anchor -> flow\n  tag -> flow\n  flow-start -> flow -> flow\n  flow-end -> .\n  seq-item-start -> error -> flow\n  explicit-key-start -> flow\n  map-value-start -> flow\n  alias -> flow\n  quote-start -> quoted-scalar -> flow\n  comma -> flow\n  [else] -> plain-scalar(true, 0) -> flow\n\nquoted-scalar\n  quote-end -> .\n  [else] -> quoted-scalar\n\nblock-scalar(min)\n  newline + peek(indent < min) -> .\n  [else] -> block-scalar(min)\n\nplain-scalar(is-flow, min)\n  scalar-end(is-flow) -> .\n  peek(newline + (indent < min)) -> .\n  [else] -> plain-scalar(min)\n*/\nfunction isEmpty(ch) {\n    switch (ch) {\n        case undefined:\n        case ' ':\n        case '\\n':\n        case '\\r':\n        case '\\t':\n            return true;\n        default:\n            return false;\n    }\n}\nconst hexDigits = '0123456789ABCDEFabcdef'.split('');\nconst tagChars = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-#;/?:@&=+$_.!~*'()\".split('');\nconst invalidFlowScalarChars = ',[]{}'.split('');\nconst invalidAnchorChars = ' ,[]{}\\n\\r\\t'.split('');\nconst isNotAnchorChar = (ch) => !ch || invalidAnchorChars.includes(ch);\n/**\n * Splits an input string into lexical tokens, i.e. smaller strings that are\n * easily identifiable by `tokens.tokenType()`.\n *\n * Lexing starts always in a \"stream\" context. Incomplete input may be buffered\n * until a complete token can be emitted.\n *\n * In addition to slices of the original input, the following control characters\n * may also be emitted:\n *\n * - `\\x02` (Start of Text): A document starts with the next token\n * - `\\x18` (Cancel): Unexpected end of flow-mode (indicates an error)\n * - `\\x1f` (Unit Separator): Next token is a scalar value\n * - `\\u{FEFF}` (Byte order mark): Emitted separately outside documents\n */\nclass Lexer {\n    constructor() {\n        /**\n         * Flag indicating whether the end of the current buffer marks the end of\n         * all input\n         */\n        this.atEnd = false;\n        /**\n         * Explicit indent set in block scalar header, as an offset from the current\n         * minimum indent, so e.g. set to 1 from a header `|2+`. Set to -1 if not\n         * explicitly set.\n         */\n        this.blockScalarIndent = -1;\n        /**\n         * Block scalars that include a + (keep) chomping indicator in their header\n         * include trailing empty lines, which are otherwise excluded from the\n         * scalar's contents.\n         */\n        this.blockScalarKeep = false;\n        /** Current input */\n        this.buffer = '';\n        /**\n         * Flag noting whether the map value indicator : can immediately follow this\n         * node within a flow context.\n         */\n        this.flowKey = false;\n        /** Count of surrounding flow collection levels. */\n        this.flowLevel = 0;\n        /**\n         * Minimum level of indentation required for next lines to be parsed as a\n         * part of the current scalar value.\n         */\n        this.indentNext = 0;\n        /** Indentation level of the current line. */\n        this.indentValue = 0;\n        /** Position of the next \\n character. */\n        this.lineEndPos = null;\n        /** Stores the state of the lexer if reaching the end of incpomplete input */\n        this.next = null;\n        /** A pointer to `buffer`; the current position of the lexer. */\n        this.pos = 0;\n    }\n    /**\n     * Generate YAML tokens from the `source` string. If `incomplete`,\n     * a part of the last line may be left as a buffer for the next call.\n     *\n     * @returns A generator of lexical tokens\n     */\n    *lex(source, incomplete = false) {\n        if (source) {\n            this.buffer = this.buffer ? this.buffer + source : source;\n            this.lineEndPos = null;\n        }\n        this.atEnd = !incomplete;\n        let next = this.next ?? 'stream';\n        while (next && (incomplete || this.hasChars(1)))\n            next = yield* this.parseNext(next);\n    }\n    atLineEnd() {\n        let i = this.pos;\n        let ch = this.buffer[i];\n        while (ch === ' ' || ch === '\\t')\n            ch = this.buffer[++i];\n        if (!ch || ch === '#' || ch === '\\n')\n            return true;\n        if (ch === '\\r')\n            return this.buffer[i + 1] === '\\n';\n        return false;\n    }\n    charAt(n) {\n        return this.buffer[this.pos + n];\n    }\n    continueScalar(offset) {\n        let ch = this.buffer[offset];\n        if (this.indentNext > 0) {\n            let indent = 0;\n            while (ch === ' ')\n                ch = this.buffer[++indent + offset];\n            if (ch === '\\r') {\n                const next = this.buffer[indent + offset + 1];\n                if (next === '\\n' || (!next && !this.atEnd))\n                    return offset + indent + 1;\n            }\n            return ch === '\\n' || indent >= this.indentNext || (!ch && !this.atEnd)\n                ? offset + indent\n                : -1;\n        }\n        if (ch === '-' || ch === '.') {\n            const dt = this.buffer.substr(offset, 3);\n            if ((dt === '---' || dt === '...') && isEmpty(this.buffer[offset + 3]))\n                return -1;\n        }\n        return offset;\n    }\n    getLine() {\n        let end = this.lineEndPos;\n        if (typeof end !== 'number' || (end !== -1 && end < this.pos)) {\n            end = this.buffer.indexOf('\\n', this.pos);\n            this.lineEndPos = end;\n        }\n        if (end === -1)\n            return this.atEnd ? this.buffer.substring(this.pos) : null;\n        if (this.buffer[end - 1] === '\\r')\n            end -= 1;\n        return this.buffer.substring(this.pos, end);\n    }\n    hasChars(n) {\n        return this.pos + n <= this.buffer.length;\n    }\n    setNext(state) {\n        this.buffer = this.buffer.substring(this.pos);\n        this.pos = 0;\n        this.lineEndPos = null;\n        this.next = state;\n        return null;\n    }\n    peek(n) {\n        return this.buffer.substr(this.pos, n);\n    }\n    *parseNext(next) {\n        switch (next) {\n            case 'stream':\n                return yield* this.parseStream();\n            case 'line-start':\n                return yield* this.parseLineStart();\n            case 'block-start':\n                return yield* this.parseBlockStart();\n            case 'doc':\n                return yield* this.parseDocument();\n            case 'flow':\n                return yield* this.parseFlowCollection();\n            case 'quoted-scalar':\n                return yield* this.parseQuotedScalar();\n            case 'block-scalar':\n                return yield* this.parseBlockScalar();\n            case 'plain-scalar':\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseStream() {\n        let line = this.getLine();\n        if (line === null)\n            return this.setNext('stream');\n        if (line[0] === cst.BOM) {\n            yield* this.pushCount(1);\n            line = line.substring(1);\n        }\n        if (line[0] === '%') {\n            let dirEnd = line.length;\n            const cs = line.indexOf('#');\n            if (cs !== -1) {\n                const ch = line[cs - 1];\n                if (ch === ' ' || ch === '\\t')\n                    dirEnd = cs - 1;\n            }\n            while (true) {\n                const ch = line[dirEnd - 1];\n                if (ch === ' ' || ch === '\\t')\n                    dirEnd -= 1;\n                else\n                    break;\n            }\n            const n = (yield* this.pushCount(dirEnd)) + (yield* this.pushSpaces(true));\n            yield* this.pushCount(line.length - n); // possible comment\n            this.pushNewline();\n            return 'stream';\n        }\n        if (this.atLineEnd()) {\n            const sp = yield* this.pushSpaces(true);\n            yield* this.pushCount(line.length - sp);\n            yield* this.pushNewline();\n            return 'stream';\n        }\n        yield cst.DOCUMENT;\n        return yield* this.parseLineStart();\n    }\n    *parseLineStart() {\n        const ch = this.charAt(0);\n        if (!ch && !this.atEnd)\n            return this.setNext('line-start');\n        if (ch === '-' || ch === '.') {\n            if (!this.atEnd && !this.hasChars(4))\n                return this.setNext('line-start');\n            const s = this.peek(3);\n            if (s === '---' && isEmpty(this.charAt(3))) {\n                yield* this.pushCount(3);\n                this.indentValue = 0;\n                this.indentNext = 0;\n                return 'doc';\n            }\n            else if (s === '...' && isEmpty(this.charAt(3))) {\n                yield* this.pushCount(3);\n                return 'stream';\n            }\n        }\n        this.indentValue = yield* this.pushSpaces(false);\n        if (this.indentNext > this.indentValue && !isEmpty(this.charAt(1)))\n            this.indentNext = this.indentValue;\n        return yield* this.parseBlockStart();\n    }\n    *parseBlockStart() {\n        const [ch0, ch1] = this.peek(2);\n        if (!ch1 && !this.atEnd)\n            return this.setNext('block-start');\n        if ((ch0 === '-' || ch0 === '?' || ch0 === ':') && isEmpty(ch1)) {\n            const n = (yield* this.pushCount(1)) + (yield* this.pushSpaces(true));\n            this.indentNext = this.indentValue + 1;\n            this.indentValue += n;\n            return yield* this.parseBlockStart();\n        }\n        return 'doc';\n    }\n    *parseDocument() {\n        yield* this.pushSpaces(true);\n        const line = this.getLine();\n        if (line === null)\n            return this.setNext('doc');\n        let n = yield* this.pushIndicators();\n        switch (line[n]) {\n            case '#':\n                yield* this.pushCount(line.length - n);\n            // fallthrough\n            case undefined:\n                yield* this.pushNewline();\n                return yield* this.parseLineStart();\n            case '{':\n            case '[':\n                yield* this.pushCount(1);\n                this.flowKey = false;\n                this.flowLevel = 1;\n                return 'flow';\n            case '}':\n            case ']':\n                // this is an error\n                yield* this.pushCount(1);\n                return 'doc';\n            case '*':\n                yield* this.pushUntil(isNotAnchorChar);\n                return 'doc';\n            case '\"':\n            case \"'\":\n                return yield* this.parseQuotedScalar();\n            case '|':\n            case '>':\n                n += yield* this.parseBlockScalarHeader();\n                n += yield* this.pushSpaces(true);\n                yield* this.pushCount(line.length - n);\n                yield* this.pushNewline();\n                return yield* this.parseBlockScalar();\n            default:\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseFlowCollection() {\n        let nl, sp;\n        let indent = -1;\n        do {\n            nl = yield* this.pushNewline();\n            if (nl > 0) {\n                sp = yield* this.pushSpaces(false);\n                this.indentValue = indent = sp;\n            }\n            else {\n                sp = 0;\n            }\n            sp += yield* this.pushSpaces(true);\n        } while (nl + sp > 0);\n        const line = this.getLine();\n        if (line === null)\n            return this.setNext('flow');\n        if ((indent !== -1 && indent < this.indentNext && line[0] !== '#') ||\n            (indent === 0 &&\n                (line.startsWith('---') || line.startsWith('...')) &&\n                isEmpty(line[3]))) {\n            // Allowing for the terminal ] or } at the same (rather than greater)\n            // indent level as the initial [ or { is technically invalid, but\n            // failing here would be surprising to users.\n            const atFlowEndMarker = indent === this.indentNext - 1 &&\n                this.flowLevel === 1 &&\n                (line[0] === ']' || line[0] === '}');\n            if (!atFlowEndMarker) {\n                // this is an error\n                this.flowLevel = 0;\n                yield cst.FLOW_END;\n                return yield* this.parseLineStart();\n            }\n        }\n        let n = 0;\n        while (line[n] === ',') {\n            n += yield* this.pushCount(1);\n            n += yield* this.pushSpaces(true);\n            this.flowKey = false;\n        }\n        n += yield* this.pushIndicators();\n        switch (line[n]) {\n            case undefined:\n                return 'flow';\n            case '#':\n                yield* this.pushCount(line.length - n);\n                return 'flow';\n            case '{':\n            case '[':\n                yield* this.pushCount(1);\n                this.flowKey = false;\n                this.flowLevel += 1;\n                return 'flow';\n            case '}':\n            case ']':\n                yield* this.pushCount(1);\n                this.flowKey = true;\n                this.flowLevel -= 1;\n                return this.flowLevel ? 'flow' : 'doc';\n            case '*':\n                yield* this.pushUntil(isNotAnchorChar);\n                return 'flow';\n            case '\"':\n            case \"'\":\n                this.flowKey = true;\n                return yield* this.parseQuotedScalar();\n            case ':': {\n                const next = this.charAt(1);\n                if (this.flowKey || isEmpty(next) || next === ',') {\n                    this.flowKey = false;\n                    yield* this.pushCount(1);\n                    yield* this.pushSpaces(true);\n                    return 'flow';\n                }\n            }\n            // fallthrough\n            default:\n                this.flowKey = false;\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseQuotedScalar() {\n        const quote = this.charAt(0);\n        let end = this.buffer.indexOf(quote, this.pos + 1);\n        if (quote === \"'\") {\n            while (end !== -1 && this.buffer[end + 1] === \"'\")\n                end = this.buffer.indexOf(\"'\", end + 2);\n        }\n        else {\n            // double-quote\n            while (end !== -1) {\n                let n = 0;\n                while (this.buffer[end - 1 - n] === '\\\\')\n                    n += 1;\n                if (n % 2 === 0)\n                    break;\n                end = this.buffer.indexOf('\"', end + 1);\n            }\n        }\n        // Only looking for newlines within the quotes\n        const qb = this.buffer.substring(0, end);\n        let nl = qb.indexOf('\\n', this.pos);\n        if (nl !== -1) {\n            while (nl !== -1) {\n                const cs = this.continueScalar(nl + 1);\n                if (cs === -1)\n                    break;\n                nl = qb.indexOf('\\n', cs);\n            }\n            if (nl !== -1) {\n                // this is an error caused by an unexpected unindent\n                end = nl - (qb[nl - 1] === '\\r' ? 2 : 1);\n            }\n        }\n        if (end === -1) {\n            if (!this.atEnd)\n                return this.setNext('quoted-scalar');\n            end = this.buffer.length;\n        }\n        yield* this.pushToIndex(end + 1, false);\n        return this.flowLevel ? 'flow' : 'doc';\n    }\n    *parseBlockScalarHeader() {\n        this.blockScalarIndent = -1;\n        this.blockScalarKeep = false;\n        let i = this.pos;\n        while (true) {\n            const ch = this.buffer[++i];\n            if (ch === '+')\n                this.blockScalarKeep = true;\n            else if (ch > '0' && ch <= '9')\n                this.blockScalarIndent = Number(ch) - 1;\n            else if (ch !== '-')\n                break;\n        }\n        return yield* this.pushUntil(ch => isEmpty(ch) || ch === '#');\n    }\n    *parseBlockScalar() {\n        let nl = this.pos - 1; // may be -1 if this.pos === 0\n        let indent = 0;\n        let ch;\n        loop: for (let i = this.pos; (ch = this.buffer[i]); ++i) {\n            switch (ch) {\n                case ' ':\n                    indent += 1;\n                    break;\n                case '\\n':\n                    nl = i;\n                    indent = 0;\n                    break;\n                case '\\r': {\n                    const next = this.buffer[i + 1];\n                    if (!next && !this.atEnd)\n                        return this.setNext('block-scalar');\n                    if (next === '\\n')\n                        break;\n                } // fallthrough\n                default:\n                    break loop;\n            }\n        }\n        if (!ch && !this.atEnd)\n            return this.setNext('block-scalar');\n        if (indent >= this.indentNext) {\n            if (this.blockScalarIndent === -1)\n                this.indentNext = indent;\n            else\n                this.indentNext += this.blockScalarIndent;\n            do {\n                const cs = this.continueScalar(nl + 1);\n                if (cs === -1)\n                    break;\n                nl = this.buffer.indexOf('\\n', cs);\n            } while (nl !== -1);\n            if (nl === -1) {\n                if (!this.atEnd)\n                    return this.setNext('block-scalar');\n                nl = this.buffer.length;\n            }\n        }\n        if (!this.blockScalarKeep) {\n            do {\n                let i = nl - 1;\n                let ch = this.buffer[i];\n                if (ch === '\\r')\n                    ch = this.buffer[--i];\n                const lastChar = i; // Drop the line if last char not more indented\n                while (ch === ' ' || ch === '\\t')\n                    ch = this.buffer[--i];\n                if (ch === '\\n' && i >= this.pos && i + 1 + indent > lastChar)\n                    nl = i;\n                else\n                    break;\n            } while (true);\n        }\n        yield cst.SCALAR;\n        yield* this.pushToIndex(nl + 1, true);\n        return yield* this.parseLineStart();\n    }\n    *parsePlainScalar() {\n        const inFlow = this.flowLevel > 0;\n        let end = this.pos - 1;\n        let i = this.pos - 1;\n        let ch;\n        while ((ch = this.buffer[++i])) {\n            if (ch === ':') {\n                const next = this.buffer[i + 1];\n                if (isEmpty(next) || (inFlow && next === ','))\n                    break;\n                end = i;\n            }\n            else if (isEmpty(ch)) {\n                let next = this.buffer[i + 1];\n                if (ch === '\\r') {\n                    if (next === '\\n') {\n                        i += 1;\n                        ch = '\\n';\n                        next = this.buffer[i + 1];\n                    }\n                    else\n                        end = i;\n                }\n                if (next === '#' || (inFlow && invalidFlowScalarChars.includes(next)))\n                    break;\n                if (ch === '\\n') {\n                    const cs = this.continueScalar(i + 1);\n                    if (cs === -1)\n                        break;\n                    i = Math.max(i, cs - 2); // to advance, but still account for ' #'\n                }\n            }\n            else {\n                if (inFlow && invalidFlowScalarChars.includes(ch))\n                    break;\n                end = i;\n            }\n        }\n        if (!ch && !this.atEnd)\n            return this.setNext('plain-scalar');\n        yield cst.SCALAR;\n        yield* this.pushToIndex(end + 1, true);\n        return inFlow ? 'flow' : 'doc';\n    }\n    *pushCount(n) {\n        if (n > 0) {\n            yield this.buffer.substr(this.pos, n);\n            this.pos += n;\n            return n;\n        }\n        return 0;\n    }\n    *pushToIndex(i, allowEmpty) {\n        const s = this.buffer.slice(this.pos, i);\n        if (s) {\n            yield s;\n            this.pos += s.length;\n            return s.length;\n        }\n        else if (allowEmpty)\n            yield '';\n        return 0;\n    }\n    *pushIndicators() {\n        switch (this.charAt(0)) {\n            case '!':\n                return ((yield* this.pushTag()) +\n                    (yield* this.pushSpaces(true)) +\n                    (yield* this.pushIndicators()));\n            case '&':\n                return ((yield* this.pushUntil(isNotAnchorChar)) +\n                    (yield* this.pushSpaces(true)) +\n                    (yield* this.pushIndicators()));\n            case '-': // this is an error\n            case '?': // this is an error outside flow collections\n            case ':': {\n                const inFlow = this.flowLevel > 0;\n                const ch1 = this.charAt(1);\n                if (isEmpty(ch1) || (inFlow && invalidFlowScalarChars.includes(ch1))) {\n                    if (!inFlow)\n                        this.indentNext = this.indentValue + 1;\n                    else if (this.flowKey)\n                        this.flowKey = false;\n                    return ((yield* this.pushCount(1)) +\n                        (yield* this.pushSpaces(true)) +\n                        (yield* this.pushIndicators()));\n                }\n            }\n        }\n        return 0;\n    }\n    *pushTag() {\n        if (this.charAt(1) === '<') {\n            let i = this.pos + 2;\n            let ch = this.buffer[i];\n            while (!isEmpty(ch) && ch !== '>')\n                ch = this.buffer[++i];\n            return yield* this.pushToIndex(ch === '>' ? i + 1 : i, false);\n        }\n        else {\n            let i = this.pos + 1;\n            let ch = this.buffer[i];\n            while (ch) {\n                if (tagChars.includes(ch))\n                    ch = this.buffer[++i];\n                else if (ch === '%' &&\n                    hexDigits.includes(this.buffer[i + 1]) &&\n                    hexDigits.includes(this.buffer[i + 2])) {\n                    ch = this.buffer[(i += 3)];\n                }\n                else\n                    break;\n            }\n            return yield* this.pushToIndex(i, false);\n        }\n    }\n    *pushNewline() {\n        const ch = this.buffer[this.pos];\n        if (ch === '\\n')\n            return yield* this.pushCount(1);\n        else if (ch === '\\r' && this.charAt(1) === '\\n')\n            return yield* this.pushCount(2);\n        else\n            return 0;\n    }\n    *pushSpaces(allowTabs) {\n        let i = this.pos - 1;\n        let ch;\n        do {\n            ch = this.buffer[++i];\n        } while (ch === ' ' || (allowTabs && ch === '\\t'));\n        const n = i - this.pos;\n        if (n > 0) {\n            yield this.buffer.substr(this.pos, n);\n            this.pos = i;\n        }\n        return n;\n    }\n    *pushUntil(test) {\n        let i = this.pos;\n        let ch = this.buffer[i];\n        while (!test(ch))\n            ch = this.buffer[++i];\n        return yield* this.pushToIndex(i, false);\n    }\n}\n\nexports.Lexer = Lexer;\n","'use strict';\n\n/**\n * Tracks newlines during parsing in order to provide an efficient API for\n * determining the one-indexed `{ line, col }` position for any offset\n * within the input.\n */\nclass LineCounter {\n    constructor() {\n        this.lineStarts = [];\n        /**\n         * Should be called in ascending order. Otherwise, call\n         * `lineCounter.lineStarts.sort()` before calling `linePos()`.\n         */\n        this.addNewLine = (offset) => this.lineStarts.push(offset);\n        /**\n         * Performs a binary search and returns the 1-indexed { line, col }\n         * position of `offset`. If `line === 0`, `addNewLine` has never been\n         * called or `offset` is before the first known newline.\n         */\n        this.linePos = (offset) => {\n            let low = 0;\n            let high = this.lineStarts.length;\n            while (low < high) {\n                const mid = (low + high) >> 1; // Math.floor((low + high) / 2)\n                if (this.lineStarts[mid] < offset)\n                    low = mid + 1;\n                else\n                    high = mid;\n            }\n            if (this.lineStarts[low] === offset)\n                return { line: low + 1, col: 1 };\n            if (low === 0)\n                return { line: 0, col: offset };\n            const start = this.lineStarts[low - 1];\n            return { line: low, col: offset - start + 1 };\n        };\n    }\n}\n\nexports.LineCounter = LineCounter;\n","'use strict';\n\nvar cst = require('./cst.js');\nvar lexer = require('./lexer.js');\n\nfunction includesToken(list, type) {\n    for (let i = 0; i < list.length; ++i)\n        if (list[i].type === type)\n            return true;\n    return false;\n}\nfunction findNonEmptyIndex(list) {\n    for (let i = 0; i < list.length; ++i) {\n        switch (list[i].type) {\n            case 'space':\n            case 'comment':\n            case 'newline':\n                break;\n            default:\n                return i;\n        }\n    }\n    return -1;\n}\nfunction isFlowToken(token) {\n    switch (token?.type) {\n        case 'alias':\n        case 'scalar':\n        case 'single-quoted-scalar':\n        case 'double-quoted-scalar':\n        case 'flow-collection':\n            return true;\n        default:\n            return false;\n    }\n}\nfunction getPrevProps(parent) {\n    switch (parent.type) {\n        case 'document':\n            return parent.start;\n        case 'block-map': {\n            const it = parent.items[parent.items.length - 1];\n            return it.sep ?? it.start;\n        }\n        case 'block-seq':\n            return parent.items[parent.items.length - 1].start;\n        /* istanbul ignore next should not happen */\n        default:\n            return [];\n    }\n}\n/** Note: May modify input array */\nfunction getFirstKeyStartProps(prev) {\n    if (prev.length === 0)\n        return [];\n    let i = prev.length;\n    loop: while (--i >= 0) {\n        switch (prev[i].type) {\n            case 'doc-start':\n            case 'explicit-key-ind':\n            case 'map-value-ind':\n            case 'seq-item-ind':\n            case 'newline':\n                break loop;\n        }\n    }\n    while (prev[++i]?.type === 'space') {\n        /* loop */\n    }\n    return prev.splice(i, prev.length);\n}\nfunction fixFlowSeqItems(fc) {\n    if (fc.start.type === 'flow-seq-start') {\n        for (const it of fc.items) {\n            if (it.sep &&\n                !it.value &&\n                !includesToken(it.start, 'explicit-key-ind') &&\n                !includesToken(it.sep, 'map-value-ind')) {\n                if (it.key)\n                    it.value = it.key;\n                delete it.key;\n                if (isFlowToken(it.value)) {\n                    if (it.value.end)\n                        Array.prototype.push.apply(it.value.end, it.sep);\n                    else\n                        it.value.end = it.sep;\n                }\n                else\n                    Array.prototype.push.apply(it.start, it.sep);\n                delete it.sep;\n            }\n        }\n    }\n}\n/**\n * A YAML concrete syntax tree (CST) parser\n *\n * ```ts\n * const src: string = ...\n * for (const token of new Parser().parse(src)) {\n *   // token: Token\n * }\n * ```\n *\n * To use the parser with a user-provided lexer:\n *\n * ```ts\n * function* parse(source: string, lexer: Lexer) {\n *   const parser = new Parser()\n *   for (const lexeme of lexer.lex(source))\n *     yield* parser.next(lexeme)\n *   yield* parser.end()\n * }\n *\n * const src: string = ...\n * const lexer = new Lexer()\n * for (const token of parse(src, lexer)) {\n *   // token: Token\n * }\n * ```\n */\nclass Parser {\n    /**\n     * @param onNewLine - If defined, called separately with the start position of\n     *   each new line (in `parse()`, including the start of input).\n     */\n    constructor(onNewLine) {\n        /** If true, space and sequence indicators count as indentation */\n        this.atNewLine = true;\n        /** If true, next token is a scalar value */\n        this.atScalar = false;\n        /** Current indentation level */\n        this.indent = 0;\n        /** Current offset since the start of parsing */\n        this.offset = 0;\n        /** On the same line with a block map key */\n        this.onKeyLine = false;\n        /** Top indicates the node that's currently being built */\n        this.stack = [];\n        /** The source of the current token, set in parse() */\n        this.source = '';\n        /** The type of the current token, set in parse() */\n        this.type = '';\n        // Must be defined after `next()`\n        this.lexer = new lexer.Lexer();\n        this.onNewLine = onNewLine;\n    }\n    /**\n     * Parse `source` as a YAML stream.\n     * If `incomplete`, a part of the last line may be left as a buffer for the next call.\n     *\n     * Errors are not thrown, but yielded as `{ type: 'error', message }` tokens.\n     *\n     * @returns A generator of tokens representing each directive, document, and other structure.\n     */\n    *parse(source, incomplete = false) {\n        if (this.onNewLine && this.offset === 0)\n            this.onNewLine(0);\n        for (const lexeme of this.lexer.lex(source, incomplete))\n            yield* this.next(lexeme);\n        if (!incomplete)\n            yield* this.end();\n    }\n    /**\n     * Advance the parser by the `source` of one lexical token.\n     */\n    *next(source) {\n        this.source = source;\n        if (process.env.LOG_TOKENS)\n            console.log('|', cst.prettyToken(source));\n        if (this.atScalar) {\n            this.atScalar = false;\n            yield* this.step();\n            this.offset += source.length;\n            return;\n        }\n        const type = cst.tokenType(source);\n        if (!type) {\n            const message = `Not a YAML token: ${source}`;\n            yield* this.pop({ type: 'error', offset: this.offset, message, source });\n            this.offset += source.length;\n        }\n        else if (type === 'scalar') {\n            this.atNewLine = false;\n            this.atScalar = true;\n            this.type = 'scalar';\n        }\n        else {\n            this.type = type;\n            yield* this.step();\n            switch (type) {\n                case 'newline':\n                    this.atNewLine = true;\n                    this.indent = 0;\n                    if (this.onNewLine)\n                        this.onNewLine(this.offset + source.length);\n                    break;\n                case 'space':\n                    if (this.atNewLine && source[0] === ' ')\n                        this.indent += source.length;\n                    break;\n                case 'explicit-key-ind':\n                case 'map-value-ind':\n                case 'seq-item-ind':\n                    if (this.atNewLine)\n                        this.indent += source.length;\n                    break;\n                case 'doc-mode':\n                case 'flow-error-end':\n                    return;\n                default:\n                    this.atNewLine = false;\n            }\n            this.offset += source.length;\n        }\n    }\n    /** Call at end of input to push out any remaining constructions */\n    *end() {\n        while (this.stack.length > 0)\n            yield* this.pop();\n    }\n    get sourceToken() {\n        const st = {\n            type: this.type,\n            offset: this.offset,\n            indent: this.indent,\n            source: this.source\n        };\n        return st;\n    }\n    *step() {\n        const top = this.peek(1);\n        if (this.type === 'doc-end' && (!top || top.type !== 'doc-end')) {\n            while (this.stack.length > 0)\n                yield* this.pop();\n            this.stack.push({\n                type: 'doc-end',\n                offset: this.offset,\n                source: this.source\n            });\n            return;\n        }\n        if (!top)\n            return yield* this.stream();\n        switch (top.type) {\n            case 'document':\n                return yield* this.document(top);\n            case 'alias':\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return yield* this.scalar(top);\n            case 'block-scalar':\n                return yield* this.blockScalar(top);\n            case 'block-map':\n                return yield* this.blockMap(top);\n            case 'block-seq':\n                return yield* this.blockSequence(top);\n            case 'flow-collection':\n                return yield* this.flowCollection(top);\n            case 'doc-end':\n                return yield* this.documentEnd(top);\n        }\n        /* istanbul ignore next should not happen */\n        yield* this.pop();\n    }\n    peek(n) {\n        return this.stack[this.stack.length - n];\n    }\n    *pop(error) {\n        const token = error ?? this.stack.pop();\n        /* istanbul ignore if should not happen */\n        if (!token) {\n            const message = 'Tried to pop an empty stack';\n            yield { type: 'error', offset: this.offset, source: '', message };\n        }\n        else if (this.stack.length === 0) {\n            yield token;\n        }\n        else {\n            const top = this.peek(1);\n            if (token.type === 'block-scalar') {\n                // Block scalars use their parent rather than header indent\n                token.indent = 'indent' in top ? top.indent : 0;\n            }\n            else if (token.type === 'flow-collection' && top.type === 'document') {\n                // Ignore all indent for top-level flow collections\n                token.indent = 0;\n            }\n            if (token.type === 'flow-collection')\n                fixFlowSeqItems(token);\n            switch (top.type) {\n                case 'document':\n                    top.value = token;\n                    break;\n                case 'block-scalar':\n                    top.props.push(token); // error\n                    break;\n                case 'block-map': {\n                    const it = top.items[top.items.length - 1];\n                    if (it.value) {\n                        top.items.push({ start: [], key: token, sep: [] });\n                        this.onKeyLine = true;\n                        return;\n                    }\n                    else if (it.sep) {\n                        it.value = token;\n                    }\n                    else {\n                        Object.assign(it, { key: token, sep: [] });\n                        this.onKeyLine = !includesToken(it.start, 'explicit-key-ind');\n                        return;\n                    }\n                    break;\n                }\n                case 'block-seq': {\n                    const it = top.items[top.items.length - 1];\n                    if (it.value)\n                        top.items.push({ start: [], value: token });\n                    else\n                        it.value = token;\n                    break;\n                }\n                case 'flow-collection': {\n                    const it = top.items[top.items.length - 1];\n                    if (!it || it.value)\n                        top.items.push({ start: [], key: token, sep: [] });\n                    else if (it.sep)\n                        it.value = token;\n                    else\n                        Object.assign(it, { key: token, sep: [] });\n                    return;\n                }\n                /* istanbul ignore next should not happen */\n                default:\n                    yield* this.pop();\n                    yield* this.pop(token);\n            }\n            if ((top.type === 'document' ||\n                top.type === 'block-map' ||\n                top.type === 'block-seq') &&\n                (token.type === 'block-map' || token.type === 'block-seq')) {\n                const last = token.items[token.items.length - 1];\n                if (last &&\n                    !last.sep &&\n                    !last.value &&\n                    last.start.length > 0 &&\n                    findNonEmptyIndex(last.start) === -1 &&\n                    (token.indent === 0 ||\n                        last.start.every(st => st.type !== 'comment' || st.indent < token.indent))) {\n                    if (top.type === 'document')\n                        top.end = last.start;\n                    else\n                        top.items.push({ start: last.start });\n                    token.items.splice(-1, 1);\n                }\n            }\n        }\n    }\n    *stream() {\n        switch (this.type) {\n            case 'directive-line':\n                yield { type: 'directive', offset: this.offset, source: this.source };\n                return;\n            case 'byte-order-mark':\n            case 'space':\n            case 'comment':\n            case 'newline':\n                yield this.sourceToken;\n                return;\n            case 'doc-mode':\n            case 'doc-start': {\n                const doc = {\n                    type: 'document',\n                    offset: this.offset,\n                    start: []\n                };\n                if (this.type === 'doc-start')\n                    doc.start.push(this.sourceToken);\n                this.stack.push(doc);\n                return;\n            }\n        }\n        yield {\n            type: 'error',\n            offset: this.offset,\n            message: `Unexpected ${this.type} token in YAML stream`,\n            source: this.source\n        };\n    }\n    *document(doc) {\n        if (doc.value)\n            return yield* this.lineEnd(doc);\n        switch (this.type) {\n            case 'doc-start': {\n                if (findNonEmptyIndex(doc.start) !== -1) {\n                    yield* this.pop();\n                    yield* this.step();\n                }\n                else\n                    doc.start.push(this.sourceToken);\n                return;\n            }\n            case 'anchor':\n            case 'tag':\n            case 'space':\n            case 'comment':\n            case 'newline':\n                doc.start.push(this.sourceToken);\n                return;\n        }\n        const bv = this.startBlockValue(doc);\n        if (bv)\n            this.stack.push(bv);\n        else {\n            yield {\n                type: 'error',\n                offset: this.offset,\n                message: `Unexpected ${this.type} token in YAML document`,\n                source: this.source\n            };\n        }\n    }\n    *scalar(scalar) {\n        if (this.type === 'map-value-ind') {\n            const prev = getPrevProps(this.peek(2));\n            const start = getFirstKeyStartProps(prev);\n            let sep;\n            if (scalar.end) {\n                sep = scalar.end;\n                sep.push(this.sourceToken);\n                delete scalar.end;\n            }\n            else\n                sep = [this.sourceToken];\n            const map = {\n                type: 'block-map',\n                offset: scalar.offset,\n                indent: scalar.indent,\n                items: [{ start, key: scalar, sep }]\n            };\n            this.onKeyLine = true;\n            this.stack[this.stack.length - 1] = map;\n        }\n        else\n            yield* this.lineEnd(scalar);\n    }\n    *blockScalar(scalar) {\n        switch (this.type) {\n            case 'space':\n            case 'comment':\n            case 'newline':\n                scalar.props.push(this.sourceToken);\n                return;\n            case 'scalar':\n                scalar.source = this.source;\n                // block-scalar source includes trailing newline\n                this.atNewLine = true;\n                this.indent = 0;\n                if (this.onNewLine) {\n                    let nl = this.source.indexOf('\\n') + 1;\n                    while (nl !== 0) {\n                        this.onNewLine(this.offset + nl);\n                        nl = this.source.indexOf('\\n', nl) + 1;\n                    }\n                }\n                yield* this.pop();\n                break;\n            /* istanbul ignore next should not happen */\n            default:\n                yield* this.pop();\n                yield* this.step();\n        }\n    }\n    *blockMap(map) {\n        const it = map.items[map.items.length - 1];\n        // it.sep is true-ish if pair already has key or : separator\n        switch (this.type) {\n            case 'newline':\n                this.onKeyLine = false;\n                if (it.value) {\n                    const end = 'end' in it.value ? it.value.end : undefined;\n                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;\n                    if (last?.type === 'comment')\n                        end?.push(this.sourceToken);\n                    else\n                        map.items.push({ start: [this.sourceToken] });\n                }\n                else if (it.sep) {\n                    it.sep.push(this.sourceToken);\n                }\n                else {\n                    it.start.push(this.sourceToken);\n                }\n                return;\n            case 'space':\n            case 'comment':\n                if (it.value) {\n                    map.items.push({ start: [this.sourceToken] });\n                }\n                else if (it.sep) {\n                    it.sep.push(this.sourceToken);\n                }\n                else {\n                    if (this.atIndentedComment(it.start, map.indent)) {\n                        const prev = map.items[map.items.length - 2];\n                        const end = prev?.value?.end;\n                        if (Array.isArray(end)) {\n                            Array.prototype.push.apply(end, it.start);\n                            end.push(this.sourceToken);\n                            map.items.pop();\n                            return;\n                        }\n                    }\n                    it.start.push(this.sourceToken);\n                }\n                return;\n        }\n        if (this.indent >= map.indent) {\n            const atNextItem = !this.onKeyLine && this.indent === map.indent && it.sep;\n            // For empty nodes, assign newline-separated not indented empty tokens to following node\n            let start = [];\n            if (atNextItem && it.sep && !it.value) {\n                const nl = [];\n                for (let i = 0; i < it.sep.length; ++i) {\n                    const st = it.sep[i];\n                    switch (st.type) {\n                        case 'newline':\n                            nl.push(i);\n                            break;\n                        case 'space':\n                            break;\n                        case 'comment':\n                            if (st.indent > map.indent)\n                                nl.length = 0;\n                            break;\n                        default:\n                            nl.length = 0;\n                    }\n                }\n                if (nl.length >= 2)\n                    start = it.sep.splice(nl[1]);\n            }\n            switch (this.type) {\n                case 'anchor':\n                case 'tag':\n                    if (atNextItem || it.value) {\n                        start.push(this.sourceToken);\n                        map.items.push({ start });\n                        this.onKeyLine = true;\n                    }\n                    else if (it.sep) {\n                        it.sep.push(this.sourceToken);\n                    }\n                    else {\n                        it.start.push(this.sourceToken);\n                    }\n                    return;\n                case 'explicit-key-ind':\n                    if (!it.sep && !includesToken(it.start, 'explicit-key-ind')) {\n                        it.start.push(this.sourceToken);\n                    }\n                    else if (atNextItem || it.value) {\n                        start.push(this.sourceToken);\n                        map.items.push({ start });\n                    }\n                    else {\n                        this.stack.push({\n                            type: 'block-map',\n                            offset: this.offset,\n                            indent: this.indent,\n                            items: [{ start: [this.sourceToken] }]\n                        });\n                    }\n                    this.onKeyLine = true;\n                    return;\n                case 'map-value-ind':\n                    if (includesToken(it.start, 'explicit-key-ind')) {\n                        if (!it.sep) {\n                            if (includesToken(it.start, 'newline')) {\n                                Object.assign(it, { key: null, sep: [this.sourceToken] });\n                            }\n                            else {\n                                const start = getFirstKeyStartProps(it.start);\n                                this.stack.push({\n                                    type: 'block-map',\n                                    offset: this.offset,\n                                    indent: this.indent,\n                                    items: [{ start, key: null, sep: [this.sourceToken] }]\n                                });\n                            }\n                        }\n                        else if (it.value) {\n                            map.items.push({ start: [], key: null, sep: [this.sourceToken] });\n                        }\n                        else if (includesToken(it.sep, 'map-value-ind')) {\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start, key: null, sep: [this.sourceToken] }]\n                            });\n                        }\n                        else if (isFlowToken(it.key) &&\n                            !includesToken(it.sep, 'newline')) {\n                            const start = getFirstKeyStartProps(it.start);\n                            const key = it.key;\n                            const sep = it.sep;\n                            sep.push(this.sourceToken);\n                            // @ts-expect-error type guard is wrong here\n                            delete it.key, delete it.sep;\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start, key, sep }]\n                            });\n                        }\n                        else if (start.length > 0) {\n                            // Not actually at next item\n                            it.sep = it.sep.concat(start, this.sourceToken);\n                        }\n                        else {\n                            it.sep.push(this.sourceToken);\n                        }\n                    }\n                    else {\n                        if (!it.sep) {\n                            Object.assign(it, { key: null, sep: [this.sourceToken] });\n                        }\n                        else if (it.value || atNextItem) {\n                            map.items.push({ start, key: null, sep: [this.sourceToken] });\n                        }\n                        else if (includesToken(it.sep, 'map-value-ind')) {\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start: [], key: null, sep: [this.sourceToken] }]\n                            });\n                        }\n                        else {\n                            it.sep.push(this.sourceToken);\n                        }\n                    }\n                    this.onKeyLine = true;\n                    return;\n                case 'alias':\n                case 'scalar':\n                case 'single-quoted-scalar':\n                case 'double-quoted-scalar': {\n                    const fs = this.flowScalar(this.type);\n                    if (atNextItem || it.value) {\n                        map.items.push({ start, key: fs, sep: [] });\n                        this.onKeyLine = true;\n                    }\n                    else if (it.sep) {\n                        this.stack.push(fs);\n                    }\n                    else {\n                        Object.assign(it, { key: fs, sep: [] });\n                        this.onKeyLine = true;\n                    }\n                    return;\n                }\n                default: {\n                    const bv = this.startBlockValue(map);\n                    if (bv) {\n                        if (atNextItem &&\n                            bv.type !== 'block-seq' &&\n                            includesToken(it.start, 'explicit-key-ind')) {\n                            map.items.push({ start });\n                        }\n                        this.stack.push(bv);\n                        return;\n                    }\n                }\n            }\n        }\n        yield* this.pop();\n        yield* this.step();\n    }\n    *blockSequence(seq) {\n        const it = seq.items[seq.items.length - 1];\n        switch (this.type) {\n            case 'newline':\n                if (it.value) {\n                    const end = 'end' in it.value ? it.value.end : undefined;\n                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;\n                    if (last?.type === 'comment')\n                        end?.push(this.sourceToken);\n                    else\n                        seq.items.push({ start: [this.sourceToken] });\n                }\n                else\n                    it.start.push(this.sourceToken);\n                return;\n            case 'space':\n            case 'comment':\n                if (it.value)\n                    seq.items.push({ start: [this.sourceToken] });\n                else {\n                    if (this.atIndentedComment(it.start, seq.indent)) {\n                        const prev = seq.items[seq.items.length - 2];\n                        const end = prev?.value?.end;\n                        if (Array.isArray(end)) {\n                            Array.prototype.push.apply(end, it.start);\n                            end.push(this.sourceToken);\n                            seq.items.pop();\n                            return;\n                        }\n                    }\n                    it.start.push(this.sourceToken);\n                }\n                return;\n            case 'anchor':\n            case 'tag':\n                if (it.value || this.indent <= seq.indent)\n                    break;\n                it.start.push(this.sourceToken);\n                return;\n            case 'seq-item-ind':\n                if (this.indent !== seq.indent)\n                    break;\n                if (it.value || includesToken(it.start, 'seq-item-ind'))\n                    seq.items.push({ start: [this.sourceToken] });\n                else\n                    it.start.push(this.sourceToken);\n                return;\n        }\n        if (this.indent > seq.indent) {\n            const bv = this.startBlockValue(seq);\n            if (bv) {\n                this.stack.push(bv);\n                return;\n            }\n        }\n        yield* this.pop();\n        yield* this.step();\n    }\n    *flowCollection(fc) {\n        const it = fc.items[fc.items.length - 1];\n        if (this.type === 'flow-error-end') {\n            let top;\n            do {\n                yield* this.pop();\n                top = this.peek(1);\n            } while (top && top.type === 'flow-collection');\n        }\n        else if (fc.end.length === 0) {\n            switch (this.type) {\n                case 'comma':\n                case 'explicit-key-ind':\n                    if (!it || it.sep)\n                        fc.items.push({ start: [this.sourceToken] });\n                    else\n                        it.start.push(this.sourceToken);\n                    return;\n                case 'map-value-ind':\n                    if (!it || it.value)\n                        fc.items.push({ start: [], key: null, sep: [this.sourceToken] });\n                    else if (it.sep)\n                        it.sep.push(this.sourceToken);\n                    else\n                        Object.assign(it, { key: null, sep: [this.sourceToken] });\n                    return;\n                case 'space':\n                case 'comment':\n                case 'newline':\n                case 'anchor':\n                case 'tag':\n                    if (!it || it.value)\n                        fc.items.push({ start: [this.sourceToken] });\n                    else if (it.sep)\n                        it.sep.push(this.sourceToken);\n                    else\n                        it.start.push(this.sourceToken);\n                    return;\n                case 'alias':\n                case 'scalar':\n                case 'single-quoted-scalar':\n                case 'double-quoted-scalar': {\n                    const fs = this.flowScalar(this.type);\n                    if (!it || it.value)\n                        fc.items.push({ start: [], key: fs, sep: [] });\n                    else if (it.sep)\n                        this.stack.push(fs);\n                    else\n                        Object.assign(it, { key: fs, sep: [] });\n                    return;\n                }\n                case 'flow-map-end':\n                case 'flow-seq-end':\n                    fc.end.push(this.sourceToken);\n                    return;\n            }\n            const bv = this.startBlockValue(fc);\n            /* istanbul ignore else should not happen */\n            if (bv)\n                this.stack.push(bv);\n            else {\n                yield* this.pop();\n                yield* this.step();\n            }\n        }\n        else {\n            const parent = this.peek(2);\n            if (parent.type === 'block-map' &&\n                ((this.type === 'map-value-ind' && parent.indent === fc.indent) ||\n                    (this.type === 'newline' &&\n                        !parent.items[parent.items.length - 1].sep))) {\n                yield* this.pop();\n                yield* this.step();\n            }\n            else if (this.type === 'map-value-ind' &&\n                parent.type !== 'flow-collection') {\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                fixFlowSeqItems(fc);\n                const sep = fc.end.splice(1, fc.end.length);\n                sep.push(this.sourceToken);\n                const map = {\n                    type: 'block-map',\n                    offset: fc.offset,\n                    indent: fc.indent,\n                    items: [{ start, key: fc, sep }]\n                };\n                this.onKeyLine = true;\n                this.stack[this.stack.length - 1] = map;\n            }\n            else {\n                yield* this.lineEnd(fc);\n            }\n        }\n    }\n    flowScalar(type) {\n        if (this.onNewLine) {\n            let nl = this.source.indexOf('\\n') + 1;\n            while (nl !== 0) {\n                this.onNewLine(this.offset + nl);\n                nl = this.source.indexOf('\\n', nl) + 1;\n            }\n        }\n        return {\n            type,\n            offset: this.offset,\n            indent: this.indent,\n            source: this.source\n        };\n    }\n    startBlockValue(parent) {\n        switch (this.type) {\n            case 'alias':\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return this.flowScalar(this.type);\n            case 'block-scalar-header':\n                return {\n                    type: 'block-scalar',\n                    offset: this.offset,\n                    indent: this.indent,\n                    props: [this.sourceToken],\n                    source: ''\n                };\n            case 'flow-map-start':\n            case 'flow-seq-start':\n                return {\n                    type: 'flow-collection',\n                    offset: this.offset,\n                    indent: this.indent,\n                    start: this.sourceToken,\n                    items: [],\n                    end: []\n                };\n            case 'seq-item-ind':\n                return {\n                    type: 'block-seq',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start: [this.sourceToken] }]\n                };\n            case 'explicit-key-ind': {\n                this.onKeyLine = true;\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                start.push(this.sourceToken);\n                return {\n                    type: 'block-map',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start }]\n                };\n            }\n            case 'map-value-ind': {\n                this.onKeyLine = true;\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                return {\n                    type: 'block-map',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start, key: null, sep: [this.sourceToken] }]\n                };\n            }\n        }\n        return null;\n    }\n    atIndentedComment(start, indent) {\n        if (this.type !== 'comment')\n            return false;\n        if (this.indent <= indent)\n            return false;\n        return start.every(st => st.type === 'newline' || st.type === 'space');\n    }\n    *documentEnd(docEnd) {\n        if (this.type !== 'doc-mode') {\n            if (docEnd.end)\n                docEnd.end.push(this.sourceToken);\n            else\n                docEnd.end = [this.sourceToken];\n            if (this.type === 'newline')\n                yield* this.pop();\n        }\n    }\n    *lineEnd(token) {\n        switch (this.type) {\n            case 'comma':\n            case 'doc-start':\n            case 'doc-end':\n            case 'flow-seq-end':\n            case 'flow-map-end':\n            case 'map-value-ind':\n                yield* this.pop();\n                yield* this.step();\n                break;\n            case 'newline':\n                this.onKeyLine = false;\n            // fallthrough\n            case 'space':\n            case 'comment':\n            default:\n                // all other values are errors\n                if (token.end)\n                    token.end.push(this.sourceToken);\n                else\n                    token.end = [this.sourceToken];\n                if (this.type === 'newline')\n                    yield* this.pop();\n        }\n    }\n}\n\nexports.Parser = Parser;\n","'use strict';\n\nvar composer = require('./compose/composer.js');\nvar Document = require('./doc/Document.js');\nvar errors = require('./errors.js');\nvar log = require('./log.js');\nvar lineCounter = require('./parse/line-counter.js');\nvar parser = require('./parse/parser.js');\n\nfunction parseOptions(options) {\n    const prettyErrors = options.prettyErrors !== false;\n    const lineCounter$1 = options.lineCounter || (prettyErrors && new lineCounter.LineCounter()) || null;\n    return { lineCounter: lineCounter$1, prettyErrors };\n}\n/**\n * Parse the input as a stream of YAML documents.\n *\n * Documents should be separated from each other by `...` or `---` marker lines.\n *\n * @returns If an empty `docs` array is returned, it will be of type\n *   EmptyStream and contain additional stream information. In\n *   TypeScript, you should use `'empty' in docs` as a type guard for it.\n */\nfunction parseAllDocuments(source, options = {}) {\n    const { lineCounter, prettyErrors } = parseOptions(options);\n    const parser$1 = new parser.Parser(lineCounter?.addNewLine);\n    const composer$1 = new composer.Composer(options);\n    const docs = Array.from(composer$1.compose(parser$1.parse(source)));\n    if (prettyErrors && lineCounter)\n        for (const doc of docs) {\n            doc.errors.forEach(errors.prettifyError(source, lineCounter));\n            doc.warnings.forEach(errors.prettifyError(source, lineCounter));\n        }\n    if (docs.length > 0)\n        return docs;\n    return Object.assign([], { empty: true }, composer$1.streamInfo());\n}\n/** Parse an input string into a single YAML.Document */\nfunction parseDocument(source, options = {}) {\n    const { lineCounter, prettyErrors } = parseOptions(options);\n    const parser$1 = new parser.Parser(lineCounter?.addNewLine);\n    const composer$1 = new composer.Composer(options);\n    // `doc` is always set by compose.end(true) at the very latest\n    let doc = null;\n    for (const _doc of composer$1.compose(parser$1.parse(source), true, source.length)) {\n        if (!doc)\n            doc = _doc;\n        else if (doc.options.logLevel !== 'silent') {\n            doc.errors.push(new errors.YAMLParseError(_doc.range.slice(0, 2), 'MULTIPLE_DOCS', 'Source contains multiple documents; please use YAML.parseAllDocuments()'));\n            break;\n        }\n    }\n    if (prettyErrors && lineCounter) {\n        doc.errors.forEach(errors.prettifyError(source, lineCounter));\n        doc.warnings.forEach(errors.prettifyError(source, lineCounter));\n    }\n    return doc;\n}\nfunction parse(src, reviver, options) {\n    let _reviver = undefined;\n    if (typeof reviver === 'function') {\n        _reviver = reviver;\n    }\n    else if (options === undefined && reviver && typeof reviver === 'object') {\n        options = reviver;\n    }\n    const doc = parseDocument(src, options);\n    if (!doc)\n        return null;\n    doc.warnings.forEach(warning => log.warn(doc.options.logLevel, warning));\n    if (doc.errors.length > 0) {\n        if (doc.options.logLevel !== 'silent')\n            throw doc.errors[0];\n        else\n            doc.errors = [];\n    }\n    return doc.toJS(Object.assign({ reviver: _reviver }, options));\n}\nfunction stringify(value, replacer, options) {\n    let _replacer = null;\n    if (typeof replacer === 'function' || Array.isArray(replacer)) {\n        _replacer = replacer;\n    }\n    else if (options === undefined && replacer) {\n        options = replacer;\n    }\n    if (typeof options === 'string')\n        options = options.length;\n    if (typeof options === 'number') {\n        const indent = Math.round(options);\n        options = indent < 1 ? undefined : indent > 8 ? { indent: 8 } : { indent };\n    }\n    if (value === undefined) {\n        const { keepUndefined } = options ?? replacer ?? {};\n        if (!keepUndefined)\n            return undefined;\n    }\n    return new Document.Document(value, _replacer, options).toString(options);\n}\n\nexports.parse = parse;\nexports.parseAllDocuments = parseAllDocuments;\nexports.parseDocument = parseDocument;\nexports.stringify = stringify;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar map = require('./common/map.js');\nvar seq = require('./common/seq.js');\nvar string = require('./common/string.js');\nvar tags = require('./tags.js');\n\nconst sortMapEntriesByKey = (a, b) => a.key < b.key ? -1 : a.key > b.key ? 1 : 0;\nclass Schema {\n    constructor({ compat, customTags, merge, resolveKnownTags, schema, sortMapEntries, toStringDefaults }) {\n        this.compat = Array.isArray(compat)\n            ? tags.getTags(compat, 'compat')\n            : compat\n                ? tags.getTags(null, compat)\n                : null;\n        this.merge = !!merge;\n        this.name = (typeof schema === 'string' && schema) || 'core';\n        this.knownTags = resolveKnownTags ? tags.coreKnownTags : {};\n        this.tags = tags.getTags(customTags, this.name);\n        this.toStringOptions = toStringDefaults ?? null;\n        Object.defineProperty(this, identity.MAP, { value: map.map });\n        Object.defineProperty(this, identity.SCALAR, { value: string.string });\n        Object.defineProperty(this, identity.SEQ, { value: seq.seq });\n        // Used by createMap()\n        this.sortMapEntries =\n            typeof sortMapEntries === 'function'\n                ? sortMapEntries\n                : sortMapEntries === true\n                    ? sortMapEntriesByKey\n                    : null;\n    }\n    clone() {\n        const copy = Object.create(Schema.prototype, Object.getOwnPropertyDescriptors(this));\n        copy.tags = this.tags.slice();\n        return copy;\n    }\n}\n\nexports.Schema = Schema;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar YAMLMap = require('../../nodes/YAMLMap.js');\n\nconst map = {\n    collection: 'map',\n    default: true,\n    nodeClass: YAMLMap.YAMLMap,\n    tag: 'tag:yaml.org,2002:map',\n    resolve(map, onError) {\n        if (!identity.isMap(map))\n            onError('Expected a mapping for this tag');\n        return map;\n    },\n    createNode: (schema, obj, ctx) => YAMLMap.YAMLMap.from(schema, obj, ctx)\n};\n\nexports.map = map;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\n\nconst nullTag = {\n    identify: value => value == null,\n    createNode: () => new Scalar.Scalar(null),\n    default: true,\n    tag: 'tag:yaml.org,2002:null',\n    test: /^(?:~|[Nn]ull|NULL)?$/,\n    resolve: () => new Scalar.Scalar(null),\n    stringify: ({ source }, ctx) => typeof source === 'string' && nullTag.test.test(source)\n        ? source\n        : ctx.options.nullStr\n};\n\nexports.nullTag = nullTag;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar YAMLSeq = require('../../nodes/YAMLSeq.js');\n\nconst seq = {\n    collection: 'seq',\n    default: true,\n    nodeClass: YAMLSeq.YAMLSeq,\n    tag: 'tag:yaml.org,2002:seq',\n    resolve(seq, onError) {\n        if (!identity.isSeq(seq))\n            onError('Expected a sequence for this tag');\n        return seq;\n    },\n    createNode: (schema, obj, ctx) => YAMLSeq.YAMLSeq.from(schema, obj, ctx)\n};\n\nexports.seq = seq;\n","'use strict';\n\nvar stringifyString = require('../../stringify/stringifyString.js');\n\nconst string = {\n    identify: value => typeof value === 'string',\n    default: true,\n    tag: 'tag:yaml.org,2002:str',\n    resolve: str => str,\n    stringify(item, ctx, onComment, onChompKeep) {\n        ctx = Object.assign({ actualString: true }, ctx);\n        return stringifyString.stringifyString(item, ctx, onComment, onChompKeep);\n    }\n};\n\nexports.string = string;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\n\nconst boolTag = {\n    identify: value => typeof value === 'boolean',\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,\n    resolve: str => new Scalar.Scalar(str[0] === 't' || str[0] === 'T'),\n    stringify({ source, value }, ctx) {\n        if (source && boolTag.test.test(source)) {\n            const sv = source[0] === 't' || source[0] === 'T';\n            if (value === sv)\n                return source;\n        }\n        return value ? ctx.options.trueStr : ctx.options.falseStr;\n    }\n};\n\nexports.boolTag = boolTag;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst floatNaN = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^(?:[-+]?\\.(?:inf|Inf|INF|nan|NaN|NAN))$/,\n    resolve: str => str.slice(-3).toLowerCase() === 'nan'\n        ? NaN\n        : str[0] === '-'\n            ? Number.NEGATIVE_INFINITY\n            : Number.POSITIVE_INFINITY,\n    stringify: stringifyNumber.stringifyNumber\n};\nconst floatExp = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'EXP',\n    test: /^[-+]?(?:\\.[0-9]+|[0-9]+(?:\\.[0-9]*)?)[eE][-+]?[0-9]+$/,\n    resolve: str => parseFloat(str),\n    stringify(node) {\n        const num = Number(node.value);\n        return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);\n    }\n};\nconst float = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?(?:\\.[0-9]+|[0-9]+\\.[0-9]*)$/,\n    resolve(str) {\n        const node = new Scalar.Scalar(parseFloat(str));\n        const dot = str.indexOf('.');\n        if (dot !== -1 && str[str.length - 1] === '0')\n            node.minFractionDigits = str.length - dot - 1;\n        return node;\n    },\n    stringify: stringifyNumber.stringifyNumber\n};\n\nexports.float = float;\nexports.floatExp = floatExp;\nexports.floatNaN = floatNaN;\n","'use strict';\n\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst intIdentify = (value) => typeof value === 'bigint' || Number.isInteger(value);\nconst intResolve = (str, offset, radix, { intAsBigInt }) => (intAsBigInt ? BigInt(str) : parseInt(str.substring(offset), radix));\nfunction intStringify(node, radix, prefix) {\n    const { value } = node;\n    if (intIdentify(value) && value >= 0)\n        return prefix + value.toString(radix);\n    return stringifyNumber.stringifyNumber(node);\n}\nconst intOct = {\n    identify: value => intIdentify(value) && value >= 0,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'OCT',\n    test: /^0o[0-7]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 8, opt),\n    stringify: node => intStringify(node, 8, '0o')\n};\nconst int = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    test: /^[-+]?[0-9]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),\n    stringify: stringifyNumber.stringifyNumber\n};\nconst intHex = {\n    identify: value => intIdentify(value) && value >= 0,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'HEX',\n    test: /^0x[0-9a-fA-F]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),\n    stringify: node => intStringify(node, 16, '0x')\n};\n\nexports.int = int;\nexports.intHex = intHex;\nexports.intOct = intOct;\n","'use strict';\n\nvar map = require('../common/map.js');\nvar _null = require('../common/null.js');\nvar seq = require('../common/seq.js');\nvar string = require('../common/string.js');\nvar bool = require('./bool.js');\nvar float = require('./float.js');\nvar int = require('./int.js');\n\nconst schema = [\n    map.map,\n    seq.seq,\n    string.string,\n    _null.nullTag,\n    bool.boolTag,\n    int.intOct,\n    int.int,\n    int.intHex,\n    float.floatNaN,\n    float.floatExp,\n    float.float\n];\n\nexports.schema = schema;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar map = require('../common/map.js');\nvar seq = require('../common/seq.js');\n\nfunction intIdentify(value) {\n    return typeof value === 'bigint' || Number.isInteger(value);\n}\nconst stringifyJSON = ({ value }) => JSON.stringify(value);\nconst jsonScalars = [\n    {\n        identify: value => typeof value === 'string',\n        default: true,\n        tag: 'tag:yaml.org,2002:str',\n        resolve: str => str,\n        stringify: stringifyJSON\n    },\n    {\n        identify: value => value == null,\n        createNode: () => new Scalar.Scalar(null),\n        default: true,\n        tag: 'tag:yaml.org,2002:null',\n        test: /^null$/,\n        resolve: () => null,\n        stringify: stringifyJSON\n    },\n    {\n        identify: value => typeof value === 'boolean',\n        default: true,\n        tag: 'tag:yaml.org,2002:bool',\n        test: /^true|false$/,\n        resolve: str => str === 'true',\n        stringify: stringifyJSON\n    },\n    {\n        identify: intIdentify,\n        default: true,\n        tag: 'tag:yaml.org,2002:int',\n        test: /^-?(?:0|[1-9][0-9]*)$/,\n        resolve: (str, _onError, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str, 10),\n        stringify: ({ value }) => intIdentify(value) ? value.toString() : JSON.stringify(value)\n    },\n    {\n        identify: value => typeof value === 'number',\n        default: true,\n        tag: 'tag:yaml.org,2002:float',\n        test: /^-?(?:0|[1-9][0-9]*)(?:\\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,\n        resolve: str => parseFloat(str),\n        stringify: stringifyJSON\n    }\n];\nconst jsonError = {\n    default: true,\n    tag: '',\n    test: /^/,\n    resolve(str, onError) {\n        onError(`Unresolved plain scalar ${JSON.stringify(str)}`);\n        return str;\n    }\n};\nconst schema = [map.map, seq.seq].concat(jsonScalars, jsonError);\n\nexports.schema = schema;\n","'use strict';\n\nvar map = require('./common/map.js');\nvar _null = require('./common/null.js');\nvar seq = require('./common/seq.js');\nvar string = require('./common/string.js');\nvar bool = require('./core/bool.js');\nvar float = require('./core/float.js');\nvar int = require('./core/int.js');\nvar schema = require('./core/schema.js');\nvar schema$1 = require('./json/schema.js');\nvar binary = require('./yaml-1.1/binary.js');\nvar omap = require('./yaml-1.1/omap.js');\nvar pairs = require('./yaml-1.1/pairs.js');\nvar schema$2 = require('./yaml-1.1/schema.js');\nvar set = require('./yaml-1.1/set.js');\nvar timestamp = require('./yaml-1.1/timestamp.js');\n\nconst schemas = new Map([\n    ['core', schema.schema],\n    ['failsafe', [map.map, seq.seq, string.string]],\n    ['json', schema$1.schema],\n    ['yaml11', schema$2.schema],\n    ['yaml-1.1', schema$2.schema]\n]);\nconst tagsByName = {\n    binary: binary.binary,\n    bool: bool.boolTag,\n    float: float.float,\n    floatExp: float.floatExp,\n    floatNaN: float.floatNaN,\n    floatTime: timestamp.floatTime,\n    int: int.int,\n    intHex: int.intHex,\n    intOct: int.intOct,\n    intTime: timestamp.intTime,\n    map: map.map,\n    null: _null.nullTag,\n    omap: omap.omap,\n    pairs: pairs.pairs,\n    seq: seq.seq,\n    set: set.set,\n    timestamp: timestamp.timestamp\n};\nconst coreKnownTags = {\n    'tag:yaml.org,2002:binary': binary.binary,\n    'tag:yaml.org,2002:omap': omap.omap,\n    'tag:yaml.org,2002:pairs': pairs.pairs,\n    'tag:yaml.org,2002:set': set.set,\n    'tag:yaml.org,2002:timestamp': timestamp.timestamp\n};\nfunction getTags(customTags, schemaName) {\n    let tags = schemas.get(schemaName);\n    if (!tags) {\n        if (Array.isArray(customTags))\n            tags = [];\n        else {\n            const keys = Array.from(schemas.keys())\n                .filter(key => key !== 'yaml11')\n                .map(key => JSON.stringify(key))\n                .join(', ');\n            throw new Error(`Unknown schema \"${schemaName}\"; use one of ${keys} or define customTags array`);\n        }\n    }\n    if (Array.isArray(customTags)) {\n        for (const tag of customTags)\n            tags = tags.concat(tag);\n    }\n    else if (typeof customTags === 'function') {\n        tags = customTags(tags.slice());\n    }\n    return tags.map(tag => {\n        if (typeof tag !== 'string')\n            return tag;\n        const tagObj = tagsByName[tag];\n        if (tagObj)\n            return tagObj;\n        const keys = Object.keys(tagsByName)\n            .map(key => JSON.stringify(key))\n            .join(', ');\n        throw new Error(`Unknown custom tag \"${tag}\"; use one of ${keys}`);\n    });\n}\n\nexports.coreKnownTags = coreKnownTags;\nexports.getTags = getTags;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar stringifyString = require('../../stringify/stringifyString.js');\n\nconst binary = {\n    identify: value => value instanceof Uint8Array,\n    default: false,\n    tag: 'tag:yaml.org,2002:binary',\n    /**\n     * Returns a Buffer in node and an Uint8Array in browsers\n     *\n     * To use the resulting buffer as an image, you'll want to do something like:\n     *\n     *   const blob = new Blob([buffer], { type: 'image/jpeg' })\n     *   document.querySelector('#photo').src = URL.createObjectURL(blob)\n     */\n    resolve(src, onError) {\n        if (typeof Buffer === 'function') {\n            return Buffer.from(src, 'base64');\n        }\n        else if (typeof atob === 'function') {\n            // On IE 11, atob() can't handle newlines\n            const str = atob(src.replace(/[\\n\\r]/g, ''));\n            const buffer = new Uint8Array(str.length);\n            for (let i = 0; i < str.length; ++i)\n                buffer[i] = str.charCodeAt(i);\n            return buffer;\n        }\n        else {\n            onError('This environment does not support reading binary tags; either Buffer or atob is required');\n            return src;\n        }\n    },\n    stringify({ comment, type, value }, ctx, onComment, onChompKeep) {\n        const buf = value; // checked earlier by binary.identify()\n        let str;\n        if (typeof Buffer === 'function') {\n            str =\n                buf instanceof Buffer\n                    ? buf.toString('base64')\n                    : Buffer.from(buf.buffer).toString('base64');\n        }\n        else if (typeof btoa === 'function') {\n            let s = '';\n            for (let i = 0; i < buf.length; ++i)\n                s += String.fromCharCode(buf[i]);\n            str = btoa(s);\n        }\n        else {\n            throw new Error('This environment does not support writing binary tags; either Buffer or btoa is required');\n        }\n        if (!type)\n            type = Scalar.Scalar.BLOCK_LITERAL;\n        if (type !== Scalar.Scalar.QUOTE_DOUBLE) {\n            const lineWidth = Math.max(ctx.options.lineWidth - ctx.indent.length, ctx.options.minContentWidth);\n            const n = Math.ceil(str.length / lineWidth);\n            const lines = new Array(n);\n            for (let i = 0, o = 0; i < n; ++i, o += lineWidth) {\n                lines[i] = str.substr(o, lineWidth);\n            }\n            str = lines.join(type === Scalar.Scalar.BLOCK_LITERAL ? '\\n' : ' ');\n        }\n        return stringifyString.stringifyString({ comment, type, value: str }, ctx, onComment, onChompKeep);\n    }\n};\n\nexports.binary = binary;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\n\nfunction boolStringify({ value, source }, ctx) {\n    const boolObj = value ? trueTag : falseTag;\n    if (source && boolObj.test.test(source))\n        return source;\n    return value ? ctx.options.trueStr : ctx.options.falseStr;\n}\nconst trueTag = {\n    identify: value => value === true,\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,\n    resolve: () => new Scalar.Scalar(true),\n    stringify: boolStringify\n};\nconst falseTag = {\n    identify: value => value === false,\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/i,\n    resolve: () => new Scalar.Scalar(false),\n    stringify: boolStringify\n};\n\nexports.falseTag = falseTag;\nexports.trueTag = trueTag;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst floatNaN = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?\\.(?:inf|Inf|INF|nan|NaN|NAN)$/,\n    resolve: (str) => str.slice(-3).toLowerCase() === 'nan'\n        ? NaN\n        : str[0] === '-'\n            ? Number.NEGATIVE_INFINITY\n            : Number.POSITIVE_INFINITY,\n    stringify: stringifyNumber.stringifyNumber\n};\nconst floatExp = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'EXP',\n    test: /^[-+]?(?:[0-9][0-9_]*)?(?:\\.[0-9_]*)?[eE][-+]?[0-9]+$/,\n    resolve: (str) => parseFloat(str.replace(/_/g, '')),\n    stringify(node) {\n        const num = Number(node.value);\n        return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);\n    }\n};\nconst float = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?(?:[0-9][0-9_]*)?\\.[0-9_]*$/,\n    resolve(str) {\n        const node = new Scalar.Scalar(parseFloat(str.replace(/_/g, '')));\n        const dot = str.indexOf('.');\n        if (dot !== -1) {\n            const f = str.substring(dot + 1).replace(/_/g, '');\n            if (f[f.length - 1] === '0')\n                node.minFractionDigits = f.length;\n        }\n        return node;\n    },\n    stringify: stringifyNumber.stringifyNumber\n};\n\nexports.float = float;\nexports.floatExp = floatExp;\nexports.floatNaN = floatNaN;\n","'use strict';\n\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst intIdentify = (value) => typeof value === 'bigint' || Number.isInteger(value);\nfunction intResolve(str, offset, radix, { intAsBigInt }) {\n    const sign = str[0];\n    if (sign === '-' || sign === '+')\n        offset += 1;\n    str = str.substring(offset).replace(/_/g, '');\n    if (intAsBigInt) {\n        switch (radix) {\n            case 2:\n                str = `0b${str}`;\n                break;\n            case 8:\n                str = `0o${str}`;\n                break;\n            case 16:\n                str = `0x${str}`;\n                break;\n        }\n        const n = BigInt(str);\n        return sign === '-' ? BigInt(-1) * n : n;\n    }\n    const n = parseInt(str, radix);\n    return sign === '-' ? -1 * n : n;\n}\nfunction intStringify(node, radix, prefix) {\n    const { value } = node;\n    if (intIdentify(value)) {\n        const str = value.toString(radix);\n        return value < 0 ? '-' + prefix + str.substr(1) : prefix + str;\n    }\n    return stringifyNumber.stringifyNumber(node);\n}\nconst intBin = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'BIN',\n    test: /^[-+]?0b[0-1_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 2, opt),\n    stringify: node => intStringify(node, 2, '0b')\n};\nconst intOct = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'OCT',\n    test: /^[-+]?0[0-7_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 1, 8, opt),\n    stringify: node => intStringify(node, 8, '0')\n};\nconst int = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    test: /^[-+]?[0-9][0-9_]*$/,\n    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),\n    stringify: stringifyNumber.stringifyNumber\n};\nconst intHex = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'HEX',\n    test: /^[-+]?0x[0-9a-fA-F_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),\n    stringify: node => intStringify(node, 16, '0x')\n};\n\nexports.int = int;\nexports.intBin = intBin;\nexports.intHex = intHex;\nexports.intOct = intOct;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar toJS = require('../../nodes/toJS.js');\nvar YAMLMap = require('../../nodes/YAMLMap.js');\nvar YAMLSeq = require('../../nodes/YAMLSeq.js');\nvar pairs = require('./pairs.js');\n\nclass YAMLOMap extends YAMLSeq.YAMLSeq {\n    constructor() {\n        super();\n        this.add = YAMLMap.YAMLMap.prototype.add.bind(this);\n        this.delete = YAMLMap.YAMLMap.prototype.delete.bind(this);\n        this.get = YAMLMap.YAMLMap.prototype.get.bind(this);\n        this.has = YAMLMap.YAMLMap.prototype.has.bind(this);\n        this.set = YAMLMap.YAMLMap.prototype.set.bind(this);\n        this.tag = YAMLOMap.tag;\n    }\n    /**\n     * If `ctx` is given, the return type is actually `Map<unknown, unknown>`,\n     * but TypeScript won't allow widening the signature of a child method.\n     */\n    toJSON(_, ctx) {\n        if (!ctx)\n            return super.toJSON(_);\n        const map = new Map();\n        if (ctx?.onCreate)\n            ctx.onCreate(map);\n        for (const pair of this.items) {\n            let key, value;\n            if (identity.isPair(pair)) {\n                key = toJS.toJS(pair.key, '', ctx);\n                value = toJS.toJS(pair.value, key, ctx);\n            }\n            else {\n                key = toJS.toJS(pair, '', ctx);\n            }\n            if (map.has(key))\n                throw new Error('Ordered maps must not include duplicate keys');\n            map.set(key, value);\n        }\n        return map;\n    }\n    static from(schema, iterable, ctx) {\n        const pairs$1 = pairs.createPairs(schema, iterable, ctx);\n        const omap = new this();\n        omap.items = pairs$1.items;\n        return omap;\n    }\n}\nYAMLOMap.tag = 'tag:yaml.org,2002:omap';\nconst omap = {\n    collection: 'seq',\n    identify: value => value instanceof Map,\n    nodeClass: YAMLOMap,\n    default: false,\n    tag: 'tag:yaml.org,2002:omap',\n    resolve(seq, onError) {\n        const pairs$1 = pairs.resolvePairs(seq, onError);\n        const seenKeys = [];\n        for (const { key } of pairs$1.items) {\n            if (identity.isScalar(key)) {\n                if (seenKeys.includes(key.value)) {\n                    onError(`Ordered maps must not include duplicate keys: ${key.value}`);\n                }\n                else {\n                    seenKeys.push(key.value);\n                }\n            }\n        }\n        return Object.assign(new YAMLOMap(), pairs$1);\n    },\n    createNode: (schema, iterable, ctx) => YAMLOMap.from(schema, iterable, ctx)\n};\n\nexports.YAMLOMap = YAMLOMap;\nexports.omap = omap;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar Pair = require('../../nodes/Pair.js');\nvar Scalar = require('../../nodes/Scalar.js');\nvar YAMLSeq = require('../../nodes/YAMLSeq.js');\n\nfunction resolvePairs(seq, onError) {\n    if (identity.isSeq(seq)) {\n        for (let i = 0; i < seq.items.length; ++i) {\n            let item = seq.items[i];\n            if (identity.isPair(item))\n                continue;\n            else if (identity.isMap(item)) {\n                if (item.items.length > 1)\n                    onError('Each pair must have its own sequence indicator');\n                const pair = item.items[0] || new Pair.Pair(new Scalar.Scalar(null));\n                if (item.commentBefore)\n                    pair.key.commentBefore = pair.key.commentBefore\n                        ? `${item.commentBefore}\\n${pair.key.commentBefore}`\n                        : item.commentBefore;\n                if (item.comment) {\n                    const cn = pair.value ?? pair.key;\n                    cn.comment = cn.comment\n                        ? `${item.comment}\\n${cn.comment}`\n                        : item.comment;\n                }\n                item = pair;\n            }\n            seq.items[i] = identity.isPair(item) ? item : new Pair.Pair(item);\n        }\n    }\n    else\n        onError('Expected a sequence for this tag');\n    return seq;\n}\nfunction createPairs(schema, iterable, ctx) {\n    const { replacer } = ctx;\n    const pairs = new YAMLSeq.YAMLSeq(schema);\n    pairs.tag = 'tag:yaml.org,2002:pairs';\n    let i = 0;\n    if (iterable && Symbol.iterator in Object(iterable))\n        for (let it of iterable) {\n            if (typeof replacer === 'function')\n                it = replacer.call(iterable, String(i++), it);\n            let key, value;\n            if (Array.isArray(it)) {\n                if (it.length === 2) {\n                    key = it[0];\n                    value = it[1];\n                }\n                else\n                    throw new TypeError(`Expected [key, value] tuple: ${it}`);\n            }\n            else if (it && it instanceof Object) {\n                const keys = Object.keys(it);\n                if (keys.length === 1) {\n                    key = keys[0];\n                    value = it[key];\n                }\n                else {\n                    throw new TypeError(`Expected tuple with one key, not ${keys.length} keys`);\n                }\n            }\n            else {\n                key = it;\n            }\n            pairs.items.push(Pair.createPair(key, value, ctx));\n        }\n    return pairs;\n}\nconst pairs = {\n    collection: 'seq',\n    default: false,\n    tag: 'tag:yaml.org,2002:pairs',\n    resolve: resolvePairs,\n    createNode: createPairs\n};\n\nexports.createPairs = createPairs;\nexports.pairs = pairs;\nexports.resolvePairs = resolvePairs;\n","'use strict';\n\nvar map = require('../common/map.js');\nvar _null = require('../common/null.js');\nvar seq = require('../common/seq.js');\nvar string = require('../common/string.js');\nvar binary = require('./binary.js');\nvar bool = require('./bool.js');\nvar float = require('./float.js');\nvar int = require('./int.js');\nvar omap = require('./omap.js');\nvar pairs = require('./pairs.js');\nvar set = require('./set.js');\nvar timestamp = require('./timestamp.js');\n\nconst schema = [\n    map.map,\n    seq.seq,\n    string.string,\n    _null.nullTag,\n    bool.trueTag,\n    bool.falseTag,\n    int.intBin,\n    int.intOct,\n    int.int,\n    int.intHex,\n    float.floatNaN,\n    float.floatExp,\n    float.float,\n    binary.binary,\n    omap.omap,\n    pairs.pairs,\n    set.set,\n    timestamp.intTime,\n    timestamp.floatTime,\n    timestamp.timestamp\n];\n\nexports.schema = schema;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar Pair = require('../../nodes/Pair.js');\nvar YAMLMap = require('../../nodes/YAMLMap.js');\n\nclass YAMLSet extends YAMLMap.YAMLMap {\n    constructor(schema) {\n        super(schema);\n        this.tag = YAMLSet.tag;\n    }\n    add(key) {\n        let pair;\n        if (identity.isPair(key))\n            pair = key;\n        else if (key &&\n            typeof key === 'object' &&\n            'key' in key &&\n            'value' in key &&\n            key.value === null)\n            pair = new Pair.Pair(key.key, null);\n        else\n            pair = new Pair.Pair(key, null);\n        const prev = YAMLMap.findPair(this.items, pair.key);\n        if (!prev)\n            this.items.push(pair);\n    }\n    /**\n     * If `keepPair` is `true`, returns the Pair matching `key`.\n     * Otherwise, returns the value of that Pair's key.\n     */\n    get(key, keepPair) {\n        const pair = YAMLMap.findPair(this.items, key);\n        return !keepPair && identity.isPair(pair)\n            ? identity.isScalar(pair.key)\n                ? pair.key.value\n                : pair.key\n            : pair;\n    }\n    set(key, value) {\n        if (typeof value !== 'boolean')\n            throw new Error(`Expected boolean value for set(key, value) in a YAML set, not ${typeof value}`);\n        const prev = YAMLMap.findPair(this.items, key);\n        if (prev && !value) {\n            this.items.splice(this.items.indexOf(prev), 1);\n        }\n        else if (!prev && value) {\n            this.items.push(new Pair.Pair(key));\n        }\n    }\n    toJSON(_, ctx) {\n        return super.toJSON(_, ctx, Set);\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        if (this.hasAllNullValues(true))\n            return super.toString(Object.assign({}, ctx, { allNullValues: true }), onComment, onChompKeep);\n        else\n            throw new Error('Set items must all have null values');\n    }\n    static from(schema, iterable, ctx) {\n        const { replacer } = ctx;\n        const set = new this(schema);\n        if (iterable && Symbol.iterator in Object(iterable))\n            for (let value of iterable) {\n                if (typeof replacer === 'function')\n                    value = replacer.call(iterable, value, value);\n                set.items.push(Pair.createPair(value, null, ctx));\n            }\n        return set;\n    }\n}\nYAMLSet.tag = 'tag:yaml.org,2002:set';\nconst set = {\n    collection: 'map',\n    identify: value => value instanceof Set,\n    nodeClass: YAMLSet,\n    default: false,\n    tag: 'tag:yaml.org,2002:set',\n    createNode: (schema, iterable, ctx) => YAMLSet.from(schema, iterable, ctx),\n    resolve(map, onError) {\n        if (identity.isMap(map)) {\n            if (map.hasAllNullValues(true))\n                return Object.assign(new YAMLSet(), map);\n            else\n                onError('Set items must all have null values');\n        }\n        else\n            onError('Expected a mapping for this tag');\n        return map;\n    }\n};\n\nexports.YAMLSet = YAMLSet;\nexports.set = set;\n","'use strict';\n\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\n/** Internal types handle bigint as number, because TS can't figure it out. */\nfunction parseSexagesimal(str, asBigInt) {\n    const sign = str[0];\n    const parts = sign === '-' || sign === '+' ? str.substring(1) : str;\n    const num = (n) => asBigInt ? BigInt(n) : Number(n);\n    const res = parts\n        .replace(/_/g, '')\n        .split(':')\n        .reduce((res, p) => res * num(60) + num(p), num(0));\n    return (sign === '-' ? num(-1) * res : res);\n}\n/**\n * hhhh:mm:ss.sss\n *\n * Internal types handle bigint as number, because TS can't figure it out.\n */\nfunction stringifySexagesimal(node) {\n    let { value } = node;\n    let num = (n) => n;\n    if (typeof value === 'bigint')\n        num = n => BigInt(n);\n    else if (isNaN(value) || !isFinite(value))\n        return stringifyNumber.stringifyNumber(node);\n    let sign = '';\n    if (value < 0) {\n        sign = '-';\n        value *= num(-1);\n    }\n    const _60 = num(60);\n    const parts = [value % _60]; // seconds, including ms\n    if (value < 60) {\n        parts.unshift(0); // at least one : is required\n    }\n    else {\n        value = (value - parts[0]) / _60;\n        parts.unshift(value % _60); // minutes\n        if (value >= 60) {\n            value = (value - parts[0]) / _60;\n            parts.unshift(value); // hours\n        }\n    }\n    return (sign +\n        parts\n            .map(n => String(n).padStart(2, '0'))\n            .join(':')\n            .replace(/000000\\d*$/, '') // % 60 may introduce error\n    );\n}\nconst intTime = {\n    identify: value => typeof value === 'bigint' || Number.isInteger(value),\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'TIME',\n    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+$/,\n    resolve: (str, _onError, { intAsBigInt }) => parseSexagesimal(str, intAsBigInt),\n    stringify: stringifySexagesimal\n};\nconst floatTime = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'TIME',\n    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\.[0-9_]*$/,\n    resolve: str => parseSexagesimal(str, false),\n    stringify: stringifySexagesimal\n};\nconst timestamp = {\n    identify: value => value instanceof Date,\n    default: true,\n    tag: 'tag:yaml.org,2002:timestamp',\n    // If the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part\n    // may be omitted altogether, resulting in a date format. In such a case, the time part is\n    // assumed to be 00:00:00Z (start of day, UTC).\n    test: RegExp('^([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})' + // YYYY-Mm-Dd\n        '(?:' + // time is optional\n        '(?:t|T|[ \\\\t]+)' + // t | T | whitespace\n        '([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\\\.[0-9]+)?)' + // Hh:Mm:Ss(.ss)?\n        '(?:[ \\\\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?' + // Z | +5 | -03:30\n        ')?$'),\n    resolve(str) {\n        const match = str.match(timestamp.test);\n        if (!match)\n            throw new Error('!!timestamp expects a date, starting with yyyy-mm-dd');\n        const [, year, month, day, hour, minute, second] = match.map(Number);\n        const millisec = match[7] ? Number((match[7] + '00').substr(1, 3)) : 0;\n        let date = Date.UTC(year, month - 1, day, hour || 0, minute || 0, second || 0, millisec);\n        const tz = match[8];\n        if (tz && tz !== 'Z') {\n            let d = parseSexagesimal(tz, false);\n            if (Math.abs(d) < 30)\n                d *= 60;\n            date -= 60000 * d;\n        }\n        return new Date(date);\n    },\n    stringify: ({ value }) => value.toISOString().replace(/((T00:00)?:00)?\\.000Z$/, '')\n};\n\nexports.floatTime = floatTime;\nexports.intTime = intTime;\nexports.timestamp = timestamp;\n","'use strict';\n\nconst FOLD_FLOW = 'flow';\nconst FOLD_BLOCK = 'block';\nconst FOLD_QUOTED = 'quoted';\n/**\n * Tries to keep input at up to `lineWidth` characters, splitting only on spaces\n * not followed by newlines or spaces unless `mode` is `'quoted'`. Lines are\n * terminated with `\\n` and started with `indent`.\n */\nfunction foldFlowLines(text, indent, mode = 'flow', { indentAtStart, lineWidth = 80, minContentWidth = 20, onFold, onOverflow } = {}) {\n    if (!lineWidth || lineWidth < 0)\n        return text;\n    const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length);\n    if (text.length <= endStep)\n        return text;\n    const folds = [];\n    const escapedFolds = {};\n    let end = lineWidth - indent.length;\n    if (typeof indentAtStart === 'number') {\n        if (indentAtStart > lineWidth - Math.max(2, minContentWidth))\n            folds.push(0);\n        else\n            end = lineWidth - indentAtStart;\n    }\n    let split = undefined;\n    let prev = undefined;\n    let overflow = false;\n    let i = -1;\n    let escStart = -1;\n    let escEnd = -1;\n    if (mode === FOLD_BLOCK) {\n        i = consumeMoreIndentedLines(text, i);\n        if (i !== -1)\n            end = i + endStep;\n    }\n    for (let ch; (ch = text[(i += 1)]);) {\n        if (mode === FOLD_QUOTED && ch === '\\\\') {\n            escStart = i;\n            switch (text[i + 1]) {\n                case 'x':\n                    i += 3;\n                    break;\n                case 'u':\n                    i += 5;\n                    break;\n                case 'U':\n                    i += 9;\n                    break;\n                default:\n                    i += 1;\n            }\n            escEnd = i;\n        }\n        if (ch === '\\n') {\n            if (mode === FOLD_BLOCK)\n                i = consumeMoreIndentedLines(text, i);\n            end = i + endStep;\n            split = undefined;\n        }\n        else {\n            if (ch === ' ' &&\n                prev &&\n                prev !== ' ' &&\n                prev !== '\\n' &&\n                prev !== '\\t') {\n                // space surrounded by non-space can be replaced with newline + indent\n                const next = text[i + 1];\n                if (next && next !== ' ' && next !== '\\n' && next !== '\\t')\n                    split = i;\n            }\n            if (i >= end) {\n                if (split) {\n                    folds.push(split);\n                    end = split + endStep;\n                    split = undefined;\n                }\n                else if (mode === FOLD_QUOTED) {\n                    // white-space collected at end may stretch past lineWidth\n                    while (prev === ' ' || prev === '\\t') {\n                        prev = ch;\n                        ch = text[(i += 1)];\n                        overflow = true;\n                    }\n                    // Account for newline escape, but don't break preceding escape\n                    const j = i > escEnd + 1 ? i - 2 : escStart - 1;\n                    // Bail out if lineWidth & minContentWidth are shorter than an escape string\n                    if (escapedFolds[j])\n                        return text;\n                    folds.push(j);\n                    escapedFolds[j] = true;\n                    end = j + endStep;\n                    split = undefined;\n                }\n                else {\n                    overflow = true;\n                }\n            }\n        }\n        prev = ch;\n    }\n    if (overflow && onOverflow)\n        onOverflow();\n    if (folds.length === 0)\n        return text;\n    if (onFold)\n        onFold();\n    let res = text.slice(0, folds[0]);\n    for (let i = 0; i < folds.length; ++i) {\n        const fold = folds[i];\n        const end = folds[i + 1] || text.length;\n        if (fold === 0)\n            res = `\\n${indent}${text.slice(0, end)}`;\n        else {\n            if (mode === FOLD_QUOTED && escapedFolds[fold])\n                res += `${text[fold]}\\\\`;\n            res += `\\n${indent}${text.slice(fold + 1, end)}`;\n        }\n    }\n    return res;\n}\n/**\n * Presumes `i + 1` is at the start of a line\n * @returns index of last newline in more-indented block\n */\nfunction consumeMoreIndentedLines(text, i) {\n    let ch = text[i + 1];\n    while (ch === ' ' || ch === '\\t') {\n        do {\n            ch = text[(i += 1)];\n        } while (ch && ch !== '\\n');\n        ch = text[i + 1];\n    }\n    return i;\n}\n\nexports.FOLD_BLOCK = FOLD_BLOCK;\nexports.FOLD_FLOW = FOLD_FLOW;\nexports.FOLD_QUOTED = FOLD_QUOTED;\nexports.foldFlowLines = foldFlowLines;\n","'use strict';\n\nvar anchors = require('../doc/anchors.js');\nvar identity = require('../nodes/identity.js');\nvar stringifyComment = require('./stringifyComment.js');\nvar stringifyString = require('./stringifyString.js');\n\nfunction createStringifyContext(doc, options) {\n    const opt = Object.assign({\n        blockQuote: true,\n        commentString: stringifyComment.stringifyComment,\n        defaultKeyType: null,\n        defaultStringType: 'PLAIN',\n        directives: null,\n        doubleQuotedAsJSON: false,\n        doubleQuotedMinMultiLineLength: 40,\n        falseStr: 'false',\n        flowCollectionPadding: true,\n        indentSeq: true,\n        lineWidth: 80,\n        minContentWidth: 20,\n        nullStr: 'null',\n        simpleKeys: false,\n        singleQuote: null,\n        trueStr: 'true',\n        verifyAliasOrder: true\n    }, doc.schema.toStringOptions, options);\n    let inFlow;\n    switch (opt.collectionStyle) {\n        case 'block':\n            inFlow = false;\n            break;\n        case 'flow':\n            inFlow = true;\n            break;\n        default:\n            inFlow = null;\n    }\n    return {\n        anchors: new Set(),\n        doc,\n        flowCollectionPadding: opt.flowCollectionPadding ? ' ' : '',\n        indent: '',\n        indentStep: typeof opt.indent === 'number' ? ' '.repeat(opt.indent) : '  ',\n        inFlow,\n        options: opt\n    };\n}\nfunction getTagObject(tags, item) {\n    if (item.tag) {\n        const match = tags.filter(t => t.tag === item.tag);\n        if (match.length > 0)\n            return match.find(t => t.format === item.format) ?? match[0];\n    }\n    let tagObj = undefined;\n    let obj;\n    if (identity.isScalar(item)) {\n        obj = item.value;\n        const match = tags.filter(t => t.identify?.(obj));\n        tagObj =\n            match.find(t => t.format === item.format) ?? match.find(t => !t.format);\n    }\n    else {\n        obj = item;\n        tagObj = tags.find(t => t.nodeClass && obj instanceof t.nodeClass);\n    }\n    if (!tagObj) {\n        const name = obj?.constructor?.name ?? typeof obj;\n        throw new Error(`Tag not resolved for ${name} value`);\n    }\n    return tagObj;\n}\n// needs to be called before value stringifier to allow for circular anchor refs\nfunction stringifyProps(node, tagObj, { anchors: anchors$1, doc }) {\n    if (!doc.directives)\n        return '';\n    const props = [];\n    const anchor = (identity.isScalar(node) || identity.isCollection(node)) && node.anchor;\n    if (anchor && anchors.anchorIsValid(anchor)) {\n        anchors$1.add(anchor);\n        props.push(`&${anchor}`);\n    }\n    const tag = node.tag ? node.tag : tagObj.default ? null : tagObj.tag;\n    if (tag)\n        props.push(doc.directives.tagString(tag));\n    return props.join(' ');\n}\nfunction stringify(item, ctx, onComment, onChompKeep) {\n    if (identity.isPair(item))\n        return item.toString(ctx, onComment, onChompKeep);\n    if (identity.isAlias(item)) {\n        if (ctx.doc.directives)\n            return item.toString(ctx);\n        if (ctx.resolvedAliases?.has(item)) {\n            throw new TypeError(`Cannot stringify circular structure without alias nodes`);\n        }\n        else {\n            if (ctx.resolvedAliases)\n                ctx.resolvedAliases.add(item);\n            else\n                ctx.resolvedAliases = new Set([item]);\n            item = item.resolve(ctx.doc);\n        }\n    }\n    let tagObj = undefined;\n    const node = identity.isNode(item)\n        ? item\n        : ctx.doc.createNode(item, { onTagObj: o => (tagObj = o) });\n    if (!tagObj)\n        tagObj = getTagObject(ctx.doc.schema.tags, node);\n    const props = stringifyProps(node, tagObj, ctx);\n    if (props.length > 0)\n        ctx.indentAtStart = (ctx.indentAtStart ?? 0) + props.length + 1;\n    const str = typeof tagObj.stringify === 'function'\n        ? tagObj.stringify(node, ctx, onComment, onChompKeep)\n        : identity.isScalar(node)\n            ? stringifyString.stringifyString(node, ctx, onComment, onChompKeep)\n            : node.toString(ctx, onComment, onChompKeep);\n    if (!props)\n        return str;\n    return identity.isScalar(node) || str[0] === '{' || str[0] === '['\n        ? `${props} ${str}`\n        : `${props}\\n${ctx.indent}${str}`;\n}\n\nexports.createStringifyContext = createStringifyContext;\nexports.stringify = stringify;\n","'use strict';\n\nvar Collection = require('../nodes/Collection.js');\nvar identity = require('../nodes/identity.js');\nvar stringify = require('./stringify.js');\nvar stringifyComment = require('./stringifyComment.js');\n\nfunction stringifyCollection(collection, ctx, options) {\n    const flow = ctx.inFlow ?? collection.flow;\n    const stringify = flow ? stringifyFlowCollection : stringifyBlockCollection;\n    return stringify(collection, ctx, options);\n}\nfunction stringifyBlockCollection({ comment, items }, ctx, { blockItemPrefix, flowChars, itemIndent, onChompKeep, onComment }) {\n    const { indent, options: { commentString } } = ctx;\n    const itemCtx = Object.assign({}, ctx, { indent: itemIndent, type: null });\n    let chompKeep = false; // flag for the preceding node's status\n    const lines = [];\n    for (let i = 0; i < items.length; ++i) {\n        const item = items[i];\n        let comment = null;\n        if (identity.isNode(item)) {\n            if (!chompKeep && item.spaceBefore)\n                lines.push('');\n            addCommentBefore(ctx, lines, item.commentBefore, chompKeep);\n            if (item.comment)\n                comment = item.comment;\n        }\n        else if (identity.isPair(item)) {\n            const ik = identity.isNode(item.key) ? item.key : null;\n            if (ik) {\n                if (!chompKeep && ik.spaceBefore)\n                    lines.push('');\n                addCommentBefore(ctx, lines, ik.commentBefore, chompKeep);\n            }\n        }\n        chompKeep = false;\n        let str = stringify.stringify(item, itemCtx, () => (comment = null), () => (chompKeep = true));\n        if (comment)\n            str += stringifyComment.lineComment(str, itemIndent, commentString(comment));\n        if (chompKeep && comment)\n            chompKeep = false;\n        lines.push(blockItemPrefix + str);\n    }\n    let str;\n    if (lines.length === 0) {\n        str = flowChars.start + flowChars.end;\n    }\n    else {\n        str = lines[0];\n        for (let i = 1; i < lines.length; ++i) {\n            const line = lines[i];\n            str += line ? `\\n${indent}${line}` : '\\n';\n        }\n    }\n    if (comment) {\n        str += '\\n' + stringifyComment.indentComment(commentString(comment), indent);\n        if (onComment)\n            onComment();\n    }\n    else if (chompKeep && onChompKeep)\n        onChompKeep();\n    return str;\n}\nfunction stringifyFlowCollection({ comment, items }, ctx, { flowChars, itemIndent, onComment }) {\n    const { indent, indentStep, flowCollectionPadding: fcPadding, options: { commentString } } = ctx;\n    itemIndent += indentStep;\n    const itemCtx = Object.assign({}, ctx, {\n        indent: itemIndent,\n        inFlow: true,\n        type: null\n    });\n    let reqNewline = false;\n    let linesAtValue = 0;\n    const lines = [];\n    for (let i = 0; i < items.length; ++i) {\n        const item = items[i];\n        let comment = null;\n        if (identity.isNode(item)) {\n            if (item.spaceBefore)\n                lines.push('');\n            addCommentBefore(ctx, lines, item.commentBefore, false);\n            if (item.comment)\n                comment = item.comment;\n        }\n        else if (identity.isPair(item)) {\n            const ik = identity.isNode(item.key) ? item.key : null;\n            if (ik) {\n                if (ik.spaceBefore)\n                    lines.push('');\n                addCommentBefore(ctx, lines, ik.commentBefore, false);\n                if (ik.comment)\n                    reqNewline = true;\n            }\n            const iv = identity.isNode(item.value) ? item.value : null;\n            if (iv) {\n                if (iv.comment)\n                    comment = iv.comment;\n                if (iv.commentBefore)\n                    reqNewline = true;\n            }\n            else if (item.value == null && ik?.comment) {\n                comment = ik.comment;\n            }\n        }\n        if (comment)\n            reqNewline = true;\n        let str = stringify.stringify(item, itemCtx, () => (comment = null));\n        if (i < items.length - 1)\n            str += ',';\n        if (comment)\n            str += stringifyComment.lineComment(str, itemIndent, commentString(comment));\n        if (!reqNewline && (lines.length > linesAtValue || str.includes('\\n')))\n            reqNewline = true;\n        lines.push(str);\n        linesAtValue = lines.length;\n    }\n    let str;\n    const { start, end } = flowChars;\n    if (lines.length === 0) {\n        str = start + end;\n    }\n    else {\n        if (!reqNewline) {\n            const len = lines.reduce((sum, line) => sum + line.length + 2, 2);\n            reqNewline = len > Collection.Collection.maxFlowStringSingleLineLength;\n        }\n        if (reqNewline) {\n            str = start;\n            for (const line of lines)\n                str += line ? `\\n${indentStep}${indent}${line}` : '\\n';\n            str += `\\n${indent}${end}`;\n        }\n        else {\n            str = `${start}${fcPadding}${lines.join(' ')}${fcPadding}${end}`;\n        }\n    }\n    if (comment) {\n        str += stringifyComment.lineComment(str, indent, commentString(comment));\n        if (onComment)\n            onComment();\n    }\n    return str;\n}\nfunction addCommentBefore({ indent, options: { commentString } }, lines, comment, chompKeep) {\n    if (comment && chompKeep)\n        comment = comment.replace(/^\\n+/, '');\n    if (comment) {\n        const ic = stringifyComment.indentComment(commentString(comment), indent);\n        lines.push(ic.trimStart()); // Avoid double indent on first line\n    }\n}\n\nexports.stringifyCollection = stringifyCollection;\n","'use strict';\n\n/**\n * Stringifies a comment.\n *\n * Empty comment lines are left empty,\n * lines consisting of a single space are replaced by `#`,\n * and all other lines are prefixed with a `#`.\n */\nconst stringifyComment = (str) => str.replace(/^(?!$)(?: $)?/gm, '#');\nfunction indentComment(comment, indent) {\n    if (/^\\n+$/.test(comment))\n        return comment.substring(1);\n    return indent ? comment.replace(/^(?! *$)/gm, indent) : comment;\n}\nconst lineComment = (str, indent, comment) => str.endsWith('\\n')\n    ? indentComment(comment, indent)\n    : comment.includes('\\n')\n        ? '\\n' + indentComment(comment, indent)\n        : (str.endsWith(' ') ? '' : ' ') + comment;\n\nexports.indentComment = indentComment;\nexports.lineComment = lineComment;\nexports.stringifyComment = stringifyComment;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar stringify = require('./stringify.js');\nvar stringifyComment = require('./stringifyComment.js');\n\nfunction stringifyDocument(doc, options) {\n    const lines = [];\n    let hasDirectives = options.directives === true;\n    if (options.directives !== false && doc.directives) {\n        const dir = doc.directives.toString(doc);\n        if (dir) {\n            lines.push(dir);\n            hasDirectives = true;\n        }\n        else if (doc.directives.docStart)\n            hasDirectives = true;\n    }\n    if (hasDirectives)\n        lines.push('---');\n    const ctx = stringify.createStringifyContext(doc, options);\n    const { commentString } = ctx.options;\n    if (doc.commentBefore) {\n        if (lines.length !== 1)\n            lines.unshift('');\n        const cs = commentString(doc.commentBefore);\n        lines.unshift(stringifyComment.indentComment(cs, ''));\n    }\n    let chompKeep = false;\n    let contentComment = null;\n    if (doc.contents) {\n        if (identity.isNode(doc.contents)) {\n            if (doc.contents.spaceBefore && hasDirectives)\n                lines.push('');\n            if (doc.contents.commentBefore) {\n                const cs = commentString(doc.contents.commentBefore);\n                lines.push(stringifyComment.indentComment(cs, ''));\n            }\n            // top-level block scalars need to be indented if followed by a comment\n            ctx.forceBlockIndent = !!doc.comment;\n            contentComment = doc.contents.comment;\n        }\n        const onChompKeep = contentComment ? undefined : () => (chompKeep = true);\n        let body = stringify.stringify(doc.contents, ctx, () => (contentComment = null), onChompKeep);\n        if (contentComment)\n            body += stringifyComment.lineComment(body, '', commentString(contentComment));\n        if ((body[0] === '|' || body[0] === '>') &&\n            lines[lines.length - 1] === '---') {\n            // Top-level block scalars with a preceding doc marker ought to use the\n            // same line for their header.\n            lines[lines.length - 1] = `--- ${body}`;\n        }\n        else\n            lines.push(body);\n    }\n    else {\n        lines.push(stringify.stringify(doc.contents, ctx));\n    }\n    if (doc.directives?.docEnd) {\n        if (doc.comment) {\n            const cs = commentString(doc.comment);\n            if (cs.includes('\\n')) {\n                lines.push('...');\n                lines.push(stringifyComment.indentComment(cs, ''));\n            }\n            else {\n                lines.push(`... ${cs}`);\n            }\n        }\n        else {\n            lines.push('...');\n        }\n    }\n    else {\n        let dc = doc.comment;\n        if (dc && chompKeep)\n            dc = dc.replace(/^\\n+/, '');\n        if (dc) {\n            if ((!chompKeep || contentComment) && lines[lines.length - 1] !== '')\n                lines.push('');\n            lines.push(stringifyComment.indentComment(commentString(dc), ''));\n        }\n    }\n    return lines.join('\\n') + '\\n';\n}\n\nexports.stringifyDocument = stringifyDocument;\n","'use strict';\n\nfunction stringifyNumber({ format, minFractionDigits, tag, value }) {\n    if (typeof value === 'bigint')\n        return String(value);\n    const num = typeof value === 'number' ? value : Number(value);\n    if (!isFinite(num))\n        return isNaN(num) ? '.nan' : num < 0 ? '-.inf' : '.inf';\n    let n = JSON.stringify(value);\n    if (!format &&\n        minFractionDigits &&\n        (!tag || tag === 'tag:yaml.org,2002:float') &&\n        /^\\d/.test(n)) {\n        let i = n.indexOf('.');\n        if (i < 0) {\n            i = n.length;\n            n += '.';\n        }\n        let d = minFractionDigits - (n.length - i - 1);\n        while (d-- > 0)\n            n += '0';\n    }\n    return n;\n}\n\nexports.stringifyNumber = stringifyNumber;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\nvar stringify = require('./stringify.js');\nvar stringifyComment = require('./stringifyComment.js');\n\nfunction stringifyPair({ key, value }, ctx, onComment, onChompKeep) {\n    const { allNullValues, doc, indent, indentStep, options: { commentString, indentSeq, simpleKeys } } = ctx;\n    let keyComment = (identity.isNode(key) && key.comment) || null;\n    if (simpleKeys) {\n        if (keyComment) {\n            throw new Error('With simple keys, key nodes cannot have comments');\n        }\n        if (identity.isCollection(key)) {\n            const msg = 'With simple keys, collection cannot be used as a key value';\n            throw new Error(msg);\n        }\n    }\n    let explicitKey = !simpleKeys &&\n        (!key ||\n            (keyComment && value == null && !ctx.inFlow) ||\n            identity.isCollection(key) ||\n            (identity.isScalar(key)\n                ? key.type === Scalar.Scalar.BLOCK_FOLDED || key.type === Scalar.Scalar.BLOCK_LITERAL\n                : typeof key === 'object'));\n    ctx = Object.assign({}, ctx, {\n        allNullValues: false,\n        implicitKey: !explicitKey && (simpleKeys || !allNullValues),\n        indent: indent + indentStep\n    });\n    let keyCommentDone = false;\n    let chompKeep = false;\n    let str = stringify.stringify(key, ctx, () => (keyCommentDone = true), () => (chompKeep = true));\n    if (!explicitKey && !ctx.inFlow && str.length > 1024) {\n        if (simpleKeys)\n            throw new Error('With simple keys, single line scalar must not span more than 1024 characters');\n        explicitKey = true;\n    }\n    if (ctx.inFlow) {\n        if (allNullValues || value == null) {\n            if (keyCommentDone && onComment)\n                onComment();\n            return str === '' ? '?' : explicitKey ? `? ${str}` : str;\n        }\n    }\n    else if ((allNullValues && !simpleKeys) || (value == null && explicitKey)) {\n        str = `? ${str}`;\n        if (keyComment && !keyCommentDone) {\n            str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));\n        }\n        else if (chompKeep && onChompKeep)\n            onChompKeep();\n        return str;\n    }\n    if (keyCommentDone)\n        keyComment = null;\n    if (explicitKey) {\n        if (keyComment)\n            str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));\n        str = `? ${str}\\n${indent}:`;\n    }\n    else {\n        str = `${str}:`;\n        if (keyComment)\n            str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));\n    }\n    let vsb, vcb, valueComment;\n    if (identity.isNode(value)) {\n        vsb = !!value.spaceBefore;\n        vcb = value.commentBefore;\n        valueComment = value.comment;\n    }\n    else {\n        vsb = false;\n        vcb = null;\n        valueComment = null;\n        if (value && typeof value === 'object')\n            value = doc.createNode(value);\n    }\n    ctx.implicitKey = false;\n    if (!explicitKey && !keyComment && identity.isScalar(value))\n        ctx.indentAtStart = str.length + 1;\n    chompKeep = false;\n    if (!indentSeq &&\n        indentStep.length >= 2 &&\n        !ctx.inFlow &&\n        !explicitKey &&\n        identity.isSeq(value) &&\n        !value.flow &&\n        !value.tag &&\n        !value.anchor) {\n        // If indentSeq === false, consider '- ' as part of indentation where possible\n        ctx.indent = ctx.indent.substring(2);\n    }\n    let valueCommentDone = false;\n    const valueStr = stringify.stringify(value, ctx, () => (valueCommentDone = true), () => (chompKeep = true));\n    let ws = ' ';\n    if (keyComment || vsb || vcb) {\n        ws = vsb ? '\\n' : '';\n        if (vcb) {\n            const cs = commentString(vcb);\n            ws += `\\n${stringifyComment.indentComment(cs, ctx.indent)}`;\n        }\n        if (valueStr === '' && !ctx.inFlow) {\n            if (ws === '\\n')\n                ws = '\\n\\n';\n        }\n        else {\n            ws += `\\n${ctx.indent}`;\n        }\n    }\n    else if (!explicitKey && identity.isCollection(value)) {\n        const vs0 = valueStr[0];\n        const nl0 = valueStr.indexOf('\\n');\n        const hasNewline = nl0 !== -1;\n        const flow = ctx.inFlow ?? value.flow ?? value.items.length === 0;\n        if (hasNewline || !flow) {\n            let hasPropsLine = false;\n            if (hasNewline && (vs0 === '&' || vs0 === '!')) {\n                let sp0 = valueStr.indexOf(' ');\n                if (vs0 === '&' &&\n                    sp0 !== -1 &&\n                    sp0 < nl0 &&\n                    valueStr[sp0 + 1] === '!') {\n                    sp0 = valueStr.indexOf(' ', sp0 + 1);\n                }\n                if (sp0 === -1 || nl0 < sp0)\n                    hasPropsLine = true;\n            }\n            if (!hasPropsLine)\n                ws = `\\n${ctx.indent}`;\n        }\n    }\n    else if (valueStr === '' || valueStr[0] === '\\n') {\n        ws = '';\n    }\n    str += ws + valueStr;\n    if (ctx.inFlow) {\n        if (valueCommentDone && onComment)\n            onComment();\n    }\n    else if (valueComment && !valueCommentDone) {\n        str += stringifyComment.lineComment(str, ctx.indent, commentString(valueComment));\n    }\n    else if (chompKeep && onChompKeep) {\n        onChompKeep();\n    }\n    return str;\n}\n\nexports.stringifyPair = stringifyPair;\n","'use strict';\n\nvar Scalar = require('../nodes/Scalar.js');\nvar foldFlowLines = require('./foldFlowLines.js');\n\nconst getFoldOptions = (ctx, isBlock) => ({\n    indentAtStart: isBlock ? ctx.indent.length : ctx.indentAtStart,\n    lineWidth: ctx.options.lineWidth,\n    minContentWidth: ctx.options.minContentWidth\n});\n// Also checks for lines starting with %, as parsing the output as YAML 1.1 will\n// presume that's starting a new document.\nconst containsDocumentMarker = (str) => /^(%|---|\\.\\.\\.)/m.test(str);\nfunction lineLengthOverLimit(str, lineWidth, indentLength) {\n    if (!lineWidth || lineWidth < 0)\n        return false;\n    const limit = lineWidth - indentLength;\n    const strLen = str.length;\n    if (strLen <= limit)\n        return false;\n    for (let i = 0, start = 0; i < strLen; ++i) {\n        if (str[i] === '\\n') {\n            if (i - start > limit)\n                return true;\n            start = i + 1;\n            if (strLen - start <= limit)\n                return false;\n        }\n    }\n    return true;\n}\nfunction doubleQuotedString(value, ctx) {\n    const json = JSON.stringify(value);\n    if (ctx.options.doubleQuotedAsJSON)\n        return json;\n    const { implicitKey } = ctx;\n    const minMultiLineLength = ctx.options.doubleQuotedMinMultiLineLength;\n    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n    let str = '';\n    let start = 0;\n    for (let i = 0, ch = json[i]; ch; ch = json[++i]) {\n        if (ch === ' ' && json[i + 1] === '\\\\' && json[i + 2] === 'n') {\n            // space before newline needs to be escaped to not be folded\n            str += json.slice(start, i) + '\\\\ ';\n            i += 1;\n            start = i;\n            ch = '\\\\';\n        }\n        if (ch === '\\\\')\n            switch (json[i + 1]) {\n                case 'u':\n                    {\n                        str += json.slice(start, i);\n                        const code = json.substr(i + 2, 4);\n                        switch (code) {\n                            case '0000':\n                                str += '\\\\0';\n                                break;\n                            case '0007':\n                                str += '\\\\a';\n                                break;\n                            case '000b':\n                                str += '\\\\v';\n                                break;\n                            case '001b':\n                                str += '\\\\e';\n                                break;\n                            case '0085':\n                                str += '\\\\N';\n                                break;\n                            case '00a0':\n                                str += '\\\\_';\n                                break;\n                            case '2028':\n                                str += '\\\\L';\n                                break;\n                            case '2029':\n                                str += '\\\\P';\n                                break;\n                            default:\n                                if (code.substr(0, 2) === '00')\n                                    str += '\\\\x' + code.substr(2);\n                                else\n                                    str += json.substr(i, 6);\n                        }\n                        i += 5;\n                        start = i + 1;\n                    }\n                    break;\n                case 'n':\n                    if (implicitKey ||\n                        json[i + 2] === '\"' ||\n                        json.length < minMultiLineLength) {\n                        i += 1;\n                    }\n                    else {\n                        // folding will eat first newline\n                        str += json.slice(start, i) + '\\n\\n';\n                        while (json[i + 2] === '\\\\' &&\n                            json[i + 3] === 'n' &&\n                            json[i + 4] !== '\"') {\n                            str += '\\n';\n                            i += 2;\n                        }\n                        str += indent;\n                        // space after newline needs to be escaped to not be folded\n                        if (json[i + 2] === ' ')\n                            str += '\\\\';\n                        i += 1;\n                        start = i + 1;\n                    }\n                    break;\n                default:\n                    i += 1;\n            }\n    }\n    str = start ? str + json.slice(start) : json;\n    return implicitKey\n        ? str\n        : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_QUOTED, getFoldOptions(ctx, false));\n}\nfunction singleQuotedString(value, ctx) {\n    if (ctx.options.singleQuote === false ||\n        (ctx.implicitKey && value.includes('\\n')) ||\n        /[ \\t]\\n|\\n[ \\t]/.test(value) // single quoted string can't have leading or trailing whitespace around newline\n    )\n        return doubleQuotedString(value, ctx);\n    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n    const res = \"'\" + value.replace(/'/g, \"''\").replace(/\\n+/g, `$&\\n${indent}`) + \"'\";\n    return ctx.implicitKey\n        ? res\n        : foldFlowLines.foldFlowLines(res, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));\n}\nfunction quotedString(value, ctx) {\n    const { singleQuote } = ctx.options;\n    let qs;\n    if (singleQuote === false)\n        qs = doubleQuotedString;\n    else {\n        const hasDouble = value.includes('\"');\n        const hasSingle = value.includes(\"'\");\n        if (hasDouble && !hasSingle)\n            qs = singleQuotedString;\n        else if (hasSingle && !hasDouble)\n            qs = doubleQuotedString;\n        else\n            qs = singleQuote ? singleQuotedString : doubleQuotedString;\n    }\n    return qs(value, ctx);\n}\n// The negative lookbehind avoids a polynomial search,\n// but isn't supported yet on Safari: https://caniuse.com/js-regexp-lookbehind\nlet blockEndNewlines;\ntry {\n    blockEndNewlines = new RegExp('(^|(?<!\\n))\\n+(?!\\n|$)', 'g');\n}\ncatch {\n    blockEndNewlines = /\\n+(?!\\n|$)/g;\n}\nfunction blockString({ comment, type, value }, ctx, onComment, onChompKeep) {\n    const { blockQuote, commentString, lineWidth } = ctx.options;\n    // 1. Block can't end in whitespace unless the last line is non-empty.\n    // 2. Strings consisting of only whitespace are best rendered explicitly.\n    if (!blockQuote || /\\n[\\t ]+$/.test(value) || /^\\s*$/.test(value)) {\n        return quotedString(value, ctx);\n    }\n    const indent = ctx.indent ||\n        (ctx.forceBlockIndent || containsDocumentMarker(value) ? '  ' : '');\n    const literal = blockQuote === 'literal'\n        ? true\n        : blockQuote === 'folded' || type === Scalar.Scalar.BLOCK_FOLDED\n            ? false\n            : type === Scalar.Scalar.BLOCK_LITERAL\n                ? true\n                : !lineLengthOverLimit(value, lineWidth, indent.length);\n    if (!value)\n        return literal ? '|\\n' : '>\\n';\n    // determine chomping from whitespace at value end\n    let chomp;\n    let endStart;\n    for (endStart = value.length; endStart > 0; --endStart) {\n        const ch = value[endStart - 1];\n        if (ch !== '\\n' && ch !== '\\t' && ch !== ' ')\n            break;\n    }\n    let end = value.substring(endStart);\n    const endNlPos = end.indexOf('\\n');\n    if (endNlPos === -1) {\n        chomp = '-'; // strip\n    }\n    else if (value === end || endNlPos !== end.length - 1) {\n        chomp = '+'; // keep\n        if (onChompKeep)\n            onChompKeep();\n    }\n    else {\n        chomp = ''; // clip\n    }\n    if (end) {\n        value = value.slice(0, -end.length);\n        if (end[end.length - 1] === '\\n')\n            end = end.slice(0, -1);\n        end = end.replace(blockEndNewlines, `$&${indent}`);\n    }\n    // determine indent indicator from whitespace at value start\n    let startWithSpace = false;\n    let startEnd;\n    let startNlPos = -1;\n    for (startEnd = 0; startEnd < value.length; ++startEnd) {\n        const ch = value[startEnd];\n        if (ch === ' ')\n            startWithSpace = true;\n        else if (ch === '\\n')\n            startNlPos = startEnd;\n        else\n            break;\n    }\n    let start = value.substring(0, startNlPos < startEnd ? startNlPos + 1 : startEnd);\n    if (start) {\n        value = value.substring(start.length);\n        start = start.replace(/\\n+/g, `$&${indent}`);\n    }\n    const indentSize = indent ? '2' : '1'; // root is at -1\n    let header = (literal ? '|' : '>') + (startWithSpace ? indentSize : '') + chomp;\n    if (comment) {\n        header += ' ' + commentString(comment.replace(/ ?[\\r\\n]+/g, ' '));\n        if (onComment)\n            onComment();\n    }\n    if (literal) {\n        value = value.replace(/\\n+/g, `$&${indent}`);\n        return `${header}\\n${indent}${start}${value}${end}`;\n    }\n    value = value\n        .replace(/\\n+/g, '\\n$&')\n        .replace(/(?:^|\\n)([\\t ].*)(?:([\\n\\t ]*)\\n(?![\\n\\t ]))?/g, '$1$2') // more-indented lines aren't folded\n        //                ^ more-ind. ^ empty     ^ capture next empty lines only at end of indent\n        .replace(/\\n+/g, `$&${indent}`);\n    const body = foldFlowLines.foldFlowLines(`${start}${value}${end}`, indent, foldFlowLines.FOLD_BLOCK, getFoldOptions(ctx, true));\n    return `${header}\\n${indent}${body}`;\n}\nfunction plainString(item, ctx, onComment, onChompKeep) {\n    const { type, value } = item;\n    const { actualString, implicitKey, indent, indentStep, inFlow } = ctx;\n    if ((implicitKey && value.includes('\\n')) ||\n        (inFlow && /[[\\]{},]/.test(value))) {\n        return quotedString(value, ctx);\n    }\n    if (!value ||\n        /^[\\n\\t ,[\\]{}#&*!|>'\"%@`]|^[?-]$|^[?-][ \\t]|[\\n:][ \\t]|[ \\t]\\n|[\\n\\t ]#|[\\n\\t :]$/.test(value)) {\n        // not allowed:\n        // - empty string, '-' or '?'\n        // - start with an indicator character (except [?:-]) or /[?-] /\n        // - '\\n ', ': ' or ' \\n' anywhere\n        // - '#' not preceded by a non-space char\n        // - end with ' ' or ':'\n        return implicitKey || inFlow || !value.includes('\\n')\n            ? quotedString(value, ctx)\n            : blockString(item, ctx, onComment, onChompKeep);\n    }\n    if (!implicitKey &&\n        !inFlow &&\n        type !== Scalar.Scalar.PLAIN &&\n        value.includes('\\n')) {\n        // Where allowed & type not set explicitly, prefer block style for multiline strings\n        return blockString(item, ctx, onComment, onChompKeep);\n    }\n    if (containsDocumentMarker(value)) {\n        if (indent === '') {\n            ctx.forceBlockIndent = true;\n            return blockString(item, ctx, onComment, onChompKeep);\n        }\n        else if (implicitKey && indent === indentStep) {\n            return quotedString(value, ctx);\n        }\n    }\n    const str = value.replace(/\\n+/g, `$&\\n${indent}`);\n    // Verify that output will be parsed as a string, as e.g. plain numbers and\n    // booleans get parsed with those types in v1.2 (e.g. '42', 'true' & '0.9e-3'),\n    // and others in v1.1.\n    if (actualString) {\n        const test = (tag) => tag.default && tag.tag !== 'tag:yaml.org,2002:str' && tag.test?.test(str);\n        const { compat, tags } = ctx.doc.schema;\n        if (tags.some(test) || compat?.some(test))\n            return quotedString(value, ctx);\n    }\n    return implicitKey\n        ? str\n        : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));\n}\nfunction stringifyString(item, ctx, onComment, onChompKeep) {\n    const { implicitKey, inFlow } = ctx;\n    const ss = typeof item.value === 'string'\n        ? item\n        : Object.assign({}, item, { value: String(item.value) });\n    let { type } = item;\n    if (type !== Scalar.Scalar.QUOTE_DOUBLE) {\n        // force double quotes on control characters & unpaired surrogates\n        if (/[\\x00-\\x08\\x0b-\\x1f\\x7f-\\x9f\\u{D800}-\\u{DFFF}]/u.test(ss.value))\n            type = Scalar.Scalar.QUOTE_DOUBLE;\n    }\n    const _stringify = (_type) => {\n        switch (_type) {\n            case Scalar.Scalar.BLOCK_FOLDED:\n            case Scalar.Scalar.BLOCK_LITERAL:\n                return implicitKey || inFlow\n                    ? quotedString(ss.value, ctx) // blocks are not valid inside flow containers\n                    : blockString(ss, ctx, onComment, onChompKeep);\n            case Scalar.Scalar.QUOTE_DOUBLE:\n                return doubleQuotedString(ss.value, ctx);\n            case Scalar.Scalar.QUOTE_SINGLE:\n                return singleQuotedString(ss.value, ctx);\n            case Scalar.Scalar.PLAIN:\n                return plainString(ss, ctx, onComment, onChompKeep);\n            default:\n                return null;\n        }\n    };\n    let res = _stringify(type);\n    if (res === null) {\n        const { defaultKeyType, defaultStringType } = ctx.options;\n        const t = (implicitKey && defaultKeyType) || defaultStringType;\n        res = _stringify(t);\n        if (res === null)\n            throw new Error(`Unsupported default string type ${t}`);\n    }\n    return res;\n}\n\nexports.stringifyString = stringifyString;\n","'use strict';\n\nvar identity = require('./nodes/identity.js');\n\nconst BREAK = Symbol('break visit');\nconst SKIP = Symbol('skip children');\nconst REMOVE = Symbol('remove node');\n/**\n * Apply a visitor to an AST node or document.\n *\n * Walks through the tree (depth-first) starting from `node`, calling a\n * `visitor` function with three arguments:\n *   - `key`: For sequence values and map `Pair`, the node's index in the\n *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.\n *     `null` for the root node.\n *   - `node`: The current node.\n *   - `path`: The ancestry of the current node.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this node, continue with next\n *     sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current node, then continue with the next one\n *   - `Node`: Replace the current node, then continue by visiting it\n *   - `number`: While iterating the items of a sequence or map, set the index\n *     of the next step. This is useful especially if the index of the current\n *     node has changed.\n *\n * If `visitor` is a single function, it will be called with all values\n * encountered in the tree, including e.g. `null` values. Alternatively,\n * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,\n * `Alias` and `Scalar` node. To define the same visitor function for more than\n * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)\n * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most\n * specific defined one will be used for each node.\n */\nfunction visit(node, visitor) {\n    const visitor_ = initVisitor(visitor);\n    if (identity.isDocument(node)) {\n        const cd = visit_(null, node.contents, visitor_, Object.freeze([node]));\n        if (cd === REMOVE)\n            node.contents = null;\n    }\n    else\n        visit_(null, node, visitor_, Object.freeze([]));\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisit.BREAK = BREAK;\n/** Do not visit the children of the current node */\nvisit.SKIP = SKIP;\n/** Remove the current node */\nvisit.REMOVE = REMOVE;\nfunction visit_(key, node, visitor, path) {\n    const ctrl = callVisitor(key, node, visitor, path);\n    if (identity.isNode(ctrl) || identity.isPair(ctrl)) {\n        replaceNode(key, path, ctrl);\n        return visit_(key, ctrl, visitor, path);\n    }\n    if (typeof ctrl !== 'symbol') {\n        if (identity.isCollection(node)) {\n            path = Object.freeze(path.concat(node));\n            for (let i = 0; i < node.items.length; ++i) {\n                const ci = visit_(i, node.items[i], visitor, path);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK)\n                    return BREAK;\n                else if (ci === REMOVE) {\n                    node.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n        }\n        else if (identity.isPair(node)) {\n            path = Object.freeze(path.concat(node));\n            const ck = visit_('key', node.key, visitor, path);\n            if (ck === BREAK)\n                return BREAK;\n            else if (ck === REMOVE)\n                node.key = null;\n            const cv = visit_('value', node.value, visitor, path);\n            if (cv === BREAK)\n                return BREAK;\n            else if (cv === REMOVE)\n                node.value = null;\n        }\n    }\n    return ctrl;\n}\n/**\n * Apply an async visitor to an AST node or document.\n *\n * Walks through the tree (depth-first) starting from `node`, calling a\n * `visitor` function with three arguments:\n *   - `key`: For sequence values and map `Pair`, the node's index in the\n *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.\n *     `null` for the root node.\n *   - `node`: The current node.\n *   - `path`: The ancestry of the current node.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `Promise`: Must resolve to one of the following values\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this node, continue with next\n *     sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current node, then continue with the next one\n *   - `Node`: Replace the current node, then continue by visiting it\n *   - `number`: While iterating the items of a sequence or map, set the index\n *     of the next step. This is useful especially if the index of the current\n *     node has changed.\n *\n * If `visitor` is a single function, it will be called with all values\n * encountered in the tree, including e.g. `null` values. Alternatively,\n * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,\n * `Alias` and `Scalar` node. To define the same visitor function for more than\n * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)\n * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most\n * specific defined one will be used for each node.\n */\nasync function visitAsync(node, visitor) {\n    const visitor_ = initVisitor(visitor);\n    if (identity.isDocument(node)) {\n        const cd = await visitAsync_(null, node.contents, visitor_, Object.freeze([node]));\n        if (cd === REMOVE)\n            node.contents = null;\n    }\n    else\n        await visitAsync_(null, node, visitor_, Object.freeze([]));\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisitAsync.BREAK = BREAK;\n/** Do not visit the children of the current node */\nvisitAsync.SKIP = SKIP;\n/** Remove the current node */\nvisitAsync.REMOVE = REMOVE;\nasync function visitAsync_(key, node, visitor, path) {\n    const ctrl = await callVisitor(key, node, visitor, path);\n    if (identity.isNode(ctrl) || identity.isPair(ctrl)) {\n        replaceNode(key, path, ctrl);\n        return visitAsync_(key, ctrl, visitor, path);\n    }\n    if (typeof ctrl !== 'symbol') {\n        if (identity.isCollection(node)) {\n            path = Object.freeze(path.concat(node));\n            for (let i = 0; i < node.items.length; ++i) {\n                const ci = await visitAsync_(i, node.items[i], visitor, path);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK)\n                    return BREAK;\n                else if (ci === REMOVE) {\n                    node.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n        }\n        else if (identity.isPair(node)) {\n            path = Object.freeze(path.concat(node));\n            const ck = await visitAsync_('key', node.key, visitor, path);\n            if (ck === BREAK)\n                return BREAK;\n            else if (ck === REMOVE)\n                node.key = null;\n            const cv = await visitAsync_('value', node.value, visitor, path);\n            if (cv === BREAK)\n                return BREAK;\n            else if (cv === REMOVE)\n                node.value = null;\n        }\n    }\n    return ctrl;\n}\nfunction initVisitor(visitor) {\n    if (typeof visitor === 'object' &&\n        (visitor.Collection || visitor.Node || visitor.Value)) {\n        return Object.assign({\n            Alias: visitor.Node,\n            Map: visitor.Node,\n            Scalar: visitor.Node,\n            Seq: visitor.Node\n        }, visitor.Value && {\n            Map: visitor.Value,\n            Scalar: visitor.Value,\n            Seq: visitor.Value\n        }, visitor.Collection && {\n            Map: visitor.Collection,\n            Seq: visitor.Collection\n        }, visitor);\n    }\n    return visitor;\n}\nfunction callVisitor(key, node, visitor, path) {\n    if (typeof visitor === 'function')\n        return visitor(key, node, path);\n    if (identity.isMap(node))\n        return visitor.Map?.(key, node, path);\n    if (identity.isSeq(node))\n        return visitor.Seq?.(key, node, path);\n    if (identity.isPair(node))\n        return visitor.Pair?.(key, node, path);\n    if (identity.isScalar(node))\n        return visitor.Scalar?.(key, node, path);\n    if (identity.isAlias(node))\n        return visitor.Alias?.(key, node, path);\n    return undefined;\n}\nfunction replaceNode(key, path, node) {\n    const parent = path[path.length - 1];\n    if (identity.isCollection(parent)) {\n        parent.items[key] = node;\n    }\n    else if (identity.isPair(parent)) {\n        if (key === 'key')\n            parent.key = node;\n        else\n            parent.value = node;\n    }\n    else if (identity.isDocument(parent)) {\n        parent.contents = node;\n    }\n    else {\n        const pt = identity.isAlias(parent) ? 'alias' : 'scalar';\n        throw new Error(`Cannot replace node with ${pt} parent`);\n    }\n}\n\nexports.visit = visit;\nexports.visitAsync = visitAsync;\n","export class Expr {\n}\nexport class Literal extends Expr {\n    constructor(literal, token) {\n        super();\n        this.literal = literal;\n        this.token = token;\n    }\n    accept(v) {\n        return v.visitLiteral(this);\n    }\n}\nexport class Unary extends Expr {\n    constructor(operator, expr) {\n        super();\n        this.operator = operator;\n        this.expr = expr;\n    }\n    accept(v) {\n        return v.visitUnary(this);\n    }\n}\nexport class FunctionCall extends Expr {\n    constructor(functionName, args) {\n        super();\n        this.functionName = functionName;\n        this.args = args;\n    }\n    accept(v) {\n        return v.visitFunctionCall(this);\n    }\n}\nexport class Binary extends Expr {\n    constructor(left, operator, right) {\n        super();\n        this.left = left;\n        this.operator = operator;\n        this.right = right;\n    }\n    accept(v) {\n        return v.visitBinary(this);\n    }\n}\nexport class Logical extends Expr {\n    constructor(operator, args) {\n        super();\n        this.operator = operator;\n        this.args = args;\n    }\n    accept(v) {\n        return v.visitLogical(this);\n    }\n}\nexport class Grouping extends Expr {\n    constructor(group) {\n        super();\n        this.group = group;\n    }\n    accept(v) {\n        return v.visitGrouping(this);\n    }\n}\nexport class ContextAccess extends Expr {\n    constructor(name) {\n        super();\n        this.name = name;\n    }\n    accept(v) {\n        return v.visitContextAccess(this);\n    }\n}\nexport class IndexAccess extends Expr {\n    constructor(expr, index) {\n        super();\n        this.expr = expr;\n        this.index = index;\n    }\n    accept(v) {\n        return v.visitIndexAccess(this);\n    }\n}\nexport class Star extends Expr {\n    accept() {\n        throw new Error(\"Method not implemented.\");\n    }\n}\n//# sourceMappingURL=ast.js.map","import { isDictionary } from \"./data/dictionary\";\nimport { Evaluator } from \"./evaluator\";\nimport { wellKnownFunctions } from \"./funcs\";\nimport { Lexer, TokenType } from \"./lexer\";\nimport { Parser } from \"./parser\";\n/**\n * Complete returns a list of completion items for the given expression.\n * The main functionality is auto-completing functions and context access:\n * We can only provide assistance if the input is in one of the following forms (with | denoting the cursor position):\n * - context.path.inp| or context.path['inp| -- auto-complete context access\n * - context.path.| or context.path['| -- auto-complete context access\n * - toJS| -- auto-complete function call or top-level\n * - | -- auto-complete function call or top-level context access\n *\n * @param input Input expression\n * @param context Context available for the expression\n * @param extensionFunctions List of functions available\n * @param functions Optional map of functions to use during evaluation\n * @returns Array of completion items\n */\nexport function complete(input, context, extensionFunctions, functions) {\n    // Lex\n    const lexer = new Lexer(input);\n    const lexResult = lexer.lex();\n    // Find interesting part of the tokenVector. For example, for an expression like `github.actor == env.actor.log|`, we are\n    // only interested in the `env.actor.log` part for auto-completion\n    const tokenInputVector = trimTokenVector(lexResult.tokens);\n    // Start by skipping the EOF token\n    let tokenIdx = tokenInputVector.length - 2;\n    if (tokenIdx >= 0) {\n        switch (tokenInputVector[tokenIdx].type) {\n            // If there is a (partial) identifier under the cursor, ignore that\n            case TokenType.IDENTIFIER:\n                tokenIdx--;\n                break;\n            case TokenType.STRING:\n                // TODO: Support string for `context.name['test|`\n                return [];\n        }\n    }\n    if (tokenIdx < 0) {\n        // Vector only contains the EOF token. Suggest functions and root context access\n        const result = contextKeys(context);\n        // Merge with functions\n        result.push(...functionItems(extensionFunctions));\n        return result;\n    }\n    // Determine path that led to the last token\n    // Use parser & evaluator to determine context to complete.\n    const pathTokenVector = tokenInputVector.slice(0, tokenIdx);\n    // Include the original EOF token to make the parser happy\n    pathTokenVector.push(tokenInputVector[tokenInputVector.length - 1]);\n    const p = new Parser(pathTokenVector, context.pairs().map(x => x.key), extensionFunctions);\n    const expr = p.parse();\n    const ev = new Evaluator(expr, context, functions);\n    const result = ev.evaluate();\n    return contextKeys(result);\n}\nfunction functionItems(extensionFunctions) {\n    const result = [];\n    for (const fdef of [...Object.values(wellKnownFunctions), ...extensionFunctions]) {\n        result.push({\n            label: fdef.name,\n            description: fdef.description,\n            function: true\n        });\n    }\n    // Sort functions\n    result.sort((a, b) => a.label.localeCompare(b.label));\n    return result;\n}\nfunction contextKeys(context) {\n    if (isDictionary(context)) {\n        return (context\n            .pairs()\n            .map(x => completionItemFromContext(x))\n            // Sort contexts\n            .sort((a, b) => a.label.localeCompare(b.label)));\n    }\n    return [];\n}\nfunction completionItemFromContext(pair) {\n    const context = pair.key.toString();\n    const parenIndex = context.indexOf(\"(\");\n    const isFunc = parenIndex >= 0 && context.indexOf(\")\") >= 0;\n    return {\n        label: isFunc ? context.substring(0, parenIndex) : context,\n        description: pair.description,\n        function: isFunc\n    };\n}\nexport function trimTokenVector(tokenVector) {\n    let tokenIdx = tokenVector.length;\n    let openParen = 0;\n    while (tokenIdx > 0) {\n        const token = tokenVector[tokenIdx - 1];\n        switch (token.type) {\n            case TokenType.LEFT_PAREN:\n                if (openParen == 0) {\n                    // Encountered an open parenthesis without a closing first, stop here\n                    break;\n                }\n                openParen--;\n                tokenIdx--;\n                continue;\n            case TokenType.RIGHT_PAREN:\n                openParen++;\n                tokenIdx--;\n                continue;\n            case TokenType.IDENTIFIER:\n            case TokenType.DOT:\n            case TokenType.EOF:\n            case TokenType.LEFT_BRACKET:\n            case TokenType.RIGHT_BRACKET:\n            case TokenType.STRING:\n                tokenIdx--;\n                continue;\n        }\n        break;\n    }\n    // Only keep the part of the token vector we're interested in\n    return tokenVector.slice(tokenIdx);\n}\n//# sourceMappingURL=completion.js.map","import { Dictionary } from \"../data/dictionary\";\nimport { Kind } from \"../data/expressiondata\";\nexport function isDescriptionDictionary(x) {\n    return x.kind === Kind.Dictionary && x instanceof DescriptionDictionary;\n}\nexport class DescriptionDictionary extends Dictionary {\n    constructor(...pairs) {\n        super();\n        this.descriptions = new Map();\n        this.complete = true;\n        for (const p of pairs) {\n            this.add(p.key, p.value, p.description);\n        }\n    }\n    add(key, value, description) {\n        if (this.get(key) !== undefined) {\n            // Key already added, ignore\n            return;\n        }\n        super.add(key, value);\n        if (description) {\n            this.descriptions.set(key, description);\n        }\n    }\n    pairs() {\n        const pairs = super.pairs();\n        return pairs.map(p => ({ ...p, description: this.descriptions.get(p.key) }));\n    }\n    getDescription(key) {\n        return this.descriptions.get(key);\n    }\n}\n//# sourceMappingURL=descriptionDictionary.js.map","import { Kind, kindStr } from \"./expressiondata\";\nexport class Array {\n    constructor(...data) {\n        this.v = [];\n        this.kind = Kind.Array;\n        this.primitive = false;\n        for (const d of data) {\n            this.add(d);\n        }\n    }\n    coerceString() {\n        return kindStr(this.kind);\n    }\n    number() {\n        return NaN;\n    }\n    add(value) {\n        this.v.push(value);\n    }\n    get(index) {\n        return this.v[index];\n    }\n    values() {\n        return this.v;\n    }\n}\n//# sourceMappingURL=array.js.map","import { Kind } from \"./expressiondata\";\nexport class BooleanData {\n    constructor(value) {\n        this.value = value;\n        this.kind = Kind.Boolean;\n        this.primitive = true;\n    }\n    coerceString() {\n        if (this.value) {\n            return \"true\";\n        }\n        return \"false\";\n    }\n    number() {\n        if (this.value) {\n            return 1;\n        }\n        return 0;\n    }\n}\n//# sourceMappingURL=boolean.js.map","import { Kind, kindStr } from \"./expressiondata\";\nexport class Dictionary {\n    constructor(...pairs) {\n        this.keys = [];\n        this.v = [];\n        this.indexMap = {};\n        this.kind = Kind.Dictionary;\n        this.primitive = false;\n        for (const p of pairs) {\n            this.add(p.key, p.value);\n        }\n    }\n    coerceString() {\n        return kindStr(this.kind);\n    }\n    number() {\n        return NaN;\n    }\n    add(key, value) {\n        if (key.toLowerCase() in this.indexMap) {\n            return;\n        }\n        this.keys.push(key);\n        this.v.push(value);\n        this.indexMap[key.toLowerCase()] = this.v.length - 1;\n    }\n    get(key) {\n        const index = this.indexMap[key.toLowerCase()];\n        if (index === undefined) {\n            return undefined;\n        }\n        return this.v[index];\n    }\n    values() {\n        return this.v;\n    }\n    pairs() {\n        const result = [];\n        for (const key of this.keys) {\n            result.push({ key, value: this.v[this.indexMap[key.toLowerCase()]] });\n        }\n        return result;\n    }\n}\nexport function isDictionary(x) {\n    return x.kind === Kind.Dictionary;\n}\n//# sourceMappingURL=dictionary.js.map","export var Kind;\n(function (Kind) {\n    Kind[Kind[\"String\"] = 0] = \"String\";\n    Kind[Kind[\"Array\"] = 1] = \"Array\";\n    Kind[Kind[\"Dictionary\"] = 2] = \"Dictionary\";\n    Kind[Kind[\"Boolean\"] = 3] = \"Boolean\";\n    Kind[Kind[\"Number\"] = 4] = \"Number\";\n    Kind[Kind[\"CaseSensitiveDictionary\"] = 5] = \"CaseSensitiveDictionary\";\n    Kind[Kind[\"Null\"] = 6] = \"Null\";\n})(Kind || (Kind = {}));\nexport function kindStr(k) {\n    switch (k) {\n        case Kind.Array:\n            return \"Array\";\n        case Kind.Boolean:\n            return \"Boolean\";\n        case Kind.Null:\n            return \"Null\";\n        case Kind.Number:\n            return \"Number\";\n        case Kind.Dictionary:\n            return \"Object\";\n        case Kind.String:\n            return \"String\";\n    }\n    return \"unknown\";\n}\n//# sourceMappingURL=expressiondata.js.map","export { Array } from \"./array\";\nexport { BooleanData } from \"./boolean\";\nexport { Dictionary } from \"./dictionary\";\nexport { Kind } from \"./expressiondata\";\nexport { Null } from \"./null\";\nexport { NumberData } from \"./number\";\nexport { replacer } from \"./replacer\";\nexport { reviver } from \"./reviver\";\nexport { StringData } from \"./string\";\n//# sourceMappingURL=index.js.map","import { Kind } from \"./expressiondata\";\nexport class Null {\n    constructor() {\n        this.kind = Kind.Null;\n        this.primitive = true;\n    }\n    coerceString() {\n        return \"\";\n    }\n    number() {\n        return 0;\n    }\n}\n//# sourceMappingURL=null.js.map","import { Kind } from \"./expressiondata\";\nexport class NumberData {\n    constructor(value) {\n        this.value = value;\n        this.kind = Kind.Number;\n        this.primitive = true;\n    }\n    coerceString() {\n        if (this.value === 0) {\n            return \"0\";\n        }\n        // Workaround to limit the precision to at most 15 digits. Format the number to a string, then parse\n        // it back to a number to remove trailing zeroes to prevent numbers to be converted to 1.200000000...\n        return (+this.value.toFixed(15)).toString();\n    }\n    number() {\n        return this.value;\n    }\n}\n//# sourceMappingURL=number.js.map","import { Array } from \"./array\";\nimport { BooleanData } from \"./boolean\";\nimport { Dictionary } from \"./dictionary\";\nimport { Null } from \"./null\";\nimport { NumberData } from \"./number\";\nimport { StringData } from \"./string\";\n/**\n * Replacer can be passed to JSON.stringify to convert an ExpressionData object into plain JSON\n *\n * See: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#replacer\n */\nexport function replacer(_key, value) {\n    if (value instanceof Null) {\n        return null;\n    }\n    if (value instanceof BooleanData) {\n        return value.value;\n    }\n    if (value instanceof NumberData) {\n        return value.number();\n    }\n    if (value instanceof StringData) {\n        return value.coerceString();\n    }\n    if (value instanceof Array) {\n        return value.values();\n    }\n    if (value instanceof Dictionary) {\n        const pairs = value.pairs();\n        const r = {};\n        for (const p of pairs) {\n            r[p.key] = p.value;\n        }\n        return r;\n    }\n    return value;\n}\n//# sourceMappingURL=replacer.js.map","import { Array as dArray } from \"./array\";\nimport { BooleanData } from \"./boolean\";\nimport { Dictionary } from \"./dictionary\";\nimport { Null } from \"./null\";\nimport { NumberData } from \"./number\";\nimport { StringData } from \"./string\";\n/**\n * Reviver can be passed to `JSON.parse` to convert plain JSON into an `ExpressionData` object.\n *\n * See: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#reviver\n */\nexport function reviver(_key, val) {\n    if (val === null) {\n        return new Null();\n    }\n    if (typeof val === \"string\") {\n        return new StringData(val);\n    }\n    if (typeof val === \"number\") {\n        return new NumberData(val);\n    }\n    if (typeof val === \"boolean\") {\n        return new BooleanData(val);\n    }\n    if (Array.isArray(val)) {\n        return new dArray(...val);\n    }\n    if (typeof val === \"object\") {\n        return new Dictionary(...Object.keys(val).map(k => ({\n            key: k,\n            value: val[k]\n        })));\n    }\n    // Pass through value\n    return val;\n}\n//# sourceMappingURL=reviver.js.map","import { Kind } from \"./expressiondata\";\nexport class StringData {\n    constructor(value) {\n        this.value = value;\n        this.kind = Kind.String;\n        this.primitive = true;\n    }\n    coerceString() {\n        return this.value;\n    }\n    number() {\n        return Number(this.value);\n    }\n}\n//# sourceMappingURL=string.js.map","import { tokenString } from \"./lexer\";\nexport const MAX_PARSER_DEPTH = 50;\nexport const MAX_EXPRESSION_LENGTH = 21000;\nexport var ErrorType;\n(function (ErrorType) {\n    ErrorType[ErrorType[\"ErrorUnexpectedSymbol\"] = 0] = \"ErrorUnexpectedSymbol\";\n    ErrorType[ErrorType[\"ErrorUnrecognizedNamedValue\"] = 1] = \"ErrorUnrecognizedNamedValue\";\n    ErrorType[ErrorType[\"ErrorUnexpectedEndOfExpression\"] = 2] = \"ErrorUnexpectedEndOfExpression\";\n    ErrorType[ErrorType[\"ErrorExceededMaxDepth\"] = 3] = \"ErrorExceededMaxDepth\";\n    ErrorType[ErrorType[\"ErrorExceededMaxLength\"] = 4] = \"ErrorExceededMaxLength\";\n    ErrorType[ErrorType[\"ErrorTooFewParameters\"] = 5] = \"ErrorTooFewParameters\";\n    ErrorType[ErrorType[\"ErrorTooManyParameters\"] = 6] = \"ErrorTooManyParameters\";\n    ErrorType[ErrorType[\"ErrorUnrecognizedContext\"] = 7] = \"ErrorUnrecognizedContext\";\n    ErrorType[ErrorType[\"ErrorUnrecognizedFunction\"] = 8] = \"ErrorUnrecognizedFunction\";\n})(ErrorType || (ErrorType = {}));\nexport class ExpressionError extends Error {\n    constructor(typ, tok) {\n        super(`${errorDescription(typ)}: '${tokenString(tok)}'`);\n        this.typ = typ;\n        this.tok = tok;\n        this.pos = this.tok.range.start;\n    }\n}\nfunction errorDescription(typ) {\n    switch (typ) {\n        case ErrorType.ErrorUnexpectedEndOfExpression:\n            return \"Unexpected end of expression\";\n        case ErrorType.ErrorUnexpectedSymbol:\n            return \"Unexpected symbol\";\n        case ErrorType.ErrorUnrecognizedNamedValue:\n            return \"Unrecognized named-value\";\n        case ErrorType.ErrorExceededMaxDepth:\n            return `Exceeded max expression depth ${MAX_PARSER_DEPTH}`;\n        case ErrorType.ErrorExceededMaxLength:\n            return `Exceeded max expression length ${MAX_EXPRESSION_LENGTH}`;\n        case ErrorType.ErrorTooFewParameters:\n            return \"Too few parameters supplied\";\n        case ErrorType.ErrorTooManyParameters:\n            return \"Too many parameters supplied\";\n        case ErrorType.ErrorUnrecognizedContext:\n            return \"Unrecognized named-value\";\n        case ErrorType.ErrorUnrecognizedFunction:\n            return \"Unrecognized function\";\n        default: // Should never reach here.\n            return \"Unknown error\";\n    }\n}\nexport class ExpressionEvaluationError extends Error {\n}\n//# sourceMappingURL=errors.js.map","import { Star } from \"./ast\";\nimport * as data from \"./data\";\nimport { FilteredArray } from \"./filtered_array\";\nimport { wellKnownFunctions } from \"./funcs\";\nimport { idxHelper } from \"./idxHelper\";\nimport { TokenType } from \"./lexer\";\nimport { equals, falsy, greaterThan, lessThan, truthy } from \"./result\";\nexport class Evaluator {\n    /**\n     * Creates a new evaluator\n     * @param n Parsed expression to evaluate\n     * @param context Context data to use\n     * @param functions Optional map of function implementations. If given, these will be preferred over the built-in functions.\n     */\n    constructor(n, context, functions) {\n        this.n = n;\n        this.context = context;\n        this.functions = functions;\n    }\n    evaluate() {\n        return this.eval(this.n);\n    }\n    eval(n) {\n        return n.accept(this);\n    }\n    visitLiteral(literal) {\n        return literal.literal;\n    }\n    visitUnary(unary) {\n        const r = this.eval(unary.expr);\n        if (unary.operator.type === TokenType.BANG) {\n            return new data.BooleanData(falsy(r));\n        }\n        throw new Error(`unknown unary operator: ${unary.operator.lexeme}`);\n    }\n    visitBinary(binary) {\n        const left = this.eval(binary.left);\n        const right = this.eval(binary.right);\n        switch (binary.operator.type) {\n            case TokenType.EQUAL_EQUAL:\n                return new data.BooleanData(equals(left, right));\n            case TokenType.BANG_EQUAL:\n                return new data.BooleanData(!equals(left, right));\n            case TokenType.GREATER:\n                return new data.BooleanData(greaterThan(left, right));\n            case TokenType.GREATER_EQUAL:\n                return new data.BooleanData(equals(left, right) || greaterThan(left, right));\n            case TokenType.LESS:\n                return new data.BooleanData(lessThan(left, right));\n            case TokenType.LESS_EQUAL:\n                return new data.BooleanData(equals(left, right) || lessThan(left, right));\n        }\n        throw new Error(`unknown binary operator: ${binary.operator.lexeme}`);\n    }\n    visitLogical(logical) {\n        let result;\n        for (const arg of logical.args) {\n            result = this.eval(arg);\n            // Break?\n            if ((logical.operator.type === TokenType.AND && falsy(result)) ||\n                (logical.operator.type === TokenType.OR && truthy(result))) {\n                break;\n            }\n        }\n        // result is always assigned before we return here\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        return result;\n    }\n    visitGrouping(grouping) {\n        return this.eval(grouping.group);\n    }\n    visitContextAccess(contextAccess) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const r = this.context.get(contextAccess.name.lexeme);\n        return r;\n    }\n    visitIndexAccess(ia) {\n        let idx;\n        if (ia.index instanceof Star) {\n            idx = new idxHelper(true, undefined);\n        }\n        else {\n            let idxResult;\n            try {\n                idxResult = this.eval(ia.index);\n            }\n            catch (e) {\n                throw new Error(`could not evaluate index for index access: ${e.message}`, { cause: e });\n            }\n            idx = new idxHelper(false, idxResult);\n        }\n        const objResult = this.eval(ia.expr);\n        let result;\n        switch (objResult.kind) {\n            case data.Kind.Array: {\n                const tobjResult = objResult;\n                if (tobjResult instanceof FilteredArray) {\n                    result = filteredArrayAccess(tobjResult, idx);\n                }\n                else {\n                    result = arrayAccess(tobjResult, idx);\n                }\n                break;\n            }\n            case data.Kind.Dictionary: {\n                const tobjResult = objResult;\n                result = objectAccess(tobjResult, idx);\n                break;\n            }\n            default:\n                if (idx.star) {\n                    result = new FilteredArray();\n                }\n                else {\n                    result = new data.Null();\n                }\n        }\n        return result;\n    }\n    visitFunctionCall(functionCall) {\n        // Evaluate arguments\n        const args = functionCall.args.map(arg => this.eval(arg));\n        // Get function definitions\n        const functionName = functionCall.functionName.lexeme.toLowerCase();\n        const f = this.functions?.get(functionName) || wellKnownFunctions[functionName];\n        return f.call(...args);\n    }\n}\nfunction filteredArrayAccess(fa, idx) {\n    const result = new FilteredArray();\n    for (const item of fa.values()) {\n        // Check the type of the nested item\n        switch (item.kind) {\n            case data.Kind.Dictionary: {\n                const ti = item;\n                if (idx.star) {\n                    for (const v of ti.values()) {\n                        result.add(v);\n                    }\n                }\n                else if (idx.str !== undefined) {\n                    const v = ti.get(idx.str);\n                    if (v !== undefined) {\n                        result.add(v);\n                    }\n                }\n                break;\n            }\n            case data.Kind.Array: {\n                const ti = item;\n                if (idx.star) {\n                    for (const v of ti.values()) {\n                        result.add(v);\n                    }\n                }\n                else if (idx.int !== undefined && idx.int < ti.values().length) {\n                    result.add(ti.get(idx.int));\n                }\n                break;\n            }\n        }\n    }\n    return result;\n}\nfunction arrayAccess(a, idx) {\n    if (idx.star) {\n        const fa = new FilteredArray();\n        for (const item of a.values()) {\n            fa.add(item);\n        }\n        return fa;\n    }\n    if (idx.int !== undefined && idx.int < a.values().length) {\n        return a.get(idx.int);\n    }\n    return new data.Null();\n}\nfunction objectAccess(obj, idx) {\n    if (idx.star) {\n        const fa = new FilteredArray(...obj.values());\n        return fa;\n    }\n    if (idx.str !== undefined) {\n        const r = obj.get(idx.str);\n        if (r !== undefined) {\n            return r;\n        }\n    }\n    return new data.Null();\n}\n//# sourceMappingURL=evaluator.js.map","import * as data from \"./data\";\nexport class FilteredArray extends data.Array {\n}\n//# sourceMappingURL=filtered_array.js.map","import { ErrorType, ExpressionError } from \"./errors\";\nimport { contains } from \"./funcs/contains\";\nimport { endswith } from \"./funcs/endswith\";\nimport { format } from \"./funcs/format\";\nimport { fromjson } from \"./funcs/fromjson\";\nimport { join } from \"./funcs/join\";\nimport { startswith } from \"./funcs/startswith\";\nimport { tojson } from \"./funcs/tojson\";\nexport const wellKnownFunctions = {\n    contains: contains,\n    endswith: endswith,\n    format: format,\n    fromjson: fromjson,\n    join: join,\n    startswith: startswith,\n    tojson: tojson\n};\n// validateFunction returns the function definition for the given function name.\n// If the function does not exist or an incorrect number of arguments is provided,\n// an error is returned.\nexport function validateFunction(context, identifier, argCount) {\n    // Expression function names are case-insensitive.\n    const name = identifier.lexeme.toLowerCase();\n    let f;\n    f = wellKnownFunctions[name];\n    if (!f) {\n        f = context.extensionFunctions.get(name);\n        if (!f) {\n            if (!context.allowUnknownKeywords) {\n                throw new ExpressionError(ErrorType.ErrorUnrecognizedFunction, identifier);\n            }\n            // Skip argument validation for unknown functions\n            return;\n        }\n    }\n    if (argCount < f.minArgs) {\n        throw new ExpressionError(ErrorType.ErrorTooFewParameters, identifier);\n    }\n    if (argCount > f.maxArgs) {\n        throw new ExpressionError(ErrorType.ErrorTooManyParameters, identifier);\n    }\n}\n//# sourceMappingURL=funcs.js.map","import { BooleanData, Kind } from \"../data\";\nimport { equals } from \"../result\";\nexport const contains = {\n    name: \"contains\",\n    description: \"`contains( search, item )`\\n\\nReturns `true` if `search` contains `item`. If `search` is an array, this function returns `true` if the `item` is an element in the array. If `search` is a string, this function returns `true` if the `item` is a substring of `search`. This function is not case sensitive. Casts values to a string.\",\n    minArgs: 2,\n    maxArgs: 2,\n    call: (...args) => {\n        const left = args[0];\n        const right = args[1];\n        if (left.primitive) {\n            const ls = left.coerceString();\n            if (right.primitive) {\n                const rs = right.coerceString();\n                return new BooleanData(ls.toLowerCase().includes(rs.toLowerCase()));\n            }\n        }\n        else if (left.kind === Kind.Array) {\n            const la = left;\n            if (la.values().length === 0) {\n                return new BooleanData(false);\n            }\n            for (const v of la.values()) {\n                if (equals(right, v)) {\n                    return new BooleanData(true);\n                }\n            }\n        }\n        return new BooleanData(false);\n    }\n};\n//# sourceMappingURL=contains.js.map","import { BooleanData } from \"../data\";\nimport { toUpperSpecial } from \"../result\";\nexport const endswith = {\n    name: \"endsWith\",\n    description: \"`endsWith( searchString, searchValue )`\\n\\nReturns `true` if `searchString` ends with `searchValue`. This function is not case sensitive. Casts values to a string.\",\n    minArgs: 2,\n    maxArgs: 2,\n    call: (...args) => {\n        const left = args[0];\n        if (!left.primitive) {\n            return new BooleanData(false);\n        }\n        const right = args[1];\n        if (!right.primitive) {\n            return new BooleanData(false);\n        }\n        const ls = toUpperSpecial(left.coerceString());\n        const rs = toUpperSpecial(right.coerceString());\n        return new BooleanData(ls.endsWith(rs));\n    }\n};\n//# sourceMappingURL=endswith.js.map","import { StringData } from \"../data\";\nexport const format = {\n    name: \"format\",\n    description: \"`format( string, replaceValue0, replaceValue1, ..., replaceValueN)`\\n\\nReplaces values in the `string`, with the variable `replaceValueN`. Variables in the `string` are specified using the `{N}` syntax, where `N` is an integer. You must specify at least one `replaceValue` and `string`. There is no maximum for the number of variables (`replaceValueN`) you can use. Escape curly braces using double braces.\",\n    minArgs: 1,\n    maxArgs: 255 /*MAX_ARGUMENTS*/,\n    call: (...args) => {\n        const fs = args[0].coerceString();\n        const result = [];\n        let index = 0;\n        while (index < fs.length) {\n            const lbrace = fs.indexOf(\"{\", index);\n            const rbrace = fs.indexOf(\"}\", index);\n            // Left brace\n            if (lbrace >= 0 && (rbrace < 0 || rbrace > lbrace)) {\n                // Escaped left brace\n                if (safeCharAt(fs, lbrace + 1) === \"{\") {\n                    result.push(fs.substr(index, lbrace - index + 1));\n                    index = lbrace + 2;\n                    continue;\n                }\n                // Left brace, number, optional format specifiers, right brace\n                if (rbrace > lbrace + 1) {\n                    const argIndex = readArgIndex(fs, lbrace + 1);\n                    if (argIndex.success) {\n                        // Check parameter count\n                        if (1 + argIndex.result > args.length - 1) {\n                            throw new Error(`The following format string references more arguments than were supplied: ${fs}`);\n                        }\n                        // Append the portion before the left brace\n                        if (lbrace > index) {\n                            result.push(fs.substr(index, lbrace - index));\n                        }\n                        // Append the arg\n                        result.push(`${args[1 + argIndex.result].coerceString()}`);\n                        index = rbrace + 1;\n                        continue;\n                    }\n                }\n                throw new Error(`The following format string is invalid: ${fs}`);\n            }\n            // Right brace\n            else if (rbrace >= 0) {\n                // Escaped right brace\n                if (safeCharAt(fs, rbrace + 1) === \"}\") {\n                    result.push(fs.substr(index, rbrace - index + 1));\n                    index = rbrace + 2;\n                }\n                else {\n                    throw new Error(`The following format string is invalid: ${fs}`);\n                }\n            }\n            // Last segment\n            else {\n                result.push(fs.substr(index));\n                break;\n            }\n        }\n        return new StringData(result.join(\"\"));\n    }\n};\nfunction safeCharAt(string, index) {\n    if (string.length > index) {\n        return string[index];\n    }\n    return \"\\0\";\n}\nfunction readArgIndex(string, startIndex) {\n    // Count the number of digits\n    let length = 0;\n    for (;;) {\n        const nextChar = safeCharAt(string, startIndex + length);\n        if (nextChar >= \"0\" && nextChar <= \"9\") {\n            length++;\n        }\n        else {\n            break;\n        }\n    }\n    // Validate at least one digit\n    if (length < 1) {\n        return {\n            success: false\n        };\n    }\n    // Parse the number\n    const endIndex = startIndex + length - 1;\n    const result = parseInt(string.substr(startIndex, length));\n    return {\n        success: !isNaN(result),\n        result: result,\n        endIndex: endIndex\n    };\n}\n//# sourceMappingURL=format.js.map","import { reviver } from \"../data/reviver\";\nimport { ExpressionEvaluationError } from \"../errors\";\nexport const fromjson = {\n    name: \"fromJson\",\n    description: \"`fromJSON(value)`\\n\\nReturns a JSON object or JSON data type for `value`. You can use this function to provide a JSON object as an evaluated expression or to convert environment variables from a string.\",\n    minArgs: 1,\n    maxArgs: 1,\n    call: (...args) => {\n        const input = args[0];\n        const is = input.coerceString();\n        if (is.trim() === \"\") {\n            throw new Error(\"empty input\");\n        }\n        try {\n            return JSON.parse(is, reviver);\n        }\n        catch (e) {\n            throw new ExpressionEvaluationError(\"Error parsing JSON when evaluating fromJson\", { cause: e });\n        }\n    }\n};\n//# sourceMappingURL=fromjson.js.map","import { Kind, StringData } from \"../data\";\nexport const join = {\n    name: \"join\",\n    description: \"`join( array, optionalSeparator )`\\n\\nThe value for `array` can be an array or a string. All values in `array` are concatenated into a string. If you provide `optionalSeparator`, it is inserted between the concatenated values. Otherwise, the default separator `,` is used. Casts values to a string.\",\n    minArgs: 1,\n    maxArgs: 2,\n    call: (...args) => {\n        // Primitive\n        if (args[0].primitive) {\n            return new StringData(args[0].coerceString());\n        }\n        // Array\n        if (args[0].kind === Kind.Array) {\n            // Separator\n            let separator = \",\";\n            if (args.length > 1 && args[1].primitive) {\n                separator = args[1].coerceString();\n            }\n            // Convert items to strings\n            return new StringData(args[0]\n                .values()\n                .map(item => item.coerceString())\n                .join(separator));\n        }\n        return new StringData(\"\");\n    }\n};\n//# sourceMappingURL=join.js.map","import { BooleanData } from \"../data\";\nimport { toUpperSpecial } from \"../result\";\nexport const startswith = {\n    name: \"startsWith\",\n    description: \"`startsWith( searchString, searchValue )`\\n\\nReturns `true` when `searchString` starts with `searchValue`. This function is not case sensitive. Casts values to a string.\",\n    minArgs: 2,\n    maxArgs: 2,\n    call: (...args) => {\n        const left = args[0];\n        if (!left.primitive) {\n            return new BooleanData(false);\n        }\n        const right = args[1];\n        if (!right.primitive) {\n            return new BooleanData(false);\n        }\n        const ls = toUpperSpecial(left.coerceString());\n        const rs = toUpperSpecial(right.coerceString());\n        return new BooleanData(ls.startsWith(rs));\n    }\n};\n//# sourceMappingURL=startswith.js.map","import { StringData } from \"../data\";\nimport { replacer } from \"../data/replacer\";\nexport const tojson = {\n    name: \"toJson\",\n    description: \"`toJSON(value)`\\n\\nReturns a pretty-print JSON representation of `value`. You can use this function to debug the information provided in contexts.\",\n    minArgs: 1,\n    maxArgs: 1,\n    call: (...args) => {\n        return new StringData(JSON.stringify(args[0], replacer, \"  \"));\n    }\n};\n//# sourceMappingURL=tojson.js.map","export class idxHelper {\n    constructor(star, idx) {\n        this.star = star;\n        if (!idx) {\n            return;\n        }\n        if (!star) {\n            if (idx.primitive) {\n                this.str = idx.coerceString();\n            }\n            let f = idx.number();\n            if (!isNaN(f) && isFinite(f) && f >= 0) {\n                f = Math.floor(f);\n                this.int = f;\n            }\n        }\n    }\n}\n//# sourceMappingURL=idxHelper.js.map","export { Expr } from \"./ast\";\nexport { complete } from \"./completion\";\nexport { DescriptionDictionary, isDescriptionDictionary } from \"./completion/descriptionDictionary\";\nexport * as data from \"./data\";\nexport { ExpressionError, ExpressionEvaluationError } from \"./errors\";\nexport { Evaluator } from \"./evaluator\";\nexport { wellKnownFunctions } from \"./funcs\";\nexport { Lexer } from \"./lexer\";\nexport { Parser } from \"./parser\";\n//# sourceMappingURL=index.js.map","import { StringData } from \"./data\";\nimport { MAX_EXPRESSION_LENGTH } from \"./errors\";\nexport var TokenType;\n(function (TokenType) {\n    TokenType[TokenType[\"UNKNOWN\"] = 0] = \"UNKNOWN\";\n    TokenType[TokenType[\"LEFT_PAREN\"] = 1] = \"LEFT_PAREN\";\n    TokenType[TokenType[\"RIGHT_PAREN\"] = 2] = \"RIGHT_PAREN\";\n    TokenType[TokenType[\"LEFT_BRACKET\"] = 3] = \"LEFT_BRACKET\";\n    TokenType[TokenType[\"RIGHT_BRACKET\"] = 4] = \"RIGHT_BRACKET\";\n    TokenType[TokenType[\"COMMA\"] = 5] = \"COMMA\";\n    TokenType[TokenType[\"DOT\"] = 6] = \"DOT\";\n    TokenType[TokenType[\"BANG\"] = 7] = \"BANG\";\n    TokenType[TokenType[\"BANG_EQUAL\"] = 8] = \"BANG_EQUAL\";\n    TokenType[TokenType[\"EQUAL_EQUAL\"] = 9] = \"EQUAL_EQUAL\";\n    TokenType[TokenType[\"GREATER\"] = 10] = \"GREATER\";\n    TokenType[TokenType[\"GREATER_EQUAL\"] = 11] = \"GREATER_EQUAL\";\n    TokenType[TokenType[\"LESS\"] = 12] = \"LESS\";\n    TokenType[TokenType[\"LESS_EQUAL\"] = 13] = \"LESS_EQUAL\";\n    TokenType[TokenType[\"AND\"] = 14] = \"AND\";\n    TokenType[TokenType[\"OR\"] = 15] = \"OR\";\n    TokenType[TokenType[\"STAR\"] = 16] = \"STAR\";\n    TokenType[TokenType[\"NUMBER\"] = 17] = \"NUMBER\";\n    TokenType[TokenType[\"STRING\"] = 18] = \"STRING\";\n    TokenType[TokenType[\"IDENTIFIER\"] = 19] = \"IDENTIFIER\";\n    TokenType[TokenType[\"TRUE\"] = 20] = \"TRUE\";\n    TokenType[TokenType[\"FALSE\"] = 21] = \"FALSE\";\n    TokenType[TokenType[\"NULL\"] = 22] = \"NULL\";\n    TokenType[TokenType[\"EOF\"] = 23] = \"EOF\";\n})(TokenType || (TokenType = {}));\nexport function tokenString(tok) {\n    switch (tok.type) {\n        case TokenType.EOF:\n            return \"EOF\";\n        case TokenType.NUMBER:\n            return tok.lexeme;\n        case TokenType.STRING:\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            return tok.value.toString();\n        default:\n            return tok.lexeme;\n    }\n}\nexport class Lexer {\n    constructor(input) {\n        this.input = input;\n        this.start = 0;\n        this.offset = 0;\n        this.line = 0;\n        this.lastLineOffset = 0;\n        this.tokens = [];\n    }\n    lex() {\n        if (this.input.length > MAX_EXPRESSION_LENGTH) {\n            throw new Error(\"ErrorExceededMaxLength\");\n        }\n        while (!this.atEnd()) {\n            this.start = this.offset;\n            const c = this.next();\n            switch (c) {\n                case \"(\":\n                    this.addToken(TokenType.LEFT_PAREN);\n                    break;\n                case \")\":\n                    this.addToken(TokenType.RIGHT_PAREN);\n                    break;\n                case \"[\":\n                    this.addToken(TokenType.LEFT_BRACKET);\n                    break;\n                case \"]\":\n                    this.addToken(TokenType.RIGHT_BRACKET);\n                    break;\n                case \",\":\n                    this.addToken(TokenType.COMMA);\n                    break;\n                case \".\":\n                    if (this.previous() != TokenType.IDENTIFIER &&\n                        this.previous() != TokenType.RIGHT_BRACKET &&\n                        this.previous() != TokenType.RIGHT_PAREN &&\n                        this.previous() != TokenType.STAR) {\n                        this.consumeNumber();\n                    }\n                    else {\n                        this.addToken(TokenType.DOT);\n                    }\n                    break;\n                case \"-\":\n                case \"+\":\n                    this.consumeNumber();\n                    break;\n                case \"!\":\n                    this.addToken(this.match(\"=\") ? TokenType.BANG_EQUAL : TokenType.BANG);\n                    break;\n                case \"=\":\n                    if (!this.match(\"=\")) {\n                        // Illegal; continue reading until we hit a boundary character and return an error\n                        this.consumeIdentifier();\n                        break;\n                    }\n                    this.addToken(TokenType.EQUAL_EQUAL);\n                    break;\n                case \"<\":\n                    this.addToken(this.match(\"=\") ? TokenType.LESS_EQUAL : TokenType.LESS);\n                    break;\n                case \">\":\n                    this.addToken(this.match(\"=\") ? TokenType.GREATER_EQUAL : TokenType.GREATER);\n                    break;\n                case \"&\":\n                    if (!this.match(\"&\")) {\n                        // Illegal; continue reading until we hit a boundary character and return an error\n                        this.consumeIdentifier();\n                        break;\n                    }\n                    this.addToken(TokenType.AND);\n                    break;\n                case \"|\":\n                    if (!this.match(\"|\")) {\n                        // Illegal; continue reading until we hit a boundary character and return an error\n                        this.consumeIdentifier();\n                        break;\n                    }\n                    this.addToken(TokenType.OR);\n                    break;\n                case \"*\":\n                    this.addToken(TokenType.STAR);\n                    break;\n                // Ignore whitespace.\n                case \" \":\n                case \"\\r\":\n                case \"\\t\":\n                    break;\n                case \"\\n\":\n                    ++this.line;\n                    this.lastLineOffset = this.offset;\n                    break;\n                case \"'\":\n                    this.consumeString();\n                    break;\n                default:\n                    switch (true) {\n                        case isDigit(c):\n                            this.consumeNumber();\n                            break;\n                        default:\n                            this.consumeIdentifier();\n                            break;\n                    }\n            }\n        }\n        this.tokens.push({\n            type: TokenType.EOF,\n            lexeme: \"\",\n            range: this.range()\n        });\n        return {\n            tokens: this.tokens\n        };\n    }\n    pos() {\n        return {\n            line: this.line,\n            column: this.start - this.lastLineOffset\n        };\n    }\n    endPos() {\n        return {\n            line: this.line,\n            column: this.offset - this.lastLineOffset\n        };\n    }\n    range() {\n        return {\n            start: this.pos(),\n            end: this.endPos()\n        };\n    }\n    atEnd() {\n        return this.offset >= this.input.length;\n    }\n    peek() {\n        if (this.atEnd()) {\n            return \"\\0\";\n        }\n        return this.input[this.offset];\n    }\n    peekNext() {\n        if (this.offset + 1 >= this.input.length) {\n            return \"\\0\";\n        }\n        return this.input[this.offset + 1];\n    }\n    previous() {\n        const l = this.tokens.length;\n        if (l == 0) {\n            return TokenType.EOF;\n        }\n        return this.tokens[l - 1].type;\n    }\n    next() {\n        return this.input[this.offset++];\n    }\n    match(expected) {\n        if (this.atEnd()) {\n            return false;\n        }\n        if (this.input[this.offset] !== expected) {\n            return false;\n        }\n        this.offset++;\n        return true;\n    }\n    addToken(type, value) {\n        this.tokens.push({\n            type,\n            lexeme: this.input.substring(this.start, this.offset),\n            range: this.range(),\n            value\n        });\n    }\n    consumeNumber() {\n        while (!this.atEnd() && (!isBoundary(this.peek()) || this.peek() == \".\")) {\n            this.next();\n        }\n        const lexeme = this.input.substring(this.start, this.offset);\n        const value = new StringData(lexeme).number();\n        if (isNaN(value)) {\n            throw new Error(`Unexpected symbol: '${lexeme}'. Located at position ${this.start + 1} within expression: ${this.input}`);\n        }\n        this.addToken(TokenType.NUMBER, value);\n    }\n    consumeString() {\n        while ((this.peek() !== \"'\" || this.peekNext() === \"'\") && !this.atEnd()) {\n            if (this.peek() === \"\\n\")\n                this.line++;\n            if (this.peek() === \"'\" && this.peekNext() === \"'\") {\n                // Escaped \"'\", consume\n                this.next();\n            }\n            this.next();\n        }\n        if (this.atEnd()) {\n            // Unterminated string\n            throw new Error(`Unexpected symbol: '${this.input.substring(this.start)}'. Located at position ${this.start + 1} within expression: ${this.input}`);\n        }\n        // Closing '\n        this.next();\n        // Trim the surrounding quotes.\n        let value = this.input.substring(this.start + 1, this.offset - 1);\n        value = value.replace(\"''\", \"'\");\n        this.addToken(TokenType.STRING, value);\n    }\n    consumeIdentifier() {\n        while (!this.atEnd() && !isBoundary(this.peek())) {\n            this.next();\n        }\n        let tokenType = TokenType.IDENTIFIER;\n        let tokenValue = undefined;\n        const lexeme = this.input.substring(this.start, this.offset);\n        if (this.previous() != TokenType.DOT) {\n            switch (lexeme) {\n                case \"true\":\n                    tokenType = TokenType.TRUE;\n                    break;\n                case \"false\":\n                    tokenType = TokenType.FALSE;\n                    break;\n                case \"null\":\n                    tokenType = TokenType.NULL;\n                    break;\n                case \"NaN\":\n                    tokenType = TokenType.NUMBER;\n                    tokenValue = NaN;\n                    break;\n                case \"Infinity\":\n                    tokenType = TokenType.NUMBER;\n                    tokenValue = Infinity;\n                    break;\n            }\n        }\n        if (!isLegalIdentifier(lexeme)) {\n            throw new Error(`Unexpected symbol: '${lexeme}'. Located at position ${this.start + 1} within expression: ${this.input}`);\n        }\n        this.addToken(tokenType, tokenValue);\n    }\n}\nfunction isDigit(c) {\n    return c >= \"0\" && c <= \"9\";\n}\nfunction isBoundary(c) {\n    switch (c) {\n        case \"(\":\n        case \"[\":\n        case \")\":\n        case \"]\":\n        case \",\":\n        case \".\":\n        case \"!\":\n        case \">\":\n        case \"<\":\n        case \"=\":\n        case \"&\":\n        case \"|\":\n            return true;\n    }\n    return /\\s/.test(c);\n}\nfunction isLegalIdentifier(str) {\n    if (str == \"\") {\n        return false;\n    }\n    const first = str[0];\n    if ((first >= \"a\" && first <= \"z\") || (first >= \"A\" && first <= \"Z\") || first == \"_\") {\n        for (const c of str.substring(1).split(\"\")) {\n            if ((c >= \"a\" && c <= \"z\") || (c >= \"A\" && c <= \"Z\") || (c >= \"0\" && c <= \"9\") || c == \"_\" || c == \"-\") {\n                // OK\n            }\n            else {\n                return false;\n            }\n        }\n        return true;\n    }\n    return false;\n}\n//# sourceMappingURL=lexer.js.map","import { Binary, ContextAccess, FunctionCall, Grouping, IndexAccess, Literal, Logical, Star, Unary } from \"./ast\";\nimport * as data from \"./data\";\nimport { ErrorType, ExpressionError, MAX_PARSER_DEPTH } from \"./errors\";\nimport { validateFunction } from \"./funcs\";\nimport { TokenType } from \"./lexer\";\nexport class Parser {\n    /**\n     * Constructs a new parser for the given tokens\n     *\n     * @param tokens Tokens to build a parse tree from\n     * @param extensionContexts Available context names\n     * @param extensionFunctions Available functions (beyond the built-in ones)\n     */\n    constructor(tokens, extensionContexts, extensionFunctions) {\n        this.tokens = tokens;\n        this.offset = 0;\n        this.depth = 0;\n        this.extContexts = new Map();\n        this.extFuncs = new Map();\n        for (const contextName of extensionContexts) {\n            this.extContexts.set(contextName.toLowerCase(), true);\n        }\n        for (const { name, func } of extensionFunctions.map(x => ({\n            name: x.name,\n            func: x\n        }))) {\n            this.extFuncs.set(name.toLowerCase(), func);\n        }\n        this.context = {\n            allowUnknownKeywords: false,\n            extensionContexts: this.extContexts,\n            extensionFunctions: this.extFuncs\n        };\n    }\n    parse() {\n        // eslint-disable-next-line prefer-const\n        let result;\n        // No tokens\n        if (this.atEnd()) {\n            return result;\n        }\n        result = this.expression();\n        if (!this.atEnd()) {\n            throw this.buildError(ErrorType.ErrorUnexpectedSymbol, this.peek());\n        }\n        return result;\n    }\n    expression() {\n        this.incrDepth();\n        try {\n            return this.logicalOr();\n        }\n        finally {\n            this.decrDepth();\n        }\n    }\n    logicalOr() {\n        // && is higher precedence than ||\n        let expr = this.logicalAnd();\n        if (this.check(TokenType.OR)) {\n            // Track depth\n            this.incrDepth();\n            try {\n                const logical = new Logical(this.peek(), [expr]);\n                expr = logical;\n                while (this.match(TokenType.OR)) {\n                    const right = this.logicalAnd();\n                    logical.args.push(right);\n                }\n            }\n            finally {\n                this.decrDepth();\n            }\n        }\n        return expr;\n    }\n    logicalAnd() {\n        // == and != are higher precedence than &&\n        let expr = this.equality();\n        if (this.check(TokenType.AND)) {\n            // Track depth\n            this.incrDepth();\n            try {\n                const logical = new Logical(this.peek(), [expr]);\n                expr = logical;\n                while (this.match(TokenType.AND)) {\n                    const right = this.equality();\n                    logical.args.push(right);\n                }\n            }\n            finally {\n                this.decrDepth();\n            }\n        }\n        return expr;\n    }\n    equality() {\n        // >, >=, <, <= are higher precedence than == and !=\n        let expr = this.comparison();\n        while (this.match(TokenType.BANG_EQUAL, TokenType.EQUAL_EQUAL)) {\n            const operator = this.previous();\n            const right = this.comparison();\n            expr = new Binary(expr, operator, right);\n        }\n        return expr;\n    }\n    comparison() {\n        // ! is higher precedence than >, >=, <, <=\n        let expr = this.unary();\n        while (this.match(TokenType.GREATER, TokenType.GREATER_EQUAL, TokenType.LESS, TokenType.LESS_EQUAL)) {\n            const operator = this.previous();\n            const right = this.unary();\n            expr = new Binary(expr, operator, right);\n        }\n        return expr;\n    }\n    unary() {\n        if (this.match(TokenType.BANG)) {\n            // Track depth\n            this.incrDepth();\n            const operator = this.previous();\n            const unary = this.unary();\n            try {\n                return new Unary(operator, unary);\n            }\n            finally {\n                this.decrDepth();\n            }\n        }\n        return this.index();\n    }\n    index() {\n        let expr = this.call();\n        let depthIncreased = 0;\n        if (expr instanceof Grouping || expr instanceof FunctionCall || expr instanceof ContextAccess) {\n            let cont = true;\n            while (cont) {\n                switch (true) {\n                    case this.match(TokenType.LEFT_BRACKET): {\n                        let indexExpr;\n                        if (this.match(TokenType.STAR)) {\n                            indexExpr = new Star();\n                        }\n                        else {\n                            indexExpr = this.expression();\n                        }\n                        this.consume(TokenType.RIGHT_BRACKET, ErrorType.ErrorUnexpectedSymbol);\n                        // Track depth\n                        this.incrDepth();\n                        depthIncreased++;\n                        expr = new IndexAccess(expr, indexExpr);\n                        break;\n                    }\n                    case this.match(TokenType.DOT):\n                        // Track depth\n                        this.incrDepth();\n                        depthIncreased++;\n                        if (this.match(TokenType.IDENTIFIER)) {\n                            const property = this.previous();\n                            expr = new IndexAccess(expr, new Literal(new data.StringData(property.lexeme), property));\n                        }\n                        else if (this.match(TokenType.STAR)) {\n                            expr = new IndexAccess(expr, new Star());\n                        }\n                        else {\n                            throw this.buildError(ErrorType.ErrorUnexpectedSymbol, this.peek());\n                        }\n                        break;\n                    default:\n                        cont = false;\n                }\n            }\n        }\n        for (let i = 0; i < depthIncreased; i++) {\n            this.decrDepth();\n        }\n        return expr;\n    }\n    call() {\n        if (!this.check(TokenType.IDENTIFIER)) {\n            return this.primary();\n        }\n        const identifier = this.next();\n        if (!this.match(TokenType.LEFT_PAREN)) {\n            if (!this.extContexts.has(identifier.lexeme.toLowerCase())) {\n                throw this.buildError(ErrorType.ErrorUnrecognizedContext, identifier);\n            }\n            return new ContextAccess(identifier);\n        }\n        // Function call\n        const args = [];\n        // Arguments\n        while (!this.match(TokenType.RIGHT_PAREN)) {\n            const aexp = this.expression();\n            args.push(aexp);\n            if (!this.check(TokenType.RIGHT_PAREN)) {\n                this.consume(TokenType.COMMA, ErrorType.ErrorUnexpectedSymbol);\n            }\n        }\n        validateFunction(this.context, identifier, args.length);\n        return new FunctionCall(identifier, args);\n    }\n    primary() {\n        switch (true) {\n            case this.match(TokenType.FALSE):\n                return new Literal(new data.BooleanData(false), this.previous());\n            case this.match(TokenType.TRUE):\n                return new Literal(new data.BooleanData(true), this.previous());\n            case this.match(TokenType.NULL):\n                return new Literal(new data.Null(), this.previous());\n            case this.match(TokenType.NUMBER):\n                return new Literal(new data.NumberData(this.previous().value), this.previous());\n            case this.match(TokenType.STRING):\n                return new Literal(new data.StringData(this.previous().value), this.previous());\n            case this.match(TokenType.LEFT_PAREN): {\n                const expr = this.expression();\n                if (this.atEnd()) {\n                    throw this.buildError(ErrorType.ErrorUnexpectedEndOfExpression, this.previous()); // Back up to get the last token before the EOF\n                }\n                this.consume(TokenType.RIGHT_PAREN, ErrorType.ErrorUnexpectedSymbol);\n                return new Grouping(expr);\n            }\n            case this.atEnd():\n                throw this.buildError(ErrorType.ErrorUnexpectedEndOfExpression, this.previous()); // Back up to get the last token before the EOF\n        }\n        throw this.buildError(ErrorType.ErrorUnexpectedSymbol, this.peek());\n    }\n    // match consumes the next token if it matches any of the given types\n    match(...tokenTypes) {\n        for (const tokenType of tokenTypes) {\n            if (this.check(tokenType)) {\n                this.next();\n                return true;\n            }\n        }\n        return false;\n    }\n    // check peeks whether the next token is of the given type\n    check(tokenType) {\n        if (this.atEnd()) {\n            return false;\n        }\n        return this.peek().type == tokenType;\n    }\n    // atEnd peeks whether the next token is EOF\n    atEnd() {\n        return this.peek().type == TokenType.EOF;\n    }\n    next() {\n        if (!this.atEnd()) {\n            this.offset++;\n        }\n        return this.previous();\n    }\n    peek() {\n        return this.tokens[this.offset];\n    }\n    // previous returns the previous token\n    previous() {\n        return this.tokens[this.offset - 1];\n    }\n    // consume attempts to consume the next token if it matches the given type. It returns an error of\n    // the given ParseErrorKind otherwise.\n    consume(tokenType, errorType) {\n        if (this.check(tokenType)) {\n            this.next();\n            return;\n        }\n        throw this.buildError(errorType, this.peek());\n    }\n    incrDepth() {\n        this.depth++;\n        if (this.depth > MAX_PARSER_DEPTH) {\n            throw this.buildError(ErrorType.ErrorExceededMaxDepth, this.peek());\n        }\n    }\n    decrDepth() {\n        this.depth--;\n    }\n    buildError(errType, token) {\n        return new ExpressionError(errType, token);\n    }\n}\n//# sourceMappingURL=parser.js.map","import * as data from \"./data\";\nexport function falsy(d) {\n    switch (d.kind) {\n        case data.Kind.Null:\n            return true;\n        case data.Kind.Boolean:\n            return !d.value;\n        case data.Kind.Number: {\n            const dv = d.value;\n            return dv === 0 || isNaN(dv);\n        }\n        case data.Kind.String:\n            return d.value.length === 0;\n    }\n    return false;\n}\nexport function truthy(d) {\n    return !falsy(d);\n}\n// Similar to the Javascript abstract equality comparison algorithm http://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3.\n// Except objects are not coerced to primitives.\nexport function coerceTypes(li, ri) {\n    let lv = li;\n    let rv = ri;\n    // Do nothing, same kind\n    if (li.kind === ri.kind) {\n        return [lv, rv];\n    }\n    switch (li.kind) {\n        // Number, String\n        case data.Kind.Number:\n            if (ri.kind === data.Kind.String) {\n                rv = new data.NumberData(ri.number());\n                return [lv, rv];\n            }\n            break;\n        // String, Number\n        case data.Kind.String:\n            if (ri.kind === data.Kind.Number) {\n                lv = new data.NumberData(li.number());\n                return [lv, rv];\n            }\n            break;\n        // Boolean|Null, Any\n        case data.Kind.Null:\n        case data.Kind.Boolean:\n            lv = new data.NumberData(li.number());\n            return coerceTypes(lv, rv);\n    }\n    // Any, Boolean|Null\n    switch (ri.kind) {\n        case data.Kind.Null:\n        case data.Kind.Boolean:\n            rv = new data.NumberData(ri.number());\n            return coerceTypes(lv, rv);\n    }\n    return [lv, rv];\n}\n// Similar to the Javascript abstract equality comparison algorithm http://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3.\n// Except string comparison is OrdinalIgnoreCase, and objects are not coerced to primitives.\nexport function equals(lhs, rhs) {\n    const [lv, rv] = coerceTypes(lhs, rhs);\n    if (lv.kind != rv.kind) {\n        return false;\n    }\n    switch (lv.kind) {\n        // Null, Null\n        case data.Kind.Null:\n            return true;\n        // Number, Number\n        case data.Kind.Number: {\n            const ld = lv.value;\n            const rd = rv.value;\n            if (isNaN(ld) || isNaN(rd)) {\n                return false;\n            }\n            return ld == rd;\n        }\n        // String, String\n        case data.Kind.String: {\n            const ls = lv.value;\n            const rs = rv.value;\n            return toUpperSpecial(ls) === toUpperSpecial(rs);\n        }\n        // Boolean, Boolean\n        case data.Kind.Boolean: {\n            const lb = lv.value;\n            const rb = rv.value;\n            return lb == rb;\n        }\n        // Object, Object\n        case data.Kind.Dictionary:\n        case data.Kind.Array:\n            // Check reference equality\n            return lv === rv;\n    }\n    return false;\n}\n// Similar to the Javascript abstract equality comparison algorithm http://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3.\n// Except string comparison is OrdinalIgnoreCase, and objects are not coerced to primitives.\nexport function greaterThan(lhs, rhs) {\n    const [lv, rv] = coerceTypes(lhs, rhs);\n    if (lv.kind != rv.kind) {\n        return false;\n    }\n    switch (lv.kind) {\n        // Number, Number\n        case data.Kind.Number: {\n            const lf = lv.value;\n            const rf = rv.value;\n            if (isNaN(lf) || isNaN(rf)) {\n                return false;\n            }\n            return lf > rf;\n        }\n        // String, String\n        case data.Kind.String: {\n            let ls = lv.value;\n            let rs = rv.value;\n            ls = toUpperSpecial(ls);\n            rs = toUpperSpecial(rs);\n            return ls > rs;\n        }\n        // Boolean, Boolean\n        case data.Kind.Boolean: {\n            const lb = lv.value;\n            const rb = rv.value;\n            return lb && !rb;\n        }\n    }\n    return false;\n}\n// Similar to the Javascript abstract equality comparison algorithm http://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3.\n// Except string comparison is OrdinalIgnoreCase, and objects are not coerced to primitives.\nexport function lessThan(lhs, rhs) {\n    const [lv, rv] = coerceTypes(lhs, rhs);\n    if (lv.kind != rv.kind) {\n        return false;\n    }\n    switch (lv.kind) {\n        // Number, Number\n        case data.Kind.Number: {\n            const lf = lv.value;\n            const rf = rv.value;\n            if (isNaN(lf) || isNaN(rf)) {\n                return false;\n            }\n            return lf < rf;\n        }\n        // String, String\n        case data.Kind.String: {\n            let ls = lv.value;\n            let rs = rv.value;\n            ls = toUpperSpecial(ls);\n            rs = toUpperSpecial(rs);\n            return ls < rs;\n        }\n        // Boolean, Boolean\n        case data.Kind.Boolean: {\n            const lb = lv.value;\n            const rb = rv.value;\n            return !lb && rb;\n        }\n    }\n    return false;\n}\n// Do not toUpper the small-dotless-\nexport function toUpperSpecial(s) {\n    const sb = [];\n    let i = 0;\n    const len = s.length;\n    let found = s.indexOf(\"\");\n    while (i < len) {\n        if (i < found) {\n            sb.push(s.substring(i, found).toUpperCase()); // Append upper segment\n            i = found;\n        }\n        else if (i == found) {\n            sb.push(s.substring(i, i + 1));\n            i += 1;\n            found = s.indexOf(\"\", i);\n        }\n        else {\n            sb.push(s.substring(i).toUpperCase()); // Append upper remaining\n            break;\n        }\n    }\n    return sb.join(\"\");\n}\n//# sourceMappingURL=result.js.map","export { convertWorkflowTemplate } from \"./model/convert\";\nexport * from \"./templates/tokens/type-guards\";\nexport { NoOperationTraceWriter } from \"./templates/trace-writer\";\nexport { parseWorkflow } from \"./workflows/workflow-parser\";\n//# sourceMappingURL=index.js.map","import { TemplateTokenError } from \"../templates/tokens/template-token\";\nimport { parseFileReference } from \"../workflows/file-reference\";\nimport { parseWorkflow } from \"../workflows/workflow-parser\";\nimport { convertConcurrency } from \"./converter/concurrency\";\nimport { convertOn } from \"./converter/events\";\nimport { handleTemplateTokenErrors } from \"./converter/handle-errors\";\nimport { convertJobs } from \"./converter/jobs\";\nimport { convertReferencedWorkflow } from \"./converter/referencedWorkflow\";\nimport { isReusableWorkflowJob } from \"./type-guards\";\nexport var ErrorPolicy;\n(function (ErrorPolicy) {\n    ErrorPolicy[ErrorPolicy[\"ReturnErrorsOnly\"] = 0] = \"ReturnErrorsOnly\";\n    ErrorPolicy[ErrorPolicy[\"TryConversion\"] = 1] = \"TryConversion\";\n})(ErrorPolicy || (ErrorPolicy = {}));\nconst defaultOptions = {\n    maxReusableWorkflowDepth: 4,\n    fetchReusableWorkflowDepth: 0,\n    errorPolicy: ErrorPolicy.ReturnErrorsOnly\n};\nexport async function convertWorkflowTemplate(context, root, fileProvider, options = defaultOptions) {\n    const result = {};\n    const opts = getOptionsWithDefaults(options);\n    if (context.errors.getErrors().length > 0 && opts.errorPolicy === ErrorPolicy.ReturnErrorsOnly) {\n        result.errors = context.errors.getErrors().map(x => ({\n            Message: x.message\n        }));\n        return result;\n    }\n    if (fileProvider === undefined && opts.fetchReusableWorkflowDepth > 0) {\n        context.error(root, new Error(\"A file provider is required to fetch reusable workflows\"));\n    }\n    try {\n        const rootMapping = root.assertMapping(\"root\");\n        for (const item of rootMapping) {\n            const key = item.key.assertString(\"root key\");\n            switch (key.value) {\n                case \"on\":\n                    result.events = handleTemplateTokenErrors(root, context, {}, () => convertOn(context, item.value));\n                    break;\n                case \"jobs\":\n                    result.jobs = handleTemplateTokenErrors(root, context, [], () => convertJobs(context, item.value));\n                    break;\n                case \"concurrency\":\n                    handleTemplateTokenErrors(root, context, {}, () => convertConcurrency(context, item.value));\n                    result.concurrency = item.value;\n                    break;\n                case \"env\":\n                    result.env = item.value;\n                    break;\n            }\n        }\n        // Load referenced workflows\n        for (const job of result.jobs || []) {\n            if (isReusableWorkflowJob(job)) {\n                if (opts.maxReusableWorkflowDepth === 0) {\n                    context.error(job.ref, new Error(\"Reusable workflows are not allowed\"));\n                    continue;\n                }\n                if (opts.fetchReusableWorkflowDepth === 0 || fileProvider === undefined) {\n                    continue;\n                }\n                try {\n                    const file = await fileProvider.getFileContent(parseFileReference(job.ref.value));\n                    const workflow = parseWorkflow(file, context);\n                    if (!workflow.value) {\n                        continue;\n                    }\n                    convertReferencedWorkflow(context, workflow.value, job);\n                }\n                catch {\n                    context.error(job.ref, new Error(\"Unable to find reusable workflow\"));\n                }\n            }\n        }\n    }\n    catch (err) {\n        if (err instanceof TemplateTokenError) {\n            context.error(err.token, err);\n        }\n        else {\n            // Report error for the root node\n            context.error(root, err);\n        }\n    }\n    finally {\n        if (context.errors.getErrors().length > 0) {\n            result.errors = context.errors.getErrors().map(x => ({\n                Message: x.message\n            }));\n        }\n    }\n    return result;\n}\nfunction getOptionsWithDefaults(options) {\n    return {\n        maxReusableWorkflowDepth: options.maxReusableWorkflowDepth !== undefined\n            ? options.maxReusableWorkflowDepth\n            : defaultOptions.maxReusableWorkflowDepth,\n        fetchReusableWorkflowDepth: options.fetchReusableWorkflowDepth !== undefined\n            ? options.fetchReusableWorkflowDepth\n            : defaultOptions.fetchReusableWorkflowDepth,\n        errorPolicy: options.errorPolicy !== undefined ? options.errorPolicy : defaultOptions.errorPolicy\n    };\n}\n//# sourceMappingURL=convert.js.map","import { isString } from \"../../templates/tokens/type-guards\";\nexport function convertConcurrency(context, token) {\n    const result = {};\n    if (token.isExpression) {\n        return result;\n    }\n    if (isString(token)) {\n        result.group = token;\n        return result;\n    }\n    const concurrencyProperty = token.assertMapping(\"concurrency group\");\n    for (const property of concurrencyProperty) {\n        const propertyName = property.key.assertString(\"concurrency group key\");\n        if (property.key.isExpression || property.value.isExpression) {\n            continue;\n        }\n        switch (propertyName.value) {\n            case \"group\":\n                result.group = property.value.assertString(\"concurrency group\");\n                break;\n            case \"cancel-in-progress\":\n                result.cancelInProgress = property.value.assertBoolean(\"cancel-in-progress\").value;\n                break;\n            default:\n                context.error(propertyName, `Invalid property name: ${propertyName.value}`);\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=concurrency.js.map","import { TemplateToken } from \"../../templates/tokens\";\nimport { isString } from \"../../templates/tokens/type-guards\";\nexport function convertToJobContainer(context, container) {\n    let image;\n    let env;\n    let ports;\n    let volumes;\n    let options;\n    // Skip validation for expressions for now to match\n    // behavior of the other parsers\n    for (const [, token] of TemplateToken.traverse(container)) {\n        if (token.isExpression) {\n            return;\n        }\n    }\n    if (isString(container)) {\n        // Workflow uses shorthand syntax `container: image-name`\n        image = container.assertString(\"container item\");\n        return { image: image };\n    }\n    const mapping = container.assertMapping(\"container item\");\n    if (mapping)\n        for (const item of mapping) {\n            const key = item.key.assertString(\"container item key\");\n            const value = item.value;\n            switch (key.value) {\n                case \"image\":\n                    image = value.assertString(\"container image\");\n                    break;\n                case \"credentials\":\n                    convertToJobCredentials(context, value);\n                    break;\n                case \"env\":\n                    env = value.assertMapping(\"container env\");\n                    for (const envItem of env) {\n                        envItem.key.assertString(\"container env value\");\n                    }\n                    break;\n                case \"ports\":\n                    ports = value.assertSequence(\"container ports\");\n                    for (const port of ports) {\n                        port.assertString(\"container port\");\n                    }\n                    break;\n                case \"volumes\":\n                    volumes = value.assertSequence(\"container volumes\");\n                    for (const volume of volumes) {\n                        volume.assertString(\"container volume\");\n                    }\n                    break;\n                case \"options\":\n                    options = value.assertString(\"container options\");\n                    break;\n                default:\n                    context.error(key, `Unexpected container item key: ${key.value}`);\n            }\n        }\n    if (!image) {\n        context.error(container, \"Container image cannot be empty\");\n    }\n    else {\n        return { image, env, ports, volumes, options };\n    }\n}\nexport function convertToJobServices(context, services) {\n    const serviceList = [];\n    const mapping = services.assertMapping(\"services\");\n    for (const service of mapping) {\n        service.key.assertString(\"service key\");\n        const container = convertToJobContainer(context, service.value);\n        if (container) {\n            serviceList.push(container);\n        }\n    }\n    return serviceList;\n}\nfunction convertToJobCredentials(context, value) {\n    const mapping = value.assertMapping(\"credentials\");\n    let username;\n    let password;\n    for (const item of mapping) {\n        const key = item.key.assertString(\"credentials item\");\n        const value = item.value;\n        switch (key.value) {\n            case \"username\":\n                username = value.assertString(\"credentials username\");\n                break;\n            case \"password\":\n                password = value.assertString(\"credentials password\");\n                break;\n            default:\n                context.error(key, `credentials key ${key.value}`);\n        }\n    }\n    return { username, password };\n}\n//# sourceMappingURL=container.js.map","// Constants for parsing and validating cron expressions\nconst MONTHS = {\n    jan: 1,\n    feb: 2,\n    mar: 3,\n    apr: 4,\n    may: 5,\n    jun: 6,\n    jul: 7,\n    aug: 8,\n    sep: 9,\n    oct: 10,\n    nov: 11,\n    dec: 12\n};\nconst DAYS = {\n    sun: 0,\n    mon: 1,\n    tue: 2,\n    wed: 3,\n    thu: 4,\n    fri: 5,\n    sat: 6\n};\nexport const MINUTE_RANGE = { min: 0, max: 59 };\nexport const HOUR_RANGE = { min: 0, max: 23 };\nexport const DOM_RANGE = { min: 1, max: 31 };\nexport const MONTH_RANGE = { min: 1, max: 12, names: MONTHS };\nexport const DOW_RANGE = { min: 0, max: 6, names: DAYS };\n//# sourceMappingURL=cron-constants.js.map","import cronstrue from \"cronstrue\";\nimport { MONTH_RANGE, HOUR_RANGE, MINUTE_RANGE, DOM_RANGE, DOW_RANGE } from \"./cron-constants\";\nexport function isValidCron(cron) {\n    // https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule\n    const parts = cron.split(/ +/);\n    if (parts.length != 5) {\n        return false;\n    }\n    const [minutes, hours, dom, months, dow] = parts;\n    return (validateCronPart(minutes, MINUTE_RANGE) &&\n        validateCronPart(hours, HOUR_RANGE) &&\n        validateCronPart(dom, DOM_RANGE) &&\n        validateCronPart(months, MONTH_RANGE) &&\n        validateCronPart(dow, DOW_RANGE));\n}\nexport function getCronDescription(cronspec) {\n    if (!isValidCron(cronspec)) {\n        return;\n    }\n    let desc = \"\";\n    try {\n        desc = cronstrue.toString(cronspec, {\n            dayOfWeekStartIndexZero: true,\n            monthStartIndexZero: false,\n            use24HourTimeFormat: true,\n            // cronstrue sets the description as the error if throwExceptionOnParseError is false\n            // so we need to distinguish between an error and a valid description\n            throwExceptionOnParseError: true\n        });\n    }\n    catch (err) {\n        return;\n    }\n    // Make first character lowercase\n    let result = \"Runs \" + desc.charAt(0).toLowerCase() + desc.slice(1);\n    result +=\n        \"\\n\\nActions schedules run at most every 5 minutes.\" +\n            \" [Learn more](https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions#onschedule)\";\n    return result;\n}\nfunction validateCronPart(value, range, allowSeparators = true) {\n    if (range.names && range.names[value.toLowerCase()] !== undefined) {\n        return true;\n    }\n    if (value === \"*\") {\n        return true;\n    }\n    // Operator precedence: , > / > -\n    if (value.includes(\",\")) {\n        if (!allowSeparators) {\n            return false;\n        }\n        return value.split(\",\").every(v => v && validateCronPart(v, range));\n    }\n    if (value.includes(\"/\")) {\n        if (!allowSeparators) {\n            return false;\n        }\n        const [start, step, ...rest] = value.split(\"/\");\n        const stepNumber = +step;\n        if (rest.length > 0 || isNaN(stepNumber) || stepNumber <= 0 || !start || !step) {\n            return false;\n        }\n        // Separators are only allowed in the part before the `/`, e.g. `1-5/2`\n        return validateCronPart(start, range) && validateCronPart(step, range, false);\n    }\n    if (value.includes(\"-\")) {\n        if (!allowSeparators) {\n            return false;\n        }\n        const [start, end, ...rest] = value.split(\"-\");\n        if (rest.length > 0 || !start || !end) {\n            return false;\n        }\n        // Convert name to integers so we can make sure end >= start\n        const startNumber = convertToNumber(start, range.names);\n        const endNumber = convertToNumber(end, range.names);\n        return validateCronPart(start, range, false) && validateCronPart(end, range, false) && endNumber >= startNumber;\n    }\n    const number = +value;\n    return !isNaN(number) && number >= range.min && number <= range.max;\n}\n// Converts a string integer or a short name to a number\nfunction convertToNumber(value, names) {\n    if (names && names[value.toLowerCase()] !== undefined) {\n        return +names[value.toLowerCase()];\n    }\n    else {\n        return +value;\n    }\n}\n//# sourceMappingURL=cron.js.map","import { isLiteral, isMapping, isSequence, isString } from \"../../templates/tokens/type-guards\";\nimport { TokenType } from \"../../templates/tokens/types\";\nimport { isValidCron } from \"./cron\";\nimport { convertStringList } from \"./string-list\";\nimport { convertEventWorkflowCall } from \"./workflow-call\";\nimport { convertEventWorkflowDispatchInputs } from \"./workflow-dispatch\";\nexport function convertOn(context, token) {\n    if (isLiteral(token)) {\n        const event = token.assertString(\"on\");\n        return {\n            [event.value]: {}\n        };\n    }\n    if (isSequence(token)) {\n        const result = {};\n        for (const item of token) {\n            const event = item.assertString(\"on\");\n            result[event.value] = {};\n        }\n        return result;\n    }\n    if (isMapping(token)) {\n        const result = {};\n        for (const item of token) {\n            const eventKey = item.key.assertString(\"event name\");\n            const eventName = eventKey.value;\n            if (item.value.templateTokenType === TokenType.Null) {\n                result[eventName] = {};\n                continue;\n            }\n            // Schedule is the only event that can be a sequence, handle that separately\n            if (eventName === \"schedule\") {\n                const scheduleToken = item.value.assertSequence(`event ${eventName}`);\n                result.schedule = convertSchedule(context, scheduleToken);\n                continue;\n            }\n            // All other events are defined as mappings. During schema validation we already ensure that events\n            // receive only known keys, so here we can focus on the values and whether they are valid.\n            const eventToken = item.value.assertMapping(`event ${eventName}`);\n            if (eventName === \"workflow_call\") {\n                result.workflow_call = convertEventWorkflowCall(context, eventToken);\n                continue;\n            }\n            if (eventName === \"workflow_dispatch\") {\n                result.workflow_dispatch = convertEventWorkflowDispatchInputs(context, eventToken);\n                continue;\n            }\n            result[eventName] = {\n                ...convertPatternFilter(\"branches\", eventToken),\n                ...convertPatternFilter(\"tags\", eventToken),\n                ...convertPatternFilter(\"paths\", eventToken),\n                ...convertFilter(\"types\", eventToken),\n                ...convertFilter(\"workflows\", eventToken)\n            };\n        }\n        return result;\n    }\n    context.error(token, \"Invalid format for 'on'\");\n    return {};\n}\nfunction convertPatternFilter(name, token) {\n    const result = {};\n    for (const item of token) {\n        const key = item.key.assertString(`${name} filter key`);\n        switch (key.value) {\n            case name:\n                if (isString(item.value)) {\n                    result[name] = [item.value.value];\n                }\n                else {\n                    result[name] = convertStringList(name, item.value.assertSequence(`${name} list`));\n                }\n                break;\n            case `${name}-ignore`:\n                if (isString(item.value)) {\n                    result[`${name}-ignore`] = [item.value.value];\n                }\n                else {\n                    result[`${name}-ignore`] = convertStringList(`${name}-ignore`, item.value.assertSequence(`${name}-ignore list`));\n                }\n                break;\n        }\n    }\n    return result;\n}\nfunction convertFilter(name, token) {\n    const result = {};\n    for (const item of token) {\n        const key = item.key.assertString(`${name} filter key`);\n        switch (key.value) {\n            case name:\n                if (isString(item.value)) {\n                    result[name] = [item.value.value];\n                }\n                else {\n                    result[name] = convertStringList(name, item.value.assertSequence(`${name} list`));\n                }\n                break;\n        }\n    }\n    return result;\n}\nfunction convertSchedule(context, token) {\n    const result = [];\n    for (const item of token) {\n        const mappingToken = item.assertMapping(`event schedule`);\n        if (mappingToken.count == 1) {\n            const schedule = mappingToken.get(0);\n            const scheduleKey = schedule.key.assertString(`schedule key`);\n            if (scheduleKey.value == \"cron\") {\n                const cron = schedule.value.assertString(`schedule cron`);\n                // Validate the cron string\n                if (!isValidCron(cron.value)) {\n                    context.error(cron, \"Invalid cron string\");\n                }\n                result.push({ cron: cron.value });\n            }\n            else {\n                context.error(scheduleKey, `Invalid schedule key`);\n            }\n        }\n        else {\n            context.error(mappingToken, \"Invalid format for 'schedule'\");\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=events.js.map","import { TemplateTokenError } from \"../../templates/tokens/template-token\";\nexport function handleTemplateTokenErrors(root, context, defaultValue, f) {\n    let r = defaultValue;\n    try {\n        r = f();\n    }\n    catch (err) {\n        if (err instanceof TemplateTokenError) {\n            context.error(err.token, err);\n        }\n        else {\n            // Report error for the root node\n            context.error(root, err);\n        }\n    }\n    return r;\n}\n//# sourceMappingURL=handle-errors.js.map","const SEPARATOR = \"_\";\nconst MAX_ATTEMPTS = 1000;\nconst MAX_LENGTH = 100;\nexport class IdBuilder {\n    constructor() {\n        this.name = [];\n        this.distinctNames = new Set();\n    }\n    appendSegment(value) {\n        if (value.length === 0) {\n            return;\n        }\n        if (this.name.length == 0) {\n            const first = value[0];\n            if (this.isAlpha(first) || first == \"_\") {\n                // Legal first char\n            }\n            else if (this.isNumeric(first) || first == \"-\") {\n                // Illegal first char, but legal char.\n                // Prepend \"_\".\n                this.name.push(\"_\");\n            }\n            else {\n                // Illegal char\n            }\n        }\n        else {\n            // Separator\n            this.name.push(SEPARATOR);\n        }\n        for (const c of value) {\n            {\n                if (this.isAlphaNumeric(c) || c == \"_\" || c == \"-\") {\n                    // Legal\n                    this.name.push(c);\n                }\n                else {\n                    // Illegal\n                    this.name.push(SEPARATOR);\n                }\n            }\n        }\n    }\n    build() {\n        const original = this.name.length > 0 ? this.name.join(\"\") : \"job\";\n        let suffix = \"\";\n        for (let attempt = 1; attempt < MAX_ATTEMPTS; attempt++) {\n            if (attempt === 1) {\n                suffix = \"\";\n            }\n            else {\n                suffix = `_${attempt}`;\n            }\n            const candidate = original.substring(0, Math.min(original.length, MAX_LENGTH - suffix.length)) + suffix;\n            if (!this.distinctNames.has(candidate)) {\n                this.distinctNames.add(candidate);\n                this.name = [];\n                return candidate;\n            }\n        }\n        throw new Error(\"Unable to create a unique name\");\n    }\n    /**\n     * Adds a known identifier to the set of distinct ids.\n     * @param value The value to add\n     * @returns An error if the value is invalid, otherwise undefined\n     */\n    tryAddKnownId(value) {\n        if (!value || !this.isValid(value) || value.length >= MAX_LENGTH) {\n            return `The identifier '${value}' is invalid. IDs may only contain alphanumeric characters, '_', and '-'. IDs must start with a letter or '_' and and must be less than ${MAX_LENGTH} characters.`;\n        }\n        if (value.startsWith(SEPARATOR + SEPARATOR)) {\n            return `The identifier '${value}' is invalid. IDs starting with '__' are reserved.`;\n        }\n        if (this.distinctNames.has(value)) {\n            return `The identifier '${value}' may not be used more than once within the same scope.`;\n        }\n        this.distinctNames.add(value);\n        return;\n    }\n    /**\n     * A name is valid if it starts with a letter or underscore, and contains only\n     * letters, numbers, underscores, and hyphens.\n     * @param name The string name to validate\n     * @returns Whether the name is valid\n     */\n    isValid(name) {\n        let first = true;\n        for (const c of name) {\n            if (first) {\n                first = false;\n                if (!this.isAlpha(c) && c != \"_\") {\n                    return false;\n                }\n                continue;\n            }\n            if (!this.isAlphaNumeric(c) && c != \"_\" && c != \"-\") {\n                return false;\n            }\n        }\n        return true;\n    }\n    isAlphaNumeric(c) {\n        return this.isAlpha(c) || this.isNumeric(c);\n    }\n    isNumeric(c) {\n        return c >= \"0\" && c <= \"9\";\n    }\n    isAlpha(c) {\n        return (c >= \"a\" && c <= \"z\") || (c >= \"A\" && c <= \"Z\");\n    }\n}\n//# sourceMappingURL=id-builder.js.map","import { BasicExpressionToken } from \"../../templates/tokens\";\nimport { isSequence, isString } from \"../../templates/tokens/type-guards\";\nimport { convertConcurrency } from \"./concurrency\";\nimport { convertToJobContainer, convertToJobServices } from \"./container\";\nimport { handleTemplateTokenErrors } from \"./handle-errors\";\nimport { IdBuilder } from \"./id-builder\";\nimport { convertToActionsEnvironmentRef } from \"./job/environment\";\nimport { convertRunsOn } from \"./job/runs-on\";\nimport { convertSteps } from \"./steps\";\nexport function convertJob(context, jobKey, token) {\n    const error = new IdBuilder().tryAddKnownId(jobKey.value);\n    if (error) {\n        context.error(jobKey, error);\n    }\n    let concurrency, container, env, environment, name, outputs, runsOn, services, strategy;\n    let needs = undefined;\n    let steps = [];\n    let workflowJobRef;\n    let workflowJobInputs;\n    let inheritSecrets = false;\n    let workflowJobSecrets;\n    for (const item of token) {\n        const propertyName = item.key.assertString(\"job property name\");\n        switch (propertyName.value) {\n            case \"concurrency\":\n                handleTemplateTokenErrors(item.value, context, undefined, () => convertConcurrency(context, item.value));\n                concurrency = item.value;\n                break;\n            case \"container\":\n                convertToJobContainer(context, item.value);\n                container = item.value;\n                break;\n            case \"env\":\n                handleTemplateTokenErrors(item.value, context, undefined, () => {\n                    env = item.value.assertMapping(\"job env\");\n                });\n                break;\n            case \"environment\":\n                handleTemplateTokenErrors(item.value, context, undefined, () => convertToActionsEnvironmentRef(context, item.value));\n                environment = item.value;\n                break;\n            case \"name\":\n                name = item.value.assertScalar(\"job name\");\n                break;\n            case \"needs\": {\n                needs = [];\n                if (isString(item.value)) {\n                    const jobNeeds = item.value.assertString(\"job needs id\");\n                    needs.push(jobNeeds);\n                }\n                if (isSequence(item.value)) {\n                    for (const seqItem of item.value) {\n                        const jobNeeds = seqItem.assertString(\"job needs id\");\n                        needs.push(jobNeeds);\n                    }\n                }\n                break;\n            }\n            case \"outputs\":\n                handleTemplateTokenErrors(item.value, context, undefined, () => {\n                    outputs = item.value.assertMapping(\"job outputs\");\n                });\n                break;\n            case \"runs-on\":\n                handleTemplateTokenErrors(item.value, context, undefined, () => convertRunsOn(context, item.value));\n                runsOn = item.value;\n                break;\n            case \"services\":\n                convertToJobServices(context, item.value);\n                services = item.value;\n                break;\n            case \"steps\":\n                steps = convertSteps(context, item.value);\n                break;\n            case \"strategy\":\n                strategy = item.value;\n                break;\n            case \"uses\":\n                workflowJobRef = item.value.assertString(\"job uses value\");\n                break;\n            case \"with\":\n                handleTemplateTokenErrors(item.value, context, undefined, () => {\n                    workflowJobInputs = item.value.assertMapping(\"uses-with value\");\n                });\n                break;\n            case \"secrets\":\n                if (isString(item.value) && item.value.value === \"inherit\") {\n                    inheritSecrets = true;\n                }\n                else {\n                    handleTemplateTokenErrors(item.value, context, undefined, () => {\n                        workflowJobSecrets = item.value.assertMapping(\"uses-secrets value\");\n                    });\n                }\n                break;\n        }\n    }\n    if (workflowJobRef !== undefined) {\n        return {\n            type: \"reusableWorkflowJob\",\n            id: jobKey,\n            name: jobName(name, jobKey),\n            needs: needs || [],\n            if: new BasicExpressionToken(undefined, undefined, \"success()\", undefined, undefined, undefined),\n            ref: workflowJobRef,\n            \"input-definitions\": undefined,\n            \"input-values\": workflowJobInputs,\n            \"secret-definitions\": undefined,\n            \"secret-values\": workflowJobSecrets,\n            \"inherit-secrets\": inheritSecrets || undefined,\n            outputs: undefined,\n            concurrency,\n            strategy\n        };\n    }\n    else {\n        return {\n            type: \"job\",\n            id: jobKey,\n            name: jobName(name, jobKey),\n            needs,\n            if: new BasicExpressionToken(undefined, undefined, \"success()\", undefined, undefined, undefined),\n            env,\n            concurrency,\n            environment,\n            strategy,\n            \"runs-on\": runsOn,\n            container,\n            services,\n            outputs,\n            steps\n        };\n    }\n}\nfunction jobName(name, jobKey) {\n    if (name === undefined) {\n        return jobKey;\n    }\n    if (isString(name) && name.value === \"\") {\n        return jobKey;\n    }\n    return name;\n}\n//# sourceMappingURL=job.js.map","import { isScalar } from \"../../../templates/tokens/type-guards\";\nexport function convertToActionsEnvironmentRef(context, token) {\n    const result = {};\n    if (token.isExpression) {\n        return result;\n    }\n    if (isScalar(token)) {\n        result.name = token;\n        return result;\n    }\n    const environmentMapping = token.assertMapping(\"job environment\");\n    for (const property of environmentMapping) {\n        const propertyName = property.key.assertString(\"job environment key\");\n        if (property.key.isExpression || property.value.isExpression) {\n            continue;\n        }\n        switch (propertyName.value) {\n            case \"name\":\n                result.name = property.value.assertScalar(\"job environment name key\");\n                break;\n            case \"url\":\n                result.url = property.value;\n                break;\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=environment.js.map","export function convertWorkflowJobInputs(context, job) {\n    const inputDefinitions = createTokenMap(job[\"input-definitions\"]?.assertMapping(\"workflow job input definitions\"), \"inputs\");\n    const inputValues = createTokenMap(job[\"input-values\"]?.assertMapping(\"workflow job input values\"), \"with\");\n    if (inputDefinitions !== undefined) {\n        for (const [, [name, value]] of inputDefinitions) {\n            const inputSpec = createTokenMap(value.assertMapping(`input ${name}`), `input ${name} key`);\n            const inputTypeToken = inputSpec?.get(\"type\")?.[1];\n            if (!inputTypeToken) {\n                // This should be validated by the template reader per the schema\n                continue;\n            }\n            const inputSet = inputValues !== undefined && inputValues.has(name.toLowerCase());\n            const required = inputSpec.get(\"required\")?.[1].assertBoolean(`input ${name} required`).value;\n            if (required && !inputSet) {\n                context.error(job.ref, `Input ${name} is required, but not provided while calling.`);\n            }\n        }\n    }\n    if (inputValues !== undefined) {\n        for (const [, [name, value]] of inputValues) {\n            if (!inputDefinitions?.has(name.toLowerCase())) {\n                context.error(value, `Invalid input, ${name} is not defined in the referenced workflow.`);\n            }\n        }\n    }\n}\nexport function createTokenMap(mapping, description) {\n    if (!mapping) {\n        return undefined;\n    }\n    const result = new Map();\n    for (const item of mapping) {\n        const name = item.key.assertString(`${description} key`);\n        result.set(name.value.toLowerCase(), [name.value, item.value]);\n    }\n    return result;\n}\n//# sourceMappingURL=inputs.js.map","import { isMapping, isString, isSequence } from \"../../../templates/tokens/type-guards\";\nexport function convertRunsOn(context, token) {\n    const labels = convertRunsOnLabels(token);\n    if (!isMapping(token)) {\n        return {\n            labels,\n            group: \"\"\n        };\n    }\n    let group = \"\";\n    for (const item of token) {\n        const key = item.key.assertString(\"job runs-on property name\");\n        switch (key.value) {\n            case \"group\": {\n                if (item.value.isExpression) {\n                    continue;\n                }\n                const groupName = item.value.assertString(\"job runs-on group name\").value;\n                const names = groupName.split(\"/\");\n                switch (names.length) {\n                    case 1: {\n                        group = groupName;\n                        break;\n                    }\n                    case 2: {\n                        if (![\"org\", \"organization\", \"ent\", \"enterprise\"].includes(names[0])) {\n                            context.error(item.value, `Invalid runs-on group name '${groupName}. Please use 'organization/' or 'enterprise/' prefix to target a single runner group.'`);\n                            continue;\n                        }\n                        if (!names[1]) {\n                            context.error(item.value, `Invalid runs-on group name '${groupName}'.`);\n                            continue;\n                        }\n                        group = groupName;\n                        break;\n                    }\n                    default: {\n                        context.error(item.value, `Invalid runs-on group name '${groupName}. Please use 'organization/' or 'enterprise/' prefix to target a single runner group.'`);\n                        break;\n                    }\n                }\n                break;\n            }\n            case \"labels\": {\n                const mapLabels = convertRunsOnLabels(item.value);\n                for (const label of mapLabels) {\n                    labels.add(label);\n                }\n                break;\n            }\n        }\n    }\n    return {\n        labels,\n        group\n    };\n}\nfunction convertRunsOnLabels(token) {\n    const labels = new Set();\n    if (token.isExpression) {\n        return labels;\n    }\n    if (isString(token)) {\n        labels.add(token.value);\n        return labels;\n    }\n    if (isSequence(token)) {\n        for (const item of token) {\n            if (item.isExpression) {\n                continue;\n            }\n            const label = item.assertString(\"job runs-on label sequence item\");\n            labels.add(label.value);\n        }\n    }\n    return labels;\n}\n//# sourceMappingURL=runs-on.js.map","import { NullToken } from \"../../../templates/tokens\";\nimport { createTokenMap } from \"./inputs\";\nexport function convertWorkflowJobSecrets(context, job) {\n    // No validation if job passes all secrets\n    if (job[\"inherit-secrets\"]) {\n        return;\n    }\n    const secretDefinitions = createTokenMap(job[\"secret-definitions\"]?.assertMapping(\"workflow job secret definitions\"), \"secrets\");\n    const secretValues = createTokenMap(job[\"secret-values\"]?.assertMapping(\"workflow job secret values\"), \"secrets\");\n    if (secretDefinitions !== undefined) {\n        for (const [, [name, value]] of secretDefinitions) {\n            if (value instanceof NullToken) {\n                continue;\n            }\n            const secretSpec = createTokenMap(value.assertMapping(`secret ${name}`), `secret ${name} key`);\n            const required = secretSpec?.get(\"required\")?.[1].assertBoolean(`secret ${name} required`).value;\n            if (required) {\n                if (secretValues == undefined || !secretValues.has(name.toLowerCase())) {\n                    context.error(job.ref, `Secret ${name} is required, but not provided while calling.`);\n                }\n            }\n        }\n    }\n    if (secretValues !== undefined) {\n        for (const [, [name, value]] of secretValues) {\n            if (!secretDefinitions?.has(name.toLowerCase())) {\n                context.error(value, `Invalid secret, ${name} is not defined in the referenced workflow.`);\n            }\n        }\n    }\n}\n//# sourceMappingURL=secrets.js.map","import { isMapping } from \"../../templates/tokens/type-guards\";\nimport { handleTemplateTokenErrors } from \"./handle-errors\";\nimport { convertJob } from \"./job\";\nexport function convertJobs(context, token) {\n    if (isMapping(token)) {\n        const result = [];\n        const jobsWithSatisfiedNeeds = [];\n        const alljobsWithUnsatisfiedNeeds = [];\n        for (const item of token) {\n            const jobKey = item.key.assertString(\"job name\");\n            const jobDef = item.value.assertMapping(`job ${jobKey.value}`);\n            const job = handleTemplateTokenErrors(token, context, undefined, () => convertJob(context, jobKey, jobDef));\n            if (job) {\n                result.push(job);\n                const node = {\n                    name: job.id.value,\n                    needs: Object.assign([], job.needs)\n                };\n                if (node.needs.length > 0) {\n                    alljobsWithUnsatisfiedNeeds.push(node);\n                }\n                else {\n                    jobsWithSatisfiedNeeds.push(node);\n                }\n            }\n        }\n        //validate job needs\n        validateNeeds(token, context, result, jobsWithSatisfiedNeeds, alljobsWithUnsatisfiedNeeds);\n        return result;\n    }\n    context.error(token, \"Invalid format for jobs\");\n    return [];\n}\nfunction validateNeeds(token, context, result, jobsWithSatisfiedNeeds, alljobsWithUnsatisfiedNeeds) {\n    if (jobsWithSatisfiedNeeds.length == 0) {\n        context.error(token, \"The workflow must contain at least one job with no dependencies.\");\n        return;\n    }\n    // Figure out which nodes would start after current completes\n    while (jobsWithSatisfiedNeeds.length > 0) {\n        const currentJob = jobsWithSatisfiedNeeds.shift();\n        if (currentJob == undefined) {\n            break;\n        }\n        for (let i = alljobsWithUnsatisfiedNeeds.length - 1; i >= 0; i--) {\n            const unsatisfiedJob = alljobsWithUnsatisfiedNeeds[i];\n            for (let j = unsatisfiedJob.needs.length - 1; j >= 0; j--) {\n                const need = unsatisfiedJob.needs[j];\n                if (need.value == currentJob.name) {\n                    unsatisfiedJob.needs.splice(j, 1);\n                    if (unsatisfiedJob.needs.length == 0) {\n                        jobsWithSatisfiedNeeds.push(unsatisfiedJob);\n                        alljobsWithUnsatisfiedNeeds.splice(i, 1);\n                    }\n                }\n            }\n        }\n    }\n    // Check whether some jobs will never execute\n    if (alljobsWithUnsatisfiedNeeds.length > 0) {\n        const jobNames = result.map(x => x.id.value);\n        for (const unsatisfiedJob of alljobsWithUnsatisfiedNeeds) {\n            for (const need of unsatisfiedJob.needs) {\n                if (jobNames.includes(need.value)) {\n                    context.error(need, `Job '${unsatisfiedJob.name}' depends on job '${need.value}' which creates a cycle in the dependency graph.`);\n                }\n                else {\n                    context.error(need, `Job '${unsatisfiedJob.name}' depends on unknown job '${need.value}'.`);\n                }\n            }\n        }\n    }\n}\n//# sourceMappingURL=jobs.js.map","import { TokenType } from \"../../templates/tokens/types\";\nimport { handleTemplateTokenErrors } from \"./handle-errors\";\nimport { convertWorkflowJobInputs } from \"./job/inputs\";\nimport { convertWorkflowJobSecrets } from \"./job/secrets\";\nimport { convertJobs } from \"./jobs\";\nexport function convertReferencedWorkflow(context, referencedWorkflow, job) {\n    const mapping = referencedWorkflow.assertMapping(\"root\");\n    // The language service doesn't currently handles on other documents,\n    // So use the ref in the original workflow as the error location\n    const tokenForErrors = job.ref;\n    for (const pair of mapping) {\n        const key = pair.key.assertString(\"root key\");\n        switch (key.value) {\n            case \"on\": {\n                handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertReferencedWorkflowOn(context, pair.value, job));\n                break;\n            }\n            case \"jobs\": {\n                job.jobs = handleTemplateTokenErrors(tokenForErrors, context, [], () => convertJobs(context, pair.value));\n                break;\n            }\n        }\n    }\n}\nfunction convertReferencedWorkflowOn(context, on, job) {\n    const tokenForErrors = job.ref;\n    switch (on.templateTokenType) {\n        case TokenType.String: {\n            const event = on.assertString(\"Reference workflow on value\").value;\n            if (event === \"workflow_call\") {\n                handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobInputs(context, job));\n                handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobSecrets(context, job));\n                return;\n            }\n            break;\n        }\n        case TokenType.Sequence: {\n            const events = on.assertSequence(\"Reference workflow on value\");\n            for (const eventToken of events) {\n                const event = eventToken.assertString(`Reference workflow on value ${eventToken}`).value;\n                if (event === \"workflow_call\") {\n                    handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobInputs(context, job));\n                    handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobSecrets(context, job));\n                    return;\n                }\n            }\n            break;\n        }\n        case TokenType.Mapping: {\n            const eventMapping = on.assertMapping(\"Reference workflow on value\");\n            for (const pair of eventMapping) {\n                const event = pair.key.assertString(`Reference workflow on value ${pair.key}`).value;\n                if (event !== \"workflow_call\") {\n                    continue;\n                }\n                if (pair.value.templateTokenType === TokenType.Null) {\n                    handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobInputs(context, job));\n                    handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobSecrets(context, job));\n                    return;\n                }\n                const definitions = pair.value.assertMapping(`Reference workflow on value ${pair.key}`);\n                for (const definition of definitions) {\n                    const definitionKey = definition.key.assertString(`on-workflow_call-${definition.key}`).value;\n                    switch (definitionKey) {\n                        case \"inputs\":\n                            job[\"input-definitions\"] = definition.value.assertMapping(`on-workflow_call-${definition.key}`);\n                            break;\n                        case \"outputs\":\n                            job.outputs = definition.value.assertMapping(`on-workflow_call-${definition.key}`);\n                            break;\n                        case \"secrets\":\n                            job[\"secret-definitions\"] = definition.value.assertMapping(`on-workflow_call-${definition.key}`);\n                            break;\n                    }\n                }\n                handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobInputs(context, job));\n                handleTemplateTokenErrors(tokenForErrors, context, undefined, () => convertWorkflowJobSecrets(context, job));\n                return;\n            }\n            break;\n        }\n    }\n    context.error(tokenForErrors, \"workflow_call key is not defined in the referenced workflow.\");\n}\n//# sourceMappingURL=referencedWorkflow.js.map","import { BasicExpressionToken } from \"../../templates/tokens\";\nimport { isSequence } from \"../../templates/tokens/type-guards\";\nimport { isActionStep } from \"../type-guards\";\nimport { handleTemplateTokenErrors } from \"./handle-errors\";\nimport { IdBuilder } from \"./id-builder\";\nexport function convertSteps(context, steps) {\n    if (!isSequence(steps)) {\n        context.error(steps, \"Invalid format for steps\");\n        return [];\n    }\n    const idBuilder = new IdBuilder();\n    const result = [];\n    for (const item of steps) {\n        const step = handleTemplateTokenErrors(steps, context, undefined, () => convertStep(context, idBuilder, item));\n        if (step) {\n            result.push(step);\n        }\n    }\n    for (const step of result) {\n        if (step.id) {\n            continue;\n        }\n        let id = \"\";\n        if (isActionStep(step)) {\n            id = createActionStepId(step);\n        }\n        if (!id) {\n            id = \"run\";\n        }\n        idBuilder.appendSegment(`__${id}`);\n        step.id = idBuilder.build();\n    }\n    return result;\n}\nfunction convertStep(context, idBuilder, step) {\n    const mapping = step.assertMapping(\"steps item\");\n    let run;\n    let id;\n    let name;\n    let uses;\n    let continueOnError;\n    let env;\n    const ifCondition = new BasicExpressionToken(undefined, undefined, \"success()\", undefined, undefined, undefined);\n    for (const item of mapping) {\n        const key = item.key.assertString(\"steps item key\");\n        switch (key.value) {\n            case \"id\":\n                id = item.value.assertString(\"steps item id\");\n                if (id) {\n                    const error = idBuilder.tryAddKnownId(id.value);\n                    if (error) {\n                        context.error(id, error);\n                    }\n                }\n                break;\n            case \"name\":\n                name = item.value.assertScalar(\"steps item name\");\n                break;\n            case \"run\":\n                run = item.value.assertScalar(\"steps item run\");\n                break;\n            case \"uses\":\n                uses = item.value.assertString(\"steps item uses\");\n                break;\n            case \"env\":\n                env = item.value.assertMapping(\"step env\");\n                break;\n            case \"continue-on-error\":\n                if (!item.value.isExpression) {\n                    continueOnError = item.value.assertBoolean(\"steps item continue-on-error\").value;\n                }\n                else {\n                    continueOnError = item.value.assertScalar(\"steps item continue-on-error\");\n                }\n        }\n    }\n    if (run) {\n        return {\n            id: id?.value || \"\",\n            name,\n            if: ifCondition,\n            \"continue-on-error\": continueOnError,\n            env,\n            run\n        };\n    }\n    if (uses) {\n        return {\n            id: id?.value || \"\",\n            name,\n            if: ifCondition,\n            \"continue-on-error\": continueOnError,\n            env,\n            uses\n        };\n    }\n    context.error(step, \"Expected uses or run to be defined\");\n}\nfunction createActionStepId(step) {\n    const uses = step.uses.value;\n    if (uses.startsWith(\"docker://\")) {\n        return uses.substring(\"docker://\".length);\n    }\n    if (uses.startsWith(\"./\") || uses.startsWith(\".\\\\\")) {\n        return \"self\";\n    }\n    const segments = uses.split(\"@\");\n    if (segments.length != 2) {\n        return \"\";\n    }\n    const pathSegments = segments[0].split(/[\\\\/]/).filter(s => s.length > 0);\n    const gitRef = segments[1];\n    if (pathSegments.length >= 2 && pathSegments[0] && pathSegments[1] && gitRef) {\n        return `${pathSegments[0]}/${pathSegments[1]}`;\n    }\n    return \"\";\n}\n//# sourceMappingURL=steps.js.map","export function convertStringList(name, token) {\n    const result = [];\n    for (const item of token) {\n        result.push(item.assertString(`${name} item`).value);\n    }\n    return result;\n}\n//# sourceMappingURL=string-list.js.map","import { isMapping } from \"../../templates/tokens/type-guards\";\nimport { InputType } from \"../workflow-template\";\nimport { convertStringList } from \"./string-list\";\nexport function convertEventWorkflowCall(context, token) {\n    const result = {};\n    for (const item of token) {\n        const key = item.key.assertString(\"workflow dispatch input key\");\n        switch (key.value) {\n            case \"inputs\":\n                result.inputs = convertWorkflowInputs(context, item.value.assertMapping(\"workflow dispatch inputs\"));\n                break;\n            case \"secrets\":\n                result.secrets = convertWorkflowCallSecrets(context, item.value.assertMapping(\"workflow dispatch inputs\"));\n                break;\n            case \"outputs\":\n                // TODO - outputs\n                break;\n        }\n    }\n    return result;\n}\nexport function convertWorkflowInputs(context, token) {\n    const result = {};\n    for (const item of token) {\n        const inputName = item.key.assertString(\"input name\");\n        const inputMapping = item.value.assertMapping(\"input configuration\");\n        result[inputName.value] = convertWorkflowInput(context, inputMapping);\n    }\n    return result;\n}\nexport function convertWorkflowInput(context, token) {\n    const result = {\n        type: InputType.string // Default to string\n    };\n    let defaultValue;\n    for (const item of token) {\n        const key = item.key.assertString(\"workflow dispatch input key\");\n        switch (key.value) {\n            case \"description\":\n                result.description = item.value.assertString(\"input description\").value;\n                break;\n            case \"required\":\n                result.required = item.value.assertBoolean(\"input required\").value;\n                break;\n            case \"default\":\n                defaultValue = item.value.assertScalar(\"input default\");\n                break;\n            case \"type\":\n                result.type = InputType[item.value.assertString(\"input type\").value];\n                break;\n            case \"options\":\n                result.options = convertStringList(\"input options\", item.value.assertSequence(\"input options\"));\n                break;\n            default:\n                context.error(item.key, `Invalid key '${key.value}'`);\n        }\n    }\n    // Validate default value\n    if (defaultValue !== undefined && !defaultValue.isExpression) {\n        try {\n            switch (result.type) {\n                case InputType.boolean:\n                    result.default = defaultValue.assertBoolean(\"input default\").value;\n                    break;\n                case InputType.string:\n                case InputType.choice:\n                case InputType.environment:\n                    result.default = defaultValue.assertString(\"input default\").value;\n                    break;\n            }\n        }\n        catch (e) {\n            context.error(defaultValue, e);\n        }\n    }\n    // Validate `options` for `choice` type\n    if (result.type === InputType.choice) {\n        if (result.options === undefined || result.options.length === 0) {\n            context.error(token, \"Missing 'options' for choice input\");\n        }\n    }\n    else {\n        if (result.options !== undefined) {\n            context.error(token, \"Input type is not 'choice', but 'options' is defined\");\n        }\n    }\n    return result;\n}\nfunction convertWorkflowCallSecrets(context, token) {\n    const result = {};\n    for (const item of token) {\n        const secretName = item.key.assertString(\"secret name\");\n        result[secretName.value] = convertWorkflowCallSecret(context, item.value);\n    }\n    return result;\n}\nfunction convertWorkflowCallSecret(context, token) {\n    const result = {};\n    if (isMapping(token)) {\n        for (const item of token) {\n            const key = item.key.assertString(\"workflow call secret key\");\n            switch (key.value) {\n                case \"description\":\n                    result.description = item.value.assertString(\"secret description\").value;\n                    break;\n                case \"required\":\n                    result.required = item.value.assertBoolean(\"secret required\").value;\n                    break;\n            }\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=workflow-call.js.map","import { InputType } from \"../workflow-template\";\nimport { convertStringList } from \"./string-list\";\nexport function convertEventWorkflowDispatchInputs(context, token) {\n    const result = {};\n    for (const item of token) {\n        const key = item.key.assertString(\"workflow dispatch input key\");\n        switch (key.value) {\n            case \"inputs\":\n                result.inputs = convertWorkflowDispatchInputs(context, item.value.assertMapping(\"workflow dispatch inputs\"));\n                break;\n        }\n    }\n    return result;\n}\nexport function convertWorkflowDispatchInputs(context, token) {\n    const result = {};\n    for (const item of token) {\n        const inputName = item.key.assertString(\"input name\");\n        const inputMapping = item.value.assertMapping(\"input configuration\");\n        result[inputName.value] = convertWorkflowDispatchInput(context, inputMapping);\n    }\n    return result;\n}\nexport function convertWorkflowDispatchInput(context, token) {\n    const result = {\n        type: InputType.string // Default to string\n    };\n    let defaultValue;\n    for (const item of token) {\n        const key = item.key.assertString(\"workflow dispatch input key\");\n        switch (key.value) {\n            case \"description\":\n                result.description = item.value.assertString(\"input description\").value;\n                break;\n            case \"required\":\n                result.required = item.value.assertBoolean(\"input required\").value;\n                break;\n            case \"default\":\n                defaultValue = item.value.assertScalar(\"input default\");\n                break;\n            case \"type\":\n                result.type = InputType[item.value.assertString(\"input type\").value];\n                break;\n            case \"options\":\n                result.options = convertStringList(\"input options\", item.value.assertSequence(\"input options\"));\n                break;\n            default:\n                context.error(item.key, `Invalid key '${key.value}'`);\n        }\n    }\n    // Validate default value\n    if (defaultValue !== undefined) {\n        try {\n            switch (result.type) {\n                case InputType.boolean:\n                    result.default = defaultValue.assertBoolean(\"input default\").value;\n                    break;\n                case InputType.string:\n                case InputType.choice:\n                case InputType.environment:\n                    result.default = defaultValue.assertString(\"input default\").value;\n                    break;\n            }\n        }\n        catch (e) {\n            context.error(defaultValue, e);\n        }\n    }\n    // Validate `options` for `choice` type\n    if (result.type === InputType.choice) {\n        if (result.options === undefined || result.options.length === 0) {\n            context.error(token, \"Missing 'options' for choice input\");\n        }\n    }\n    else {\n        if (result.options !== undefined) {\n            context.error(token, \"Input type is not 'choice', but 'options' is defined\");\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=workflow-dispatch.js.map","export function isRunStep(step) {\n    return step.run !== undefined;\n}\nexport function isActionStep(step) {\n    return step.uses !== undefined;\n}\nexport function isJob(job) {\n    return job.type === \"job\";\n}\nexport function isReusableWorkflowJob(job) {\n    return job.type === \"reusableWorkflowJob\";\n}\n//# sourceMappingURL=type-guards.js.map","export var InputType;\n(function (InputType) {\n    InputType[\"string\"] = \"string\";\n    InputType[\"choice\"] = \"choice\";\n    InputType[\"boolean\"] = \"boolean\";\n    InputType[\"environment\"] = \"environment\";\n})(InputType || (InputType = {}));\n//# sourceMappingURL=workflow-template.js.map","import { MAX_CONSTANT } from \"./template-constants\";\nexport function splitAllowedContext(allowedContext) {\n    const FUNCTION_REGEXP = /^([a-zA-Z0-9_]+)\\(([0-9]+),([0-9]+|MAX)\\)$/;\n    const namedContexts = [];\n    const functions = [];\n    if (allowedContext.length > 0) {\n        for (const contextItem of allowedContext) {\n            const match = contextItem.match(FUNCTION_REGEXP);\n            if (match) {\n                const functionName = match[1];\n                const minParameters = Number.parseInt(match[2]);\n                const maxParametersRaw = match[3];\n                const maxParameters = maxParametersRaw === MAX_CONSTANT ? Number.MAX_SAFE_INTEGER : Number.parseInt(maxParametersRaw);\n                functions.push({\n                    name: functionName,\n                    minArgs: minParameters,\n                    maxArgs: maxParameters\n                });\n            }\n            else {\n                namedContexts.push(contextItem);\n            }\n        }\n    }\n    return {\n        namedContexts: namedContexts,\n        functions: functions\n    };\n}\n//# sourceMappingURL=allowed-context.js.map","import { EventType, ParseEvent } from \"./parse-event\";\nimport { SequenceToken, MappingToken, NullToken, BooleanToken, NumberToken, StringToken } from \"./tokens\";\nexport class JSONObjectReader {\n    constructor(fileId, input) {\n        this._fileId = fileId;\n        const value = JSON.parse(input);\n        this._generator = this.getParseEvents(value, true);\n        this._current = this._generator.next();\n    }\n    allowLiteral() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.Literal) {\n                this._current = this._generator.next();\n                return parseEvent.token;\n            }\n        }\n        return undefined;\n    }\n    allowSequenceStart() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.SequenceStart) {\n                this._current = this._generator.next();\n                return parseEvent.token;\n            }\n        }\n        return undefined;\n    }\n    allowSequenceEnd() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.SequenceEnd) {\n                this._current = this._generator.next();\n                return true;\n            }\n        }\n        return false;\n    }\n    allowMappingStart() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.MappingStart) {\n                this._current = this._generator.next();\n                return parseEvent.token;\n            }\n        }\n        return undefined;\n    }\n    allowMappingEnd() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.MappingEnd) {\n                this._current = this._generator.next();\n                return true;\n            }\n        }\n        return false;\n    }\n    validateEnd() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.DocumentEnd) {\n                this._current = this._generator.next();\n                return;\n            }\n        }\n        throw new Error(\"Expected end of reader\");\n    }\n    validateStart() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.DocumentStart) {\n                this._current = this._generator.next();\n                return;\n            }\n        }\n        throw new Error(\"Expected start of reader\");\n    }\n    /**\n     * Returns all tokens (depth first)\n     */\n    *getParseEvents(value, root) {\n        if (root) {\n            yield new ParseEvent(EventType.DocumentStart, undefined);\n        }\n        switch (typeof value) {\n            case \"undefined\":\n                yield new ParseEvent(EventType.Literal, new NullToken(this._fileId, undefined, undefined));\n                break;\n            case \"boolean\":\n                yield new ParseEvent(EventType.Literal, new BooleanToken(this._fileId, undefined, value, undefined));\n                break;\n            case \"number\":\n                yield new ParseEvent(EventType.Literal, new NumberToken(this._fileId, undefined, value, undefined));\n                break;\n            case \"string\":\n                yield new ParseEvent(EventType.Literal, new StringToken(this._fileId, undefined, value, undefined));\n                break;\n            case \"object\":\n                // null\n                if (value === null) {\n                    yield new ParseEvent(EventType.Literal, new NullToken(this._fileId, undefined, undefined));\n                }\n                // array\n                else if (Array.isArray(value)) {\n                    yield new ParseEvent(EventType.SequenceStart, new SequenceToken(this._fileId, undefined, undefined));\n                    for (const item of value) {\n                        for (const e of this.getParseEvents(item)) {\n                            yield e;\n                        }\n                    }\n                    yield new ParseEvent(EventType.SequenceEnd, undefined);\n                }\n                // object\n                else {\n                    yield new ParseEvent(EventType.MappingStart, new MappingToken(this._fileId, undefined, undefined));\n                    for (const key of Object.keys(value)) {\n                        yield new ParseEvent(EventType.Literal, new StringToken(this._fileId, undefined, key, undefined));\n                        for (const e of this.getParseEvents(value[key])) {\n                            yield e;\n                        }\n                    }\n                    yield new ParseEvent(EventType.MappingEnd, undefined);\n                }\n                break;\n            default:\n                throw new Error(`Unexpected value type '${typeof value}' when reading object`);\n        }\n        if (root) {\n            yield new ParseEvent(EventType.DocumentEnd, undefined);\n        }\n    }\n}\n//# sourceMappingURL=json-object-reader.js.map","export class ParseEvent {\n    constructor(type, token) {\n        this.type = type;\n        this.token = token;\n    }\n}\nexport var EventType;\n(function (EventType) {\n    EventType[EventType[\"Literal\"] = 0] = \"Literal\";\n    EventType[EventType[\"SequenceStart\"] = 1] = \"SequenceStart\";\n    EventType[EventType[\"SequenceEnd\"] = 2] = \"SequenceEnd\";\n    EventType[EventType[\"MappingStart\"] = 3] = \"MappingStart\";\n    EventType[EventType[\"MappingEnd\"] = 4] = \"MappingEnd\";\n    EventType[EventType[\"DocumentStart\"] = 5] = \"DocumentStart\";\n    EventType[EventType[\"DocumentEnd\"] = 6] = \"DocumentEnd\";\n})(EventType || (EventType = {}));\n//# sourceMappingURL=parse-event.js.map","import { DEFINITION, BOOLEAN } from \"../template-constants\";\nimport { TokenType } from \"../tokens/types\";\nimport { DefinitionType } from \"./definition-type\";\nimport { ScalarDefinition } from \"./scalar-definition\";\nexport class BooleanDefinition extends ScalarDefinition {\n    constructor(key, definition) {\n        super(key, definition);\n        if (definition) {\n            for (const definitionPair of definition) {\n                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case BOOLEAN: {\n                        const mapping = definitionPair.value.assertMapping(`${DEFINITION} ${BOOLEAN}`);\n                        for (const mappingPair of mapping) {\n                            const mappingKey = mappingPair.key.assertString(`${DEFINITION} ${BOOLEAN} key`);\n                            switch (mappingKey.value) {\n                                default:\n                                    // throws\n                                    mappingKey.assertUnexpectedValue(`${DEFINITION} ${BOOLEAN} key`);\n                                    break;\n                            }\n                        }\n                        break;\n                    }\n                    default:\n                        definitionKey.assertUnexpectedValue(`${DEFINITION} key`); // throws\n                }\n            }\n        }\n    }\n    get definitionType() {\n        return DefinitionType.Boolean;\n    }\n    isMatch(literal) {\n        return literal.templateTokenType === TokenType.Boolean;\n    }\n    validate() {\n        // no-op\n    }\n}\n//# sourceMappingURL=boolean-definition.js.map","export class DefinitionInfo {\n    constructor(schemaOrParent, nameOrDefinition) {\n        this.isDefinitionInfo = true;\n        const parent = schemaOrParent?.isDefinitionInfo === true\n            ? schemaOrParent\n            : undefined;\n        this._schema = parent === undefined ? schemaOrParent : parent._schema;\n        // Lookup the definition if a key was passed in\n        this.definition =\n            typeof nameOrDefinition === \"string\" ? this._schema.getDefinition(nameOrDefinition) : nameOrDefinition;\n        // Record allowed context\n        if (this.definition.readerContext.length > 0) {\n            this.allowedContext = [];\n            // Copy parent allowed context\n            const upperSeen = {};\n            for (const context of parent?.allowedContext ?? []) {\n                this.allowedContext.push(context);\n                upperSeen[context.toUpperCase()] = true;\n            }\n            // Append context if unseen\n            for (const context of this.definition.readerContext) {\n                const upper = context.toUpperCase();\n                if (!upperSeen[upper]) {\n                    this.allowedContext.push(context);\n                    upperSeen[upper] = true;\n                }\n            }\n        }\n        else {\n            this.allowedContext = parent?.allowedContext ?? [];\n        }\n    }\n    getScalarDefinitions() {\n        return this._schema.getScalarDefinitions(this.definition);\n    }\n    getDefinitionsOfType(type) {\n        return this._schema.getDefinitionsOfType(this.definition, type);\n    }\n}\n//# sourceMappingURL=definition-info.js.map","export var DefinitionType;\n(function (DefinitionType) {\n    DefinitionType[DefinitionType[\"Null\"] = 0] = \"Null\";\n    DefinitionType[DefinitionType[\"Boolean\"] = 1] = \"Boolean\";\n    DefinitionType[DefinitionType[\"Number\"] = 2] = \"Number\";\n    DefinitionType[DefinitionType[\"String\"] = 3] = \"String\";\n    DefinitionType[DefinitionType[\"Sequence\"] = 4] = \"Sequence\";\n    DefinitionType[DefinitionType[\"Mapping\"] = 5] = \"Mapping\";\n    DefinitionType[DefinitionType[\"OneOf\"] = 6] = \"OneOf\";\n    DefinitionType[DefinitionType[\"AllowedValues\"] = 7] = \"AllowedValues\";\n})(DefinitionType || (DefinitionType = {}));\n//# sourceMappingURL=definition-type.js.map","import { CONTEXT, DEFINITION, DESCRIPTION } from \"../template-constants\";\n/**\n * Defines the allowable schema for a user defined type\n */\nexport class Definition {\n    constructor(key, definition) {\n        /**\n         * Used by the template reader to determine allowed expression values and functions.\n         * Also used by the template reader to validate function min/max parameters.\n         */\n        this.readerContext = [];\n        /**\n         * Used by the template evaluator to determine allowed expression values and functions.\n         * The min/max parameter info is omitted.\n         */\n        this.evaluatorContext = [];\n        this.key = key;\n        if (definition) {\n            for (let i = 0; i < definition.count;) {\n                const definitionKey = definition.get(i).key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case CONTEXT: {\n                        const context = definition.get(i).value.assertSequence(`${DEFINITION} ${CONTEXT}`);\n                        definition.remove(i);\n                        const seenReaderContext = {};\n                        const seenEvaluatorContext = {};\n                        for (const item of context) {\n                            const itemStr = item.assertString(`${CONTEXT} item`).value;\n                            const upperItemStr = itemStr.toUpperCase();\n                            if (seenReaderContext[upperItemStr]) {\n                                throw new Error(`Duplicate context item '${itemStr}'`);\n                            }\n                            seenReaderContext[upperItemStr] = true;\n                            this.readerContext.push(itemStr);\n                            // Remove min/max parameter info\n                            const paramIndex = itemStr.indexOf(\"(\");\n                            const modifiedItemStr = paramIndex > 0 ? itemStr.substr(0, paramIndex + 1) + \")\" : itemStr;\n                            const upperModifiedItemStr = modifiedItemStr.toUpperCase();\n                            if (seenEvaluatorContext[upperModifiedItemStr]) {\n                                throw new Error(`Duplicate context item '${modifiedItemStr}'`);\n                            }\n                            seenEvaluatorContext[upperModifiedItemStr] = true;\n                            this.evaluatorContext.push(modifiedItemStr);\n                        }\n                        break;\n                    }\n                    case DESCRIPTION: {\n                        const value = definition.get(i).value;\n                        this.description = value.assertString(DESCRIPTION).value;\n                        definition.remove(i);\n                        break;\n                    }\n                    default: {\n                        i++;\n                        break;\n                    }\n                }\n            }\n        }\n    }\n}\n//# sourceMappingURL=definition.js.map","export { TemplateSchema } from \"./template-schema\";\n//# sourceMappingURL=index.js.map","import { DEFINITION, MAPPING, PROPERTIES, LOOSE_KEY_TYPE, LOOSE_VALUE_TYPE } from \"../template-constants\";\nimport { Definition } from \"./definition\";\nimport { DefinitionType } from \"./definition-type\";\nimport { PropertyDefinition } from \"./property-definition\";\nexport class MappingDefinition extends Definition {\n    constructor(key, definition) {\n        super(key, definition);\n        this.properties = {};\n        this.looseKeyType = \"\";\n        this.looseValueType = \"\";\n        if (definition) {\n            for (const definitionPair of definition) {\n                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case MAPPING: {\n                        const mapping = definitionPair.value.assertMapping(`${DEFINITION} ${MAPPING}`);\n                        for (const mappingPair of mapping) {\n                            const mappingKey = mappingPair.key.assertString(`${DEFINITION} ${MAPPING} key`);\n                            switch (mappingKey.value) {\n                                case PROPERTIES: {\n                                    const properties = mappingPair.value.assertMapping(`${DEFINITION} ${MAPPING} ${PROPERTIES}`);\n                                    for (const propertiesPair of properties) {\n                                        const propertyName = propertiesPair.key.assertString(`${DEFINITION} ${MAPPING} ${PROPERTIES} key`);\n                                        this.properties[propertyName.value] = new PropertyDefinition(propertiesPair.value);\n                                    }\n                                    break;\n                                }\n                                case LOOSE_KEY_TYPE: {\n                                    const looseKeyType = mappingPair.value.assertString(`${DEFINITION} ${MAPPING} ${LOOSE_KEY_TYPE}`);\n                                    this.looseKeyType = looseKeyType.value;\n                                    break;\n                                }\n                                case LOOSE_VALUE_TYPE: {\n                                    const looseValueType = mappingPair.value.assertString(`${DEFINITION} ${MAPPING} ${LOOSE_VALUE_TYPE}`);\n                                    this.looseValueType = looseValueType.value;\n                                    break;\n                                }\n                                default:\n                                    // throws\n                                    mappingKey.assertUnexpectedValue(`${DEFINITION} ${MAPPING} key`);\n                                    break;\n                            }\n                        }\n                        break;\n                    }\n                    default:\n                        definitionKey.assertUnexpectedValue(`${DEFINITION} key`); // throws\n                }\n            }\n        }\n    }\n    get definitionType() {\n        return DefinitionType.Mapping;\n    }\n    validate(schema, name) {\n        // Lookup loose key type\n        if (this.looseKeyType) {\n            schema.getDefinition(this.looseKeyType);\n            // Lookup loose value type\n            if (this.looseValueType) {\n                schema.getDefinition(this.looseValueType);\n            }\n            else {\n                throw new Error(`Property '${LOOSE_KEY_TYPE}' is defined but '${LOOSE_VALUE_TYPE}' is not defined on '${name}'`);\n            }\n        }\n        // Otherwise validate loose value type not be defined\n        else if (this.looseValueType) {\n            throw new Error(`Property '${LOOSE_VALUE_TYPE}' is defined but '${LOOSE_KEY_TYPE}' is not defined on '${name}'`);\n        }\n        // Lookup each property\n        for (const propertyName of Object.keys(this.properties)) {\n            const propertyDef = this.properties[propertyName];\n            if (!propertyDef.type) {\n                throw new Error(`Type not specified for the property '${propertyName}' on '${name}'`);\n            }\n            schema.getDefinition(propertyDef.type);\n        }\n    }\n}\n//# sourceMappingURL=mapping-definition.js.map","import { DEFINITION, NULL } from \"../template-constants\";\nimport { DefinitionType } from \"./definition-type\";\nimport { ScalarDefinition } from \"./scalar-definition\";\nimport { TokenType } from \"../tokens/types\";\nexport class NullDefinition extends ScalarDefinition {\n    constructor(key, definition) {\n        super(key, definition);\n        if (definition) {\n            for (const definitionPair of definition) {\n                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case NULL: {\n                        const mapping = definitionPair.value.assertMapping(`${DEFINITION} ${NULL}`);\n                        for (const mappingPair of mapping) {\n                            const mappingKey = mappingPair.key.assertString(`${DEFINITION} ${NULL} key`);\n                            switch (mappingKey.value) {\n                                default:\n                                    // throws\n                                    mappingKey.assertUnexpectedValue(`${DEFINITION} ${NULL} key`);\n                                    break;\n                            }\n                        }\n                        break;\n                    }\n                    default:\n                        definitionKey.assertUnexpectedValue(`${DEFINITION} key`); // throws\n                }\n            }\n        }\n    }\n    get definitionType() {\n        return DefinitionType.Null;\n    }\n    isMatch(literal) {\n        return literal.templateTokenType === TokenType.Null;\n    }\n    validate() {\n        // no-op\n    }\n}\n//# sourceMappingURL=null-definition.js.map","import { DEFINITION, NUMBER } from \"../template-constants\";\nimport { DefinitionType } from \"./definition-type\";\nimport { ScalarDefinition } from \"./scalar-definition\";\nimport { TokenType } from \"../tokens/types\";\nexport class NumberDefinition extends ScalarDefinition {\n    constructor(key, definition) {\n        super(key, definition);\n        if (definition) {\n            for (const definitionPair of definition) {\n                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case NUMBER: {\n                        const mapping = definitionPair.value.assertMapping(`${DEFINITION} ${NUMBER}`);\n                        for (const mappingPair of mapping) {\n                            const mappingKey = mappingPair.key.assertString(`${DEFINITION} ${NUMBER} key`);\n                            switch (mappingKey.value) {\n                                default:\n                                    // throws\n                                    mappingKey.assertUnexpectedValue(`${DEFINITION} ${NUMBER} key`);\n                                    break;\n                            }\n                        }\n                        break;\n                    }\n                    default:\n                        definitionKey.assertUnexpectedValue(`${DEFINITION} key`); // throws\n                }\n            }\n        }\n    }\n    get definitionType() {\n        return DefinitionType.Number;\n    }\n    isMatch(literal) {\n        return literal.templateTokenType === TokenType.Number;\n    }\n    validate() {\n        // no-op\n    }\n}\n//# sourceMappingURL=number-definition.js.map","import { DEFINITION, ONE_OF, SEQUENCE, NULL, BOOLEAN, NUMBER, SCALAR, CONSTANT, LOOSE_KEY_TYPE, ALLOWED_VALUES } from \"../template-constants\";\nimport { Definition } from \"./definition\";\nimport { DefinitionType } from \"./definition-type\";\n/**\n * Must resolve to exactly one of the referenced definitions\n */\nexport class OneOfDefinition extends Definition {\n    constructor(key, definition) {\n        super(key, definition);\n        this.oneOf = [];\n        this.oneOfPrefix = [];\n        if (definition) {\n            for (const definitionPair of definition) {\n                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case ONE_OF: {\n                        const oneOf = definitionPair.value.assertSequence(`${DEFINITION} ${ONE_OF}`);\n                        for (const item of oneOf) {\n                            const oneOfItem = item.assertString(`${DEFINITION} ${ONE_OF} item`);\n                            this.oneOf.push(oneOfItem.value);\n                        }\n                        break;\n                    }\n                    case ALLOWED_VALUES: {\n                        const oneOf = definitionPair.value.assertSequence(`${DEFINITION} ${ALLOWED_VALUES}`);\n                        for (const item of oneOf) {\n                            const oneOfItem = item.assertString(`${DEFINITION} ${ONE_OF} item`);\n                            this.oneOf.push(this.key + \"-\" + oneOfItem.value);\n                        }\n                        break;\n                    }\n                    default:\n                        // throws\n                        definitionKey.assertUnexpectedValue(`${DEFINITION} key`);\n                        break;\n                }\n            }\n        }\n    }\n    get definitionType() {\n        return DefinitionType.OneOf;\n    }\n    validate(schema, name) {\n        if (this.oneOf.length === 0) {\n            throw new Error(`'${name}' does not contain any references`);\n        }\n        let foundLooseKeyType = false;\n        const mappingDefinitions = [];\n        let allowedValuesDefinition;\n        let sequenceDefinition;\n        let nullDefinition;\n        let booleanDefinition;\n        let numberDefinition;\n        const stringDefinitions = [];\n        const seenNestedTypes = {};\n        for (const nestedType of this.oneOf) {\n            if (seenNestedTypes[nestedType]) {\n                throw new Error(`'${name}' contains duplicate nested type '${nestedType}'`);\n            }\n            seenNestedTypes[nestedType] = true;\n            const nestedDefinition = schema.getDefinition(nestedType);\n            if (nestedDefinition.readerContext.length > 0) {\n                throw new Error(`'${name}' is a one-of definition and references another definition that defines context. This is currently not supported.`);\n            }\n            switch (nestedDefinition.definitionType) {\n                case DefinitionType.Mapping: {\n                    const mappingDefinition = nestedDefinition;\n                    mappingDefinitions.push(mappingDefinition);\n                    if (mappingDefinition.looseKeyType) {\n                        foundLooseKeyType = true;\n                    }\n                    break;\n                }\n                case DefinitionType.Sequence: {\n                    // Multiple sequence definitions not allowed\n                    if (sequenceDefinition) {\n                        throw new Error(`'${name}' refers to more than one definition of type '${SEQUENCE}'`);\n                    }\n                    sequenceDefinition = nestedDefinition;\n                    break;\n                }\n                case DefinitionType.Null: {\n                    // Multiple null definitions not allowed\n                    if (nullDefinition) {\n                        throw new Error(`'${name}' refers to more than one definition of type '${NULL}'`);\n                    }\n                    nullDefinition = nestedDefinition;\n                    break;\n                }\n                case DefinitionType.Boolean: {\n                    // Multiple boolean definitions not allowed\n                    if (booleanDefinition) {\n                        throw new Error(`'${name}' refers to more than one definition of type '${BOOLEAN}'`);\n                    }\n                    booleanDefinition = nestedDefinition;\n                    break;\n                }\n                case DefinitionType.Number: {\n                    // Multiple number definitions not allowed\n                    if (numberDefinition) {\n                        throw new Error(`'${name}' refers to more than one definition of type '${NUMBER}'`);\n                    }\n                    numberDefinition = nestedDefinition;\n                    break;\n                }\n                case DefinitionType.String: {\n                    const stringDefinition = nestedDefinition;\n                    // Multiple string definitions\n                    if (stringDefinitions.length > 0 && (!stringDefinitions[0].constant || !stringDefinition.constant)) {\n                        throw new Error(`'${name}' refers to more than one '${SCALAR}', but some do not set '${CONSTANT}'`);\n                    }\n                    stringDefinitions.push(stringDefinition);\n                    break;\n                }\n                case DefinitionType.OneOf: {\n                    // Multiple allowed-values definitions not allowed\n                    if (allowedValuesDefinition) {\n                        throw new Error(`'${name}' contains multiple allowed-values definitions`);\n                    }\n                    allowedValuesDefinition = nestedDefinition;\n                    break;\n                }\n                default:\n                    throw new Error(`'${name}' refers to a definition with type '${nestedDefinition.definitionType}'`);\n            }\n        }\n        if (mappingDefinitions.length > 1) {\n            if (foundLooseKeyType) {\n                throw new Error(`'${name}' refers to two mappings and at least one sets '${LOOSE_KEY_TYPE}'. This is not currently supported.`);\n            }\n            const seenProperties = {};\n            for (const mappingDefinition of mappingDefinitions) {\n                for (const propertyName of Object.keys(mappingDefinition.properties)) {\n                    const newPropertyDef = mappingDefinition.properties[propertyName];\n                    // Already seen\n                    const existingPropertyDef = seenProperties[propertyName];\n                    if (existingPropertyDef) {\n                        // Types match\n                        if (existingPropertyDef.type === newPropertyDef.type) {\n                            continue;\n                        }\n                        // Collision\n                        throw new Error(`'${name}' contains two mappings with the same property, but each refers to a different type. All matching properties must refer to the same type.`);\n                    }\n                    // New\n                    else {\n                        seenProperties[propertyName] = newPropertyDef;\n                    }\n                }\n            }\n        }\n    }\n}\n//# sourceMappingURL=one-of-definition.js.map","import { MAPPING_PROPERTY_VALUE, TYPE, REQUIRED, DESCRIPTION } from \"../template-constants\";\nimport { TokenType } from \"../tokens/types\";\nexport class PropertyDefinition {\n    constructor(token) {\n        this.type = \"\";\n        this.required = false;\n        if (token.templateTokenType === TokenType.String) {\n            this.type = token.value;\n        }\n        else {\n            const mapping = token.assertMapping(MAPPING_PROPERTY_VALUE);\n            for (const mappingPair of mapping) {\n                const mappingKey = mappingPair.key.assertString(`${MAPPING_PROPERTY_VALUE} key`);\n                switch (mappingKey.value) {\n                    case TYPE:\n                        this.type = mappingPair.value.assertString(`${MAPPING_PROPERTY_VALUE} ${TYPE}`).value;\n                        break;\n                    case REQUIRED:\n                        this.required = mappingPair.value.assertBoolean(`${MAPPING_PROPERTY_VALUE} ${REQUIRED}`).value;\n                        break;\n                    case DESCRIPTION:\n                        this.description = mappingPair.value.assertString(`${MAPPING_PROPERTY_VALUE} ${DESCRIPTION}`).value;\n                        break;\n                    default:\n                        mappingKey.assertUnexpectedValue(`${MAPPING_PROPERTY_VALUE} key`); // throws\n                }\n            }\n        }\n    }\n}\n//# sourceMappingURL=property-definition.js.map","import { Definition } from \"./definition\";\nexport class ScalarDefinition extends Definition {\n    constructor(key, definition) {\n        super(key, definition);\n    }\n}\n//# sourceMappingURL=scalar-definition.js.map","import { DEFINITION, SEQUENCE, ITEM_TYPE } from \"../template-constants\";\nimport { Definition } from \"./definition\";\nimport { DefinitionType } from \"./definition-type\";\nexport class SequenceDefinition extends Definition {\n    constructor(key, definition) {\n        super(key, definition);\n        this.itemType = \"\";\n        if (definition) {\n            for (const definitionPair of definition) {\n                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case SEQUENCE: {\n                        const mapping = definitionPair.value.assertMapping(`${DEFINITION} ${SEQUENCE}`);\n                        for (const mappingPair of mapping) {\n                            const mappingKey = mappingPair.key.assertString(`${DEFINITION} ${SEQUENCE} key`);\n                            switch (mappingKey.value) {\n                                case ITEM_TYPE: {\n                                    const itemType = mappingPair.value.assertString(`${DEFINITION} ${SEQUENCE} ${ITEM_TYPE}`);\n                                    this.itemType = itemType.value;\n                                    break;\n                                }\n                                default:\n                                    // throws\n                                    mappingKey.assertUnexpectedValue(`${DEFINITION} ${SEQUENCE} key`);\n                                    break;\n                            }\n                        }\n                        break;\n                    }\n                    default:\n                        definitionKey.assertUnexpectedValue(`${DEFINITION} key`); // throws\n                }\n            }\n        }\n    }\n    get definitionType() {\n        return DefinitionType.Sequence;\n    }\n    validate(schema, name) {\n        if (!this.itemType) {\n            throw new Error(`'${name}' does not defined '${ITEM_TYPE}'`);\n        }\n        // Lookup item type\n        schema.getDefinition(this.itemType);\n    }\n}\n//# sourceMappingURL=sequence-definition.js.map","import { CONSTANT, DEFINITION, IGNORE_CASE, IS_EXPRESSION, REQUIRE_NON_EMPTY, STRING } from \"../template-constants\";\nimport { TokenType } from \"../tokens/types\";\nimport { DefinitionType } from \"./definition-type\";\nimport { ScalarDefinition } from \"./scalar-definition\";\nexport class StringDefinition extends ScalarDefinition {\n    constructor(key, definition) {\n        super(key, definition);\n        this.constant = \"\";\n        this.ignoreCase = false;\n        this.requireNonEmpty = false;\n        this.isExpression = false;\n        if (definition) {\n            for (const definitionPair of definition) {\n                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                switch (definitionKey.value) {\n                    case STRING: {\n                        const mapping = definitionPair.value.assertMapping(`${DEFINITION} ${STRING}`);\n                        for (const mappingPair of mapping) {\n                            const mappingKey = mappingPair.key.assertString(`${DEFINITION} ${STRING} key`);\n                            switch (mappingKey.value) {\n                                case CONSTANT: {\n                                    const constantStringToken = mappingPair.value.assertString(`${DEFINITION} ${STRING} ${CONSTANT}`);\n                                    this.constant = constantStringToken.value;\n                                    break;\n                                }\n                                case IGNORE_CASE: {\n                                    const ignoreCaseBooleanToken = mappingPair.value.assertBoolean(`${DEFINITION} ${STRING} ${IGNORE_CASE}`);\n                                    this.ignoreCase = ignoreCaseBooleanToken.value;\n                                    break;\n                                }\n                                case REQUIRE_NON_EMPTY: {\n                                    const requireNonEmptyBooleanToken = mappingPair.value.assertBoolean(`${DEFINITION} ${STRING} ${REQUIRE_NON_EMPTY}`);\n                                    this.requireNonEmpty = requireNonEmptyBooleanToken.value;\n                                    break;\n                                }\n                                case IS_EXPRESSION: {\n                                    const isExpressionToken = mappingPair.value.assertBoolean(`${DEFINITION} ${STRING} ${IS_EXPRESSION}`);\n                                    this.isExpression = isExpressionToken.value;\n                                    break;\n                                }\n                                default:\n                                    // throws\n                                    mappingKey.assertUnexpectedValue(`${DEFINITION} ${STRING} key`);\n                                    break;\n                            }\n                        }\n                        break;\n                    }\n                    default:\n                        definitionKey.assertUnexpectedValue(`${DEFINITION} key`); // throws\n                }\n            }\n        }\n    }\n    get definitionType() {\n        return DefinitionType.String;\n    }\n    isMatch(literal) {\n        if (literal.templateTokenType === TokenType.String) {\n            const value = literal.value;\n            if (this.constant) {\n                return this.ignoreCase ? this.constant.toUpperCase() === value.toUpperCase() : this.constant === value;\n            }\n            else if (this.requireNonEmpty) {\n                return !!value;\n            }\n            else {\n                return true;\n            }\n        }\n        return false;\n    }\n    validate() {\n        if (this.constant && this.requireNonEmpty) {\n            throw new Error(`Properties '${CONSTANT}' and '${REQUIRE_NON_EMPTY}' cannot both be set`);\n        }\n    }\n}\n//# sourceMappingURL=string-definition.js.map","import { TokenType } from \"../../templates/tokens/types\";\nimport { ALLOWED_VALUES, ANY, BOOLEAN, BOOLEAN_DEFINITION, BOOLEAN_DEFINITION_PROPERTIES, CONSTANT, CONTEXT, DEFINITION, DEFINITIONS, DESCRIPTION, IGNORE_CASE, IS_EXPRESSION, ITEM_TYPE, LOOSE_KEY_TYPE, LOOSE_VALUE_TYPE, MAPPING, MAPPING_DEFINITION, MAPPING_DEFINITION_PROPERTIES, MAPPING_PROPERTY_VALUE, NON_EMPTY_STRING, NULL, NULL_DEFINITION, NULL_DEFINITION_PROPERTIES, NUMBER, NUMBER_DEFINITION, NUMBER_DEFINITION_PROPERTIES, ONE_OF, ONE_OF_DEFINITION, PROPERTIES, PROPERTY_VALUE, REQUIRED, REQUIRE_NON_EMPTY, SEQUENCE, SEQUENCE_DEFINITION, SEQUENCE_DEFINITION_PROPERTIES, SEQUENCE_OF_NON_EMPTY_STRING, STRING, STRING_DEFINITION, STRING_DEFINITION_PROPERTIES, TEMPLATE_SCHEMA, TYPE, VERSION } from \"../template-constants\";\nimport { TemplateContext, TemplateValidationErrors } from \"../template-context\";\nimport { readTemplate } from \"../template-reader\";\nimport { StringToken } from \"../tokens\";\nimport { NoOperationTraceWriter } from \"../trace-writer\";\nimport { BooleanDefinition } from \"./boolean-definition\";\nimport { DefinitionType } from \"./definition-type\";\nimport { MappingDefinition } from \"./mapping-definition\";\nimport { NullDefinition } from \"./null-definition\";\nimport { NumberDefinition } from \"./number-definition\";\nimport { OneOfDefinition } from \"./one-of-definition\";\nimport { PropertyDefinition } from \"./property-definition\";\nimport { SequenceDefinition } from \"./sequence-definition\";\nimport { StringDefinition } from \"./string-definition\";\n/**\n * This models the root schema object and contains definitions\n */\nexport class TemplateSchema {\n    constructor(mapping) {\n        this.definitions = {};\n        this.version = \"\";\n        // Add built-in type: null\n        this.definitions[NULL] = new NullDefinition(NULL);\n        // Add built-in type: boolean\n        this.definitions[BOOLEAN] = new BooleanDefinition(BOOLEAN);\n        // Add built-in type: number\n        this.definitions[NUMBER] = new NumberDefinition(NUMBER);\n        // Add built-in type: string\n        this.definitions[STRING] = new StringDefinition(STRING);\n        // Add built-in type: sequence\n        const sequenceDefinition = new SequenceDefinition(SEQUENCE);\n        sequenceDefinition.itemType = ANY;\n        this.definitions[sequenceDefinition.key] = sequenceDefinition;\n        // Add built-in type: mapping\n        const mappingDefinition = new MappingDefinition(MAPPING);\n        mappingDefinition.looseKeyType = STRING;\n        mappingDefinition.looseValueType = ANY;\n        this.definitions[mappingDefinition.key] = mappingDefinition;\n        // Add built-in type: any\n        const anyDefinition = new OneOfDefinition(ANY);\n        anyDefinition.oneOf.push(NULL);\n        anyDefinition.oneOf.push(BOOLEAN);\n        anyDefinition.oneOf.push(NUMBER);\n        anyDefinition.oneOf.push(STRING);\n        anyDefinition.oneOf.push(SEQUENCE);\n        anyDefinition.oneOf.push(MAPPING);\n        this.definitions[anyDefinition.key] = anyDefinition;\n        if (mapping) {\n            for (const pair of mapping) {\n                const key = pair.key.assertString(`${TEMPLATE_SCHEMA} key`);\n                switch (key.value) {\n                    case VERSION: {\n                        this.version = pair.value.assertString(`${TEMPLATE_SCHEMA} ${VERSION}`).value;\n                        break;\n                    }\n                    case DEFINITIONS: {\n                        const definitions = pair.value.assertMapping(`${TEMPLATE_SCHEMA} ${DEFINITIONS}`);\n                        for (const definitionsPair of definitions) {\n                            const definitionsKey = definitionsPair.key.assertString(`${TEMPLATE_SCHEMA} ${DEFINITIONS} key`);\n                            const definitionsValue = definitionsPair.value.assertMapping(`${TEMPLATE_SCHEMA} ${DEFINITIONS} value`);\n                            let definition;\n                            for (const definitionPair of definitionsValue) {\n                                const definitionKey = definitionPair.key.assertString(`${DEFINITION} key`);\n                                const mappingToken = definitionsPair.value;\n                                switch (definitionKey.value) {\n                                    case NULL:\n                                        definition = new NullDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case BOOLEAN:\n                                        definition = new BooleanDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case NUMBER:\n                                        definition = new NumberDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case STRING:\n                                        definition = new StringDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case SEQUENCE:\n                                        definition = new SequenceDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case MAPPING:\n                                        definition = new MappingDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case ONE_OF:\n                                        definition = new OneOfDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case ALLOWED_VALUES:\n                                        // Change the allowed-values definition into a one-of definition and its corresponding string definitions\n                                        for (const item of mappingToken) {\n                                            if (item.value.templateTokenType === TokenType.Sequence) {\n                                                // Create a new string definition for each StringToken in the sequence\n                                                const sequenceToken = item.value;\n                                                for (const activity of sequenceToken) {\n                                                    if (activity.templateTokenType === TokenType.String) {\n                                                        const stringToken = activity;\n                                                        const allowedValuesKey = definitionsKey.value + \"-\" + stringToken.value;\n                                                        const allowedValuesDef = new StringDefinition(allowedValuesKey);\n                                                        allowedValuesDef.constant = stringToken.toDisplayString();\n                                                        this.definitions[allowedValuesKey] = allowedValuesDef;\n                                                    }\n                                                }\n                                            }\n                                        }\n                                        definition = new OneOfDefinition(definitionsKey.value, definitionsValue);\n                                        break;\n                                    case CONTEXT:\n                                    case DESCRIPTION:\n                                        continue;\n                                    default:\n                                        // throws\n                                        definitionKey.assertUnexpectedValue(`${DEFINITION} mapping key`);\n                                        break;\n                                }\n                                break;\n                            }\n                            if (!definition) {\n                                throw new Error(`Not enough information to construct definition '${definitionsKey.value}'`);\n                            }\n                            this.definitions[definitionsKey.value] = definition;\n                        }\n                        break;\n                    }\n                    default:\n                        // throws\n                        key.assertUnexpectedValue(`${TEMPLATE_SCHEMA} key`);\n                        break;\n                }\n            }\n        }\n    }\n    /**\n     * Looks up a definition by name\n     */\n    getDefinition(name) {\n        const result = this.definitions[name];\n        if (result) {\n            return result;\n        }\n        throw new Error(`Schema definition '${name}' not found`);\n    }\n    /**\n     * Expands one-of definitions and returns all scalar definitions\n     */\n    getScalarDefinitions(definition) {\n        const result = [];\n        switch (definition.definitionType) {\n            case DefinitionType.Null:\n            case DefinitionType.Boolean:\n            case DefinitionType.Number:\n            case DefinitionType.String:\n                result.push(definition);\n                break;\n            case DefinitionType.OneOf: {\n                const oneOf = definition;\n                // Expand nested one-of definitions\n                for (const nestedName of oneOf.oneOf) {\n                    const nestedDefinition = this.getDefinition(nestedName);\n                    result.push(...this.getScalarDefinitions(nestedDefinition));\n                }\n                break;\n            }\n        }\n        return result;\n    }\n    /**\n     * Expands one-of definitions and returns all matching definitions by type\n     */\n    getDefinitionsOfType(definition, type) {\n        const result = [];\n        if (definition.definitionType === type) {\n            result.push(definition);\n        }\n        else if (definition.definitionType === DefinitionType.OneOf) {\n            const oneOf = definition;\n            for (const nestedName of oneOf.oneOf) {\n                const nestedDefinition = this.getDefinition(nestedName);\n                if (nestedDefinition.definitionType === type) {\n                    result.push(nestedDefinition);\n                }\n            }\n        }\n        return result;\n    }\n    /**\n     * Attempts match the property name to a property defined by any of the specified definitions.\n     * If matched, any unmatching definitions are filtered from the definitions array.\n     * Returns the type information for the matched property.\n     */\n    matchPropertyAndFilter(definitions, propertyName) {\n        let result;\n        // Check for a matching well-known property\n        let notFoundInSome = false;\n        for (const definition of definitions) {\n            const propertyDef = definition.properties[propertyName];\n            if (propertyDef) {\n                result = propertyDef;\n            }\n            else {\n                notFoundInSome = true;\n            }\n        }\n        // Filter the matched definitions if needed\n        if (result && notFoundInSome) {\n            for (let i = 0; i < definitions.length;) {\n                if (definitions[i].properties[propertyName]) {\n                    i++;\n                }\n                else {\n                    definitions.splice(i, 1);\n                }\n            }\n        }\n        return result;\n    }\n    validate() {\n        const oneOfDefinitions = {};\n        for (const name of Object.keys(this.definitions)) {\n            if (!name.match(TemplateSchema._definitionNamePattern)) {\n                throw new Error(`Invalid definition name '${name}'`);\n            }\n            const definition = this.definitions[name];\n            // Delay validation for 'one-of' definitions\n            if (definition.definitionType === DefinitionType.OneOf) {\n                oneOfDefinitions[name] = definition;\n            }\n            // Otherwise validate now\n            else {\n                definition.validate(this, name);\n            }\n        }\n        // Validate 'one-of' definitions\n        for (const name of Object.keys(oneOfDefinitions)) {\n            const oneOf = oneOfDefinitions[name];\n            oneOf.validate(this, name);\n        }\n    }\n    /**\n     * Loads a user-defined schema file\n     */\n    static load(objectReader) {\n        const context = new TemplateContext(new TemplateValidationErrors(10, 500), TemplateSchema.getInternalSchema(), new NoOperationTraceWriter());\n        const template = readTemplate(context, TEMPLATE_SCHEMA, objectReader, undefined);\n        context.errors.check();\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const mapping = template.assertMapping(TEMPLATE_SCHEMA);\n        const schema = new TemplateSchema(mapping);\n        schema.validate();\n        return schema;\n    }\n    /**\n     * Gets the internal schema used for reading user-defined schema files\n     */\n    static getInternalSchema() {\n        if (TemplateSchema._internalSchema === undefined) {\n            const schema = new TemplateSchema();\n            // template-schema\n            let mappingDefinition = new MappingDefinition(TEMPLATE_SCHEMA);\n            mappingDefinition.properties[VERSION] = new PropertyDefinition(new StringToken(undefined, undefined, NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[DEFINITIONS] = new PropertyDefinition(new StringToken(undefined, undefined, DEFINITIONS, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // definitions\n            mappingDefinition = new MappingDefinition(DEFINITIONS);\n            mappingDefinition.looseKeyType = NON_EMPTY_STRING;\n            mappingDefinition.looseValueType = DEFINITION;\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // definition\n            let oneOfDefinition = new OneOfDefinition(DEFINITION);\n            oneOfDefinition.oneOf.push(NULL_DEFINITION);\n            oneOfDefinition.oneOf.push(BOOLEAN_DEFINITION);\n            oneOfDefinition.oneOf.push(NUMBER_DEFINITION);\n            oneOfDefinition.oneOf.push(STRING_DEFINITION);\n            oneOfDefinition.oneOf.push(SEQUENCE_DEFINITION);\n            oneOfDefinition.oneOf.push(MAPPING_DEFINITION);\n            oneOfDefinition.oneOf.push(ONE_OF_DEFINITION);\n            schema.definitions[oneOfDefinition.key] = oneOfDefinition;\n            // null-definition\n            mappingDefinition = new MappingDefinition(NULL_DEFINITION);\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            mappingDefinition.properties[CONTEXT] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[NULL] = new PropertyDefinition(new StringToken(undefined, undefined, NULL_DEFINITION_PROPERTIES, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // null-definition-properties\n            mappingDefinition = new MappingDefinition(NULL_DEFINITION_PROPERTIES);\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // boolean-definition\n            mappingDefinition = new MappingDefinition(BOOLEAN_DEFINITION);\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            mappingDefinition.properties[CONTEXT] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[BOOLEAN] = new PropertyDefinition(new StringToken(undefined, undefined, BOOLEAN_DEFINITION_PROPERTIES, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // boolean-definition-properties\n            mappingDefinition = new MappingDefinition(BOOLEAN_DEFINITION_PROPERTIES);\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // number-definition\n            mappingDefinition = new MappingDefinition(NUMBER_DEFINITION);\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            mappingDefinition.properties[CONTEXT] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[NUMBER] = new PropertyDefinition(new StringToken(undefined, undefined, NUMBER_DEFINITION_PROPERTIES, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // number-definition-properties\n            mappingDefinition = new MappingDefinition(NUMBER_DEFINITION_PROPERTIES);\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // string-definition\n            mappingDefinition = new MappingDefinition(STRING_DEFINITION);\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            mappingDefinition.properties[CONTEXT] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[STRING] = new PropertyDefinition(new StringToken(undefined, undefined, STRING_DEFINITION_PROPERTIES, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // string-definition-properties\n            mappingDefinition = new MappingDefinition(STRING_DEFINITION_PROPERTIES);\n            mappingDefinition.properties[CONSTANT] = new PropertyDefinition(new StringToken(undefined, undefined, NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[IGNORE_CASE] = new PropertyDefinition(new StringToken(undefined, undefined, BOOLEAN, undefined));\n            mappingDefinition.properties[REQUIRE_NON_EMPTY] = new PropertyDefinition(new StringToken(undefined, undefined, BOOLEAN, undefined));\n            mappingDefinition.properties[IS_EXPRESSION] = new PropertyDefinition(new StringToken(undefined, undefined, BOOLEAN, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // sequence-definition\n            mappingDefinition = new MappingDefinition(SEQUENCE_DEFINITION);\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            mappingDefinition.properties[CONTEXT] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[SEQUENCE] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_DEFINITION_PROPERTIES, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // sequence-definition-properties\n            mappingDefinition = new MappingDefinition(SEQUENCE_DEFINITION_PROPERTIES);\n            mappingDefinition.properties[ITEM_TYPE] = new PropertyDefinition(new StringToken(undefined, undefined, NON_EMPTY_STRING, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // mapping-definition\n            mappingDefinition = new MappingDefinition(MAPPING_DEFINITION);\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            mappingDefinition.properties[CONTEXT] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[MAPPING] = new PropertyDefinition(new StringToken(undefined, undefined, MAPPING_DEFINITION_PROPERTIES, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // mapping-definition-properties\n            mappingDefinition = new MappingDefinition(MAPPING_DEFINITION_PROPERTIES);\n            mappingDefinition.properties[PROPERTIES] = new PropertyDefinition(new StringToken(undefined, undefined, PROPERTIES, undefined));\n            mappingDefinition.properties[LOOSE_KEY_TYPE] = new PropertyDefinition(new StringToken(undefined, undefined, NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[LOOSE_VALUE_TYPE] = new PropertyDefinition(new StringToken(undefined, undefined, NON_EMPTY_STRING, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // properties\n            mappingDefinition = new MappingDefinition(PROPERTIES);\n            mappingDefinition.looseKeyType = NON_EMPTY_STRING;\n            mappingDefinition.looseValueType = PROPERTY_VALUE;\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // property-value\n            oneOfDefinition = new OneOfDefinition(PROPERTY_VALUE);\n            oneOfDefinition.oneOf.push(NON_EMPTY_STRING);\n            oneOfDefinition.oneOf.push(MAPPING_PROPERTY_VALUE);\n            schema.definitions[oneOfDefinition.key] = oneOfDefinition;\n            // mapping-property-value\n            mappingDefinition = new MappingDefinition(MAPPING_PROPERTY_VALUE);\n            mappingDefinition.properties[TYPE] = new PropertyDefinition(new StringToken(undefined, undefined, NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[REQUIRED] = new PropertyDefinition(new StringToken(undefined, undefined, BOOLEAN, undefined));\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // one-of-definition\n            mappingDefinition = new MappingDefinition(ONE_OF_DEFINITION);\n            mappingDefinition.properties[DESCRIPTION] = new PropertyDefinition(new StringToken(undefined, undefined, STRING, undefined));\n            mappingDefinition.properties[CONTEXT] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[ONE_OF] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            mappingDefinition.properties[ALLOWED_VALUES] = new PropertyDefinition(new StringToken(undefined, undefined, SEQUENCE_OF_NON_EMPTY_STRING, undefined));\n            schema.definitions[mappingDefinition.key] = mappingDefinition;\n            // non-empty-string\n            const stringDefinition = new StringDefinition(NON_EMPTY_STRING);\n            stringDefinition.requireNonEmpty = true;\n            schema.definitions[stringDefinition.key] = stringDefinition;\n            // sequence-of-non-empty-string\n            const sequenceDefinition = new SequenceDefinition(SEQUENCE_OF_NON_EMPTY_STRING);\n            sequenceDefinition.itemType = NON_EMPTY_STRING;\n            schema.definitions[sequenceDefinition.key] = sequenceDefinition;\n            schema.validate();\n            TemplateSchema._internalSchema = schema;\n        }\n        return TemplateSchema._internalSchema;\n    }\n}\nTemplateSchema._definitionNamePattern = /^[a-zA-Z_][a-zA-Z0-9_-]*$/;\n//# sourceMappingURL=template-schema.js.map","export const ALLOWED_VALUES = \"allowed-values\";\nexport const ANY = \"any\";\nexport const BOOLEAN = \"boolean\";\nexport const BOOLEAN_DEFINITION = \"boolean-definition\";\nexport const BOOLEAN_DEFINITION_PROPERTIES = \"boolean-definition-properties\";\nexport const CLOSE_EXPRESSION = \"}}\";\nexport const CONSTANT = \"constant\";\nexport const CONTEXT = \"context\";\nexport const DEFINITION = \"definition\";\nexport const DEFINITIONS = \"definitions\";\nexport const DESCRIPTION = \"description\";\nexport const IGNORE_CASE = \"ignore-case\";\nexport const INSERT_DIRECTIVE = \"insert\";\nexport const IS_EXPRESSION = \"is-expression\";\nexport const ITEM_TYPE = \"item-type\";\nexport const LOOSE_KEY_TYPE = \"loose-key-type\";\nexport const LOOSE_VALUE_TYPE = \"loose-value-type\";\nexport const MAX_CONSTANT = \"MAX\";\nexport const MAPPING = \"mapping\";\nexport const MAPPING_DEFINITION = \"mapping-definition\";\nexport const MAPPING_DEFINITION_PROPERTIES = \"mapping-definition-properties\";\nexport const MAPPING_PROPERTY_VALUE = \"mapping-property-value\";\nexport const NON_EMPTY_STRING = \"non-empty-string\";\nexport const NULL = \"null\";\nexport const NULL_DEFINITION = \"null-definition\";\nexport const NULL_DEFINITION_PROPERTIES = \"null-definition-properties\";\nexport const NUMBER = \"number\";\nexport const NUMBER_DEFINITION = \"number-definition\";\nexport const NUMBER_DEFINITION_PROPERTIES = \"number-definition-properties\";\nexport const ONE_OF = \"one-of\";\nexport const ONE_OF_DEFINITION = \"one-of-definition\";\nexport const OPEN_EXPRESSION = \"${{\";\nexport const PROPERTY_VALUE = \"property-value\";\nexport const PROPERTIES = \"properties\";\nexport const REQUIRED = \"required\";\nexport const REQUIRE_NON_EMPTY = \"require-non-empty\";\nexport const SCALAR = \"scalar\";\nexport const SEQUENCE = \"sequence\";\nexport const SEQUENCE_DEFINITION = \"sequence-definition\";\nexport const SEQUENCE_DEFINITION_PROPERTIES = \"sequence-definition-properties\";\nexport const TYPE = \"type\";\nexport const SEQUENCE_OF_NON_EMPTY_STRING = \"sequence-of-non-empty-string\";\nexport const STRING = \"string\";\nexport const STRING_DEFINITION = \"string-definition\";\nexport const STRING_DEFINITION_PROPERTIES = \"string-definition-properties\";\nexport const STRUCTURE = \"structure\";\nexport const TEMPLATE_SCHEMA = \"template-schema\";\nexport const VERSION = \"version\";\n//# sourceMappingURL=template-constants.js.map","import { TemplateValidationError } from \"./template-validation-error\";\n/**\n * Context object that is flowed through while loading and evaluating object templates\n */\nexport class TemplateContext {\n    constructor(errors, schema, trace) {\n        this._fileIds = {};\n        this._fileNames = [];\n        /**\n         * Available functions within expression contexts\n         */\n        this.expressionFunctions = [];\n        /**\n         * Available values within expression contexts\n         */\n        this.expressionNamedContexts = [];\n        this.state = {};\n        this.errors = errors;\n        this.schema = schema;\n        this.trace = trace;\n    }\n    error(tokenOrFileId, err, tokenRange) {\n        const token = tokenOrFileId;\n        const range = tokenRange || token?.range;\n        const prefix = this.getErrorPrefix(token?.file ?? tokenOrFileId, token?.line, token?.col);\n        const message = err?.message ?? String(err);\n        const e = new TemplateValidationError(message, prefix, undefined, range);\n        this.errors.add(e);\n        this.trace.error(e.message);\n    }\n    /**\n     * Gets or adds the file ID\n     */\n    getFileId(file) {\n        const key = file.toUpperCase();\n        let id = this._fileIds[key];\n        if (id === undefined) {\n            id = this._fileNames.length + 1;\n            this._fileIds[key] = id;\n            this._fileNames.push(file);\n        }\n        return id;\n    }\n    /**\n     * Looks up a file name by ID. Returns undefined if not found.\n     */\n    getFileName(fileId) {\n        return this._fileNames.length >= fileId ? this._fileNames[fileId - 1] : undefined;\n    }\n    /**\n     * Gets a copy of the file table\n     */\n    getFileTable() {\n        return this._fileNames.slice();\n    }\n    getErrorPrefix(fileId, line, column) {\n        const fileName = fileId !== undefined ? this.getFileName(fileId) : undefined;\n        if (fileName) {\n            if (line !== undefined && column !== undefined) {\n                return `${fileName} (Line: ${line}, Col: ${column})`;\n            }\n            else {\n                return fileName;\n            }\n        }\n        else if (line !== undefined && column !== undefined) {\n            return `(Line: ${line}, Col: ${column})`;\n        }\n        else {\n            return \"\";\n        }\n    }\n}\n/**\n * Provides information about errors which occurred during validation\n */\nexport class TemplateValidationErrors {\n    constructor(maxErrors, maxMessageLength) {\n        this._errors = [];\n        this._maxErrors = maxErrors ?? 0;\n        this._maxMessageLength = maxMessageLength ?? 0;\n    }\n    get count() {\n        return this._errors.length;\n    }\n    add(err) {\n        for (let e of Array.isArray(err) ? err : [err]) {\n            // Check max errors\n            if (this._maxErrors <= 0 || this._errors.length < this._maxErrors) {\n                // Check max message length\n                if (this._maxMessageLength > 0 && e.message.length > this._maxMessageLength) {\n                    e = new TemplateValidationError(e.message.substring(0, this._maxMessageLength) + \"[...]\", e.prefix, e.code, e.range);\n                }\n                this._errors.push(e);\n            }\n        }\n    }\n    /**\n     * Throws if any errors\n     * @param prefix The error message prefix\n     */\n    check(prefix) {\n        if (this._errors.length <= 0) {\n            return;\n        }\n        if (!prefix) {\n            prefix = \"The template is not valid.\";\n        }\n        throw new Error(`${prefix} ${this._errors.map(x => x.message).join(\",\")}`);\n    }\n    clear() {\n        this._errors = [];\n    }\n    getErrors() {\n        return this._errors.slice();\n    }\n}\n//# sourceMappingURL=template-context.js.map","// template-reader *just* does schema validation\n/* eslint-disable @typescript-eslint/no-non-null-assertion */\nimport { DefinitionInfo } from \"./schema/definition-info\";\nimport { DefinitionType } from \"./schema/definition-type\";\nimport { StringDefinition } from \"./schema/string-definition\";\nimport { ANY, CLOSE_EXPRESSION, INSERT_DIRECTIVE, OPEN_EXPRESSION } from \"./template-constants\";\nimport { BasicExpressionToken, ExpressionToken, InsertExpressionToken, StringToken } from \"./tokens\";\nimport { isString } from \"./tokens/type-guards\";\nimport { TokenType } from \"./tokens/types\";\nconst WHITESPACE_PATTERN = /\\s/;\nexport function readTemplate(context, type, objectReader, fileId) {\n    const reader = new TemplateReader(context, objectReader, fileId);\n    let value;\n    try {\n        objectReader.validateStart();\n        const definition = new DefinitionInfo(context.schema, type);\n        value = reader.readValue(definition);\n        objectReader.validateEnd();\n    }\n    catch (err) {\n        context.error(fileId, err);\n    }\n    return value;\n}\nclass TemplateReader {\n    constructor(context, objectReader, fileId) {\n        this._context = context;\n        this._schema = context.schema;\n        this._objectReader = objectReader;\n        this._fileId = fileId;\n    }\n    readValue(definition) {\n        // Scalar\n        const literal = this._objectReader.allowLiteral();\n        if (literal) {\n            let scalar = this.parseScalar(literal, definition);\n            scalar = this.validate(scalar, definition);\n            return scalar;\n        }\n        // Sequence\n        const sequence = this._objectReader.allowSequenceStart();\n        if (sequence) {\n            const sequenceDefinition = definition.getDefinitionsOfType(DefinitionType.Sequence)[0];\n            // Legal\n            if (sequenceDefinition) {\n                const itemDefinition = new DefinitionInfo(definition, sequenceDefinition.itemType);\n                // Add each item\n                while (!this._objectReader.allowSequenceEnd()) {\n                    const item = this.readValue(itemDefinition);\n                    sequence.add(item);\n                }\n            }\n            // Illegal\n            else {\n                // Error\n                this._context.error(sequence, \"A sequence was not expected\");\n                // Skip each item\n                while (!this._objectReader.allowSequenceEnd()) {\n                    this.skipValue();\n                }\n            }\n            sequence.definitionInfo = definition;\n            return sequence;\n        }\n        // Mapping\n        const mapping = this._objectReader.allowMappingStart();\n        if (mapping) {\n            const mappingDefinitions = definition.getDefinitionsOfType(DefinitionType.Mapping);\n            // Legal\n            if (mappingDefinitions.length > 0) {\n                if (mappingDefinitions.length > 1 ||\n                    Object.keys(mappingDefinitions[0].properties).length > 0 ||\n                    !mappingDefinitions[0].looseKeyType) {\n                    this.handleMappingWithWellKnownProperties(definition, mappingDefinitions, mapping);\n                }\n                else {\n                    const keyDefinition = new DefinitionInfo(definition, mappingDefinitions[0].looseKeyType);\n                    const valueDefinition = new DefinitionInfo(definition, mappingDefinitions[0].looseValueType);\n                    this.handleMappingWithAllLooseProperties(definition, keyDefinition, valueDefinition, mappingDefinitions[0], mapping);\n                }\n            }\n            // Illegal\n            else {\n                this._context.error(mapping, \"A mapping was not expected\");\n                while (!this._objectReader.allowMappingEnd()) {\n                    this.skipValue();\n                    this.skipValue();\n                }\n            }\n            // handleMappingWithWellKnownProperties will only set a definition\n            // if it can identify a single matching definition\n            if (!mapping.definitionInfo) {\n                mapping.definitionInfo = definition;\n            }\n            return mapping;\n        }\n        throw new Error(\"Expected a scalar value, a sequence, or a mapping\");\n    }\n    handleMappingWithWellKnownProperties(definition, mappingDefinitions, mapping) {\n        // Check if loose properties are allowed\n        let looseKeyType;\n        let looseValueType;\n        let looseKeyDefinition;\n        let looseValueDefinition;\n        if (mappingDefinitions[0].looseKeyType) {\n            looseKeyType = mappingDefinitions[0].looseKeyType;\n            looseValueType = mappingDefinitions[0].looseValueType;\n        }\n        const upperKeys = {};\n        let hasExpressionKey = false;\n        let rawLiteral;\n        while ((rawLiteral = this._objectReader.allowLiteral())) {\n            const nextKeyScalar = this.parseScalar(rawLiteral, definition);\n            // Expression\n            if (nextKeyScalar.isExpression) {\n                hasExpressionKey = true;\n                // Legal\n                if (definition.allowedContext.length > 0) {\n                    const anyDefinition = new DefinitionInfo(definition, ANY);\n                    mapping.add(nextKeyScalar, this.readValue(anyDefinition));\n                }\n                // Illegal\n                else {\n                    this._context.error(nextKeyScalar, \"A template expression is not allowed in this context\");\n                    this.skipValue();\n                }\n                continue;\n            }\n            // Convert to StringToken if required\n            const nextKey = nextKeyScalar.templateTokenType === TokenType.String\n                ? nextKeyScalar\n                : new StringToken(nextKeyScalar.file, nextKeyScalar.range, nextKeyScalar.toString(), nextKeyScalar.definitionInfo);\n            // Duplicate\n            if (nextKey.value) {\n                const upperKey = nextKey.value.toUpperCase();\n                if (upperKeys[upperKey]) {\n                    this._context.error(nextKey, `'${nextKey.value}' is already defined`);\n                    this.skipValue();\n                    continue;\n                }\n                upperKeys[upperKey] = true;\n            }\n            // Well known\n            const nextPropertyDef = this._schema.matchPropertyAndFilter(mappingDefinitions, nextKey.value);\n            if (nextPropertyDef) {\n                const nextDefinition = new DefinitionInfo(definition, nextPropertyDef.type);\n                // Store the definition on the key, the value may have its own definition\n                nextKey.definitionInfo = nextDefinition;\n                // If the property has a description, it's a parameter that uses a shared type\n                // and we need to make sure its description is set if there is one\n                if (nextPropertyDef.description) {\n                    nextKey.description = nextPropertyDef.description;\n                }\n                const nextValue = this.readValue(nextDefinition);\n                mapping.add(nextKey, nextValue);\n                continue;\n            }\n            // Loose\n            if (looseKeyType) {\n                if (!looseKeyDefinition) {\n                    looseKeyDefinition = new DefinitionInfo(definition, looseKeyType);\n                    looseValueDefinition = new DefinitionInfo(definition, looseValueType);\n                }\n                this.validate(nextKey, looseKeyDefinition);\n                // Store the definition on the key, the value may have its own definition\n                const nextDefinition = new DefinitionInfo(definition, mappingDefinitions[0].looseValueType);\n                nextKey.definitionInfo = nextDefinition;\n                const nextValue = this.readValue(looseValueDefinition);\n                mapping.add(nextKey, nextValue);\n                continue;\n            }\n            // Error\n            this._context.error(nextKey, `Unexpected value '${nextKey.value}'`);\n            this.skipValue();\n        }\n        // If we matched a single definition from multiple,\n        // update the token's definition to enable more specific editor\n        // completion and validation\n        if (mappingDefinitions.length === 1) {\n            mapping.definitionInfo = new DefinitionInfo(definition, mappingDefinitions[0]);\n        }\n        // Unable to filter to one definition\n        if (mappingDefinitions.length > 1) {\n            const hitCount = {};\n            for (const mappingDefinition of mappingDefinitions) {\n                for (const key of Object.keys(mappingDefinition.properties)) {\n                    hitCount[key] = (hitCount[key] ?? 0) + 1;\n                }\n            }\n            const nonDuplicates = [];\n            for (const key of Object.keys(hitCount)) {\n                if (hitCount[key] === 1) {\n                    nonDuplicates.push(key);\n                }\n            }\n            this._context.error(mapping, `There's not enough info to determine what you meant. Add one of these properties: ${nonDuplicates\n                .sort()\n                .join(\", \")}`);\n        }\n        // Check required properties\n        else if (mappingDefinitions.length === 1 && !hasExpressionKey) {\n            for (const propertyName of Object.keys(mappingDefinitions[0].properties)) {\n                const propertyDef = mappingDefinitions[0].properties[propertyName];\n                if (propertyDef.required && !upperKeys[propertyName.toUpperCase()]) {\n                    this._context.error(mapping, `Required property is missing: ${propertyName}`);\n                }\n            }\n        }\n        this.expectMappingEnd();\n    }\n    handleMappingWithAllLooseProperties(definition, keyDefinition, valueDefinition, mappingDefinition, mapping) {\n        let nextValue;\n        const upperKeys = {};\n        let rawLiteral;\n        while ((rawLiteral = this._objectReader.allowLiteral())) {\n            const nextKeyScalar = this.parseScalar(rawLiteral, definition);\n            nextKeyScalar.definitionInfo = keyDefinition;\n            // Expression\n            if (nextKeyScalar.isExpression) {\n                // Legal\n                if (definition.allowedContext.length > 0) {\n                    nextValue = this.readValue(valueDefinition);\n                    mapping.add(nextKeyScalar, nextValue);\n                }\n                // Illegal\n                else {\n                    this._context.error(nextKeyScalar, \"A template expression is not allowed in this context\");\n                    this.skipValue();\n                }\n                continue;\n            }\n            // Convert to StringToken if required\n            const nextKey = nextKeyScalar.templateTokenType === TokenType.String\n                ? nextKeyScalar\n                : new StringToken(nextKeyScalar.file, nextKeyScalar.range, nextKeyScalar.toString(), nextKeyScalar.definitionInfo);\n            // Duplicate\n            if (nextKey.value) {\n                const upperKey = nextKey.value.toUpperCase();\n                if (upperKeys[upperKey]) {\n                    this._context.error(nextKey, `'${nextKey.value}' is already defined`);\n                    this.skipValue();\n                    continue;\n                }\n                upperKeys[upperKey] = true;\n            }\n            // Validate\n            this.validate(nextKey, keyDefinition);\n            // Store the definition on the key, the value may have its own definition\n            const nextDefinition = new DefinitionInfo(definition, mappingDefinition.looseValueType);\n            nextKey.definitionInfo = nextDefinition;\n            // Add the pair\n            nextValue = this.readValue(valueDefinition);\n            mapping.add(nextKey, nextValue);\n        }\n        this.expectMappingEnd();\n    }\n    expectMappingEnd() {\n        if (!this._objectReader.allowMappingEnd()) {\n            throw new Error(\"Expected mapping end\"); // Should never happen\n        }\n    }\n    skipValue() {\n        // Scalar\n        if (this._objectReader.allowLiteral()) {\n            // Intentionally empty\n        }\n        // Sequence\n        else if (this._objectReader.allowSequenceStart()) {\n            while (!this._objectReader.allowSequenceEnd()) {\n                this.skipValue();\n            }\n        }\n        // Mapping\n        else if (this._objectReader.allowMappingStart()) {\n            while (!this._objectReader.allowMappingEnd()) {\n                this.skipValue();\n                this.skipValue();\n            }\n        }\n        // Unexpected\n        else {\n            throw new Error(\"Expected a scalar value, a sequence, or a mapping\");\n        }\n    }\n    validate(scalar, definition) {\n        switch (scalar.templateTokenType) {\n            case TokenType.Null:\n            case TokenType.Boolean:\n            case TokenType.Number:\n            case TokenType.String: {\n                const literal = scalar;\n                // Legal\n                const scalarDefinitions = definition.getScalarDefinitions();\n                let relevantDefinition;\n                if ((relevantDefinition = scalarDefinitions.find(x => x.isMatch(literal)))) {\n                    scalar.definitionInfo = new DefinitionInfo(definition, relevantDefinition);\n                    return scalar;\n                }\n                // Not a string, convert\n                if (literal.templateTokenType !== TokenType.String) {\n                    const stringLiteral = new StringToken(literal.file, literal.range, literal.toString(), literal.definitionInfo);\n                    // Legal\n                    if ((relevantDefinition = scalarDefinitions.find(x => x.isMatch(stringLiteral)))) {\n                        stringLiteral.definitionInfo = new DefinitionInfo(definition, relevantDefinition);\n                        return stringLiteral;\n                    }\n                }\n                // Illegal\n                this._context.error(literal, `Unexpected value '${literal.toString()}'`);\n                return scalar;\n            }\n            case TokenType.BasicExpression:\n                // Illegal\n                if (definition.allowedContext.length === 0) {\n                    this._context.error(scalar, \"A template expression is not allowed in this context\");\n                }\n                return scalar;\n            default:\n                this._context.error(scalar, `Unexpected value '${scalar.toString()}'`);\n                return scalar;\n        }\n    }\n    parseScalar(token, definitionInfo) {\n        // Not a string\n        if (!isString(token) || !token.value) {\n            return token;\n        }\n        const allowedContext = definitionInfo.allowedContext;\n        const raw = token.source || token.value;\n        let startExpression = raw.indexOf(OPEN_EXPRESSION);\n        if (startExpression < 0) {\n            // Doesn't contain \"${{\"\n            // Check if value should still be evaluated as an expression\n            if (definitionInfo.definition instanceof StringDefinition && definitionInfo.definition.isExpression) {\n                const expression = this.parseIntoExpressionToken(token.range, raw, allowedContext, token, definitionInfo);\n                if (expression) {\n                    return expression;\n                }\n            }\n            return token;\n        }\n        // Break the value into segments of LiteralToken and ExpressionToken\n        let encounteredError = false;\n        const segments = [];\n        let i = 0;\n        while (i < raw.length) {\n            // An expression starts here\n            if (i === startExpression) {\n                // Find the end of the expression - i.e. \"}}\"\n                startExpression = i;\n                let endExpression = -1;\n                let inString = false;\n                for (i += OPEN_EXPRESSION.length; i < raw.length; i++) {\n                    if (raw[i] === \"'\") {\n                        inString = !inString; // Note, this handles escaped single quotes gracefully. E.x. 'foo''bar'\n                    }\n                    else if (!inString && raw[i] === \"}\" && raw[i - 1] === \"}\") {\n                        endExpression = i;\n                        i++;\n                        break;\n                    }\n                }\n                // Check if not closed\n                if (endExpression < startExpression) {\n                    this._context.error(token, \"The expression is not closed. An unescaped ${{ sequence was found, but the closing }} sequence was not found.\");\n                    return token;\n                }\n                // Parse the expression\n                const rawExpression = raw.substr(startExpression + OPEN_EXPRESSION.length, endExpression - startExpression + 1 - OPEN_EXPRESSION.length - CLOSE_EXPRESSION.length);\n                let tr = token.range;\n                if (tr.start.line === tr.end.line) {\n                    // If it's a single line expression, adjust the range to only cover the sub-expression\n                    tr = {\n                        start: { line: tr.start.line, column: tr.start.column + startExpression },\n                        end: { line: tr.end.line, column: tr.start.column + endExpression + 1 }\n                    };\n                }\n                else {\n                    // Adjust the range to only cover the expression for multi-line strings\n                    const startRaw = raw.substring(0, startExpression);\n                    const adjustedStartLine = startRaw.split(\"\\n\").length;\n                    const beginningOfLine = startRaw.lastIndexOf(\"\\n\");\n                    const adjustedStart = startExpression - beginningOfLine;\n                    const adjustedEnd = endExpression - beginningOfLine + 1;\n                    tr = {\n                        start: { line: tr.start.line + adjustedStartLine, column: adjustedStart },\n                        end: { line: tr.start.line + adjustedStartLine, column: adjustedEnd }\n                    };\n                }\n                const expression = this.parseIntoExpressionToken(tr, rawExpression, allowedContext, token, definitionInfo);\n                if (!expression) {\n                    // Record that we've hit an error but continue to validate any other expressions\n                    // that might be in the string\n                    encounteredError = true;\n                }\n                else {\n                    // Check if a directive was used when not allowed\n                    if (expression.directive && (startExpression !== 0 || i < raw.length)) {\n                        this._context.error(token, `The directive '${expression.directive}' is not allowed in this context. Directives are not supported for expressions that are embedded within a string. Directives are only supported when the entire value is an expression.`);\n                        return token;\n                    }\n                    // Add the segment\n                    segments.push(expression);\n                }\n                // Look for the next expression\n                startExpression = raw.indexOf(OPEN_EXPRESSION, i);\n            }\n            // The next expression is further ahead\n            else if (i < startExpression) {\n                // Append the segment\n                this.addString(segments, token.range, raw.substr(i, startExpression - i), token.definitionInfo);\n                // Adjust the position\n                i = startExpression;\n            }\n            // No remaining expressions\n            else {\n                this.addString(segments, token.range, raw.substr(i), token.definitionInfo);\n                break;\n            }\n        }\n        // If we've hit any error during parsing, return the original token\n        if (encounteredError) {\n            return token;\n        }\n        // Check if can convert to a literal\n        // For example, the escaped expression: ${{ '{{ this is a literal }}' }}\n        if (segments.length === 1 && segments[0].templateTokenType === TokenType.BasicExpression) {\n            const basicExpression = segments[0];\n            const str = this.getExpressionString(basicExpression.expression);\n            if (str !== undefined) {\n                return new StringToken(this._fileId, token.range, str, token.definitionInfo);\n            }\n        }\n        // Check if only one segment\n        if (segments.length === 1) {\n            return segments[0];\n        }\n        // Build the new expression, using the format function\n        const format = [];\n        const args = [];\n        const expressionTokens = [];\n        let argIndex = 0;\n        for (const segment of segments) {\n            if (isString(segment)) {\n                const text = segment.value\n                    .replace(/'/g, \"''\") // Escape quotes\n                    .replace(/\\{/g, \"{{\") // Escape braces\n                    .replace(/\\}/g, \"}}\");\n                format.push(text);\n            }\n            else {\n                format.push(`{${argIndex}}`); // Append format arg\n                argIndex++;\n                const expression = segment;\n                args.push(\", \");\n                args.push(expression.expression);\n                expressionTokens.push(expression);\n            }\n        }\n        return new BasicExpressionToken(this._fileId, token.range, `format('${format.join(\"\")}'${args.join(\"\")})`, definitionInfo, expressionTokens, raw);\n    }\n    parseIntoExpressionToken(tr, rawExpression, allowedContext, token, definitionInfo) {\n        const parseExpressionResult = this.parseExpression(tr, token, rawExpression, allowedContext, definitionInfo);\n        // Check for error\n        if (parseExpressionResult.error) {\n            this._context.error(token, parseExpressionResult.error, tr);\n            return undefined;\n        }\n        return parseExpressionResult.expression;\n    }\n    parseExpression(range, token, value, allowedContext, definitionInfo) {\n        const trimmed = value.trim();\n        // Check if the value is empty\n        if (!trimmed) {\n            return {\n                error: new Error(\"An expression was expected\")\n            };\n        }\n        // Try to find a matching directive\n        const matchDirectiveResult = this.matchDirective(trimmed, INSERT_DIRECTIVE, 0);\n        if (matchDirectiveResult.isMatch) {\n            return {\n                expression: new InsertExpressionToken(this._fileId, range, definitionInfo)\n            };\n        }\n        else if (matchDirectiveResult.error) {\n            return {\n                error: matchDirectiveResult.error\n            };\n        }\n        // Check if valid expression\n        try {\n            ExpressionToken.validateExpression(trimmed, allowedContext);\n        }\n        catch (err) {\n            return {\n                error: err\n            };\n        }\n        const startTrim = value.length - value.trimStart().length;\n        const endTrim = value.length - value.trimEnd().length;\n        const expressionRange = {\n            start: {\n                ...range.start,\n                column: range.start.column + OPEN_EXPRESSION.length + startTrim\n            },\n            end: {\n                ...range.end,\n                column: range.end.column - CLOSE_EXPRESSION.length - endTrim\n            }\n        };\n        // Return the expression\n        return {\n            expression: new BasicExpressionToken(this._fileId, range, trimmed, definitionInfo, undefined, token.source, expressionRange),\n            error: undefined\n        };\n    }\n    addString(segments, range, value, definition) {\n        // If the last segment was a LiteralToken, then append to the last segment\n        if (segments.length > 0 && segments[segments.length - 1].templateTokenType === TokenType.String) {\n            const lastSegment = segments[segments.length - 1];\n            segments[segments.length - 1] = new StringToken(this._fileId, range, `${lastSegment.value}${value}`, definition);\n        }\n        // Otherwise add a new LiteralToken\n        else {\n            segments.push(new StringToken(this._fileId, range, value, definition));\n        }\n    }\n    matchDirective(trimmed, directive, expectedParameters) {\n        const parameters = [];\n        if (trimmed.startsWith(directive) &&\n            (trimmed.length === directive.length || WHITESPACE_PATTERN.test(trimmed[directive.length]))) {\n            let startIndex = directive.length;\n            let inString = false;\n            let parens = 0;\n            for (let i = startIndex; i < trimmed.length; i++) {\n                const c = trimmed[i];\n                if (WHITESPACE_PATTERN.test(c) && !inString && parens == 0) {\n                    if (startIndex < 1) {\n                        parameters.push(trimmed.substr(startIndex, i - startIndex));\n                    }\n                    startIndex = i + 1;\n                }\n                else if (c === \"'\") {\n                    inString = !inString;\n                }\n                else if (c === \"(\" && !inString) {\n                    parens++;\n                }\n                else if (c === \")\" && !inString) {\n                    parens--;\n                }\n            }\n            if (startIndex < trimmed.length) {\n                parameters.push(trimmed.substr(startIndex));\n            }\n            if (expectedParameters != parameters.length) {\n                return {\n                    isMatch: false,\n                    parameters: [],\n                    error: new Error(`Exactly ${expectedParameters} parameter(s) were expected following the directive '${directive}'. Actual parameter count: ${parameters.length}`)\n                };\n            }\n            return {\n                isMatch: true,\n                parameters: parameters\n            };\n        }\n        return {\n            isMatch: false,\n            parameters: parameters\n        };\n    }\n    getExpressionString(trimmed) {\n        const result = [];\n        let inString = false;\n        for (let i = 0; i < trimmed.length; i++) {\n            const c = trimmed[i];\n            if (c === \"'\") {\n                inString = !inString;\n                if (inString && i !== 0) {\n                    result.push(c);\n                }\n            }\n            else if (!inString) {\n                return undefined;\n            }\n            else {\n                result.push(c);\n            }\n        }\n        return result.join(\"\");\n    }\n}\n//# sourceMappingURL=template-reader.js.map","/**\n * Provides information about an error which occurred during validation\n */\nexport class TemplateValidationError {\n    constructor(rawMessage, prefix, code, range) {\n        this.rawMessage = rawMessage;\n        this.prefix = prefix;\n        this.code = code;\n        this.range = range;\n    }\n    get message() {\n        if (this.prefix) {\n            return `${this.prefix}: ${this.rawMessage}`;\n        }\n        return this.rawMessage;\n    }\n    toString() {\n        return this.message;\n    }\n}\n//# sourceMappingURL=template-validation-error.js.map","import { CLOSE_EXPRESSION, OPEN_EXPRESSION } from \"../template-constants\";\nimport { ExpressionToken } from \"./expression-token\";\nimport { ScalarToken } from \"./scalar-token\";\nimport { TokenType } from \"./types\";\nexport class BasicExpressionToken extends ExpressionToken {\n    /**\n     * @param originalExpressions If the basic expression was transformed from individual expressions, these will be the original ones\n     */\n    constructor(file, range, expression, definitionInfo, originalExpressions, source, expressionRange) {\n        super(TokenType.BasicExpression, file, range, undefined, definitionInfo);\n        this.expr = expression;\n        this.source = source;\n        this.originalExpressions = originalExpressions;\n        this.expressionRange = expressionRange;\n    }\n    get expression() {\n        return this.expr;\n    }\n    clone(omitSource) {\n        return omitSource\n            ? new BasicExpressionToken(undefined, undefined, this.expr, this.definitionInfo, this.originalExpressions, this.source, this.expressionRange)\n            : new BasicExpressionToken(this.file, this.range, this.expr, this.definitionInfo, this.originalExpressions, this.source, this.expressionRange);\n    }\n    toString() {\n        return `${OPEN_EXPRESSION} ${this.expr} ${CLOSE_EXPRESSION}`;\n    }\n    toDisplayString() {\n        // TODO: Implement expression display string to match `BasicExpressionToken#ToDisplayString()` in the C# parser\n        return ScalarToken.trimDisplayString(this.toString());\n    }\n    toJSON() {\n        return {\n            type: TokenType.BasicExpression,\n            expr: this.expr\n        };\n    }\n}\n//# sourceMappingURL=basic-expression-token.js.map","import { LiteralToken } from \".\";\nimport { TokenType } from \"./types\";\nexport class BooleanToken extends LiteralToken {\n    constructor(file, range, value, definitionInfo) {\n        super(TokenType.Boolean, file, range, definitionInfo);\n        this.bool = value;\n    }\n    get value() {\n        return this.bool;\n    }\n    clone(omitSource) {\n        return omitSource\n            ? new BooleanToken(undefined, undefined, this.bool, this.definitionInfo)\n            : new BooleanToken(this.file, this.range, this.bool, this.definitionInfo);\n    }\n    toString() {\n        return this.bool ? \"true\" : \"false\";\n    }\n    toJSON() {\n        return this.bool;\n    }\n}\n//# sourceMappingURL=boolean-token.js.map","import { Lexer, Parser } from \"@actions/expressions\";\nimport { splitAllowedContext } from \"../allowed-context\";\nimport { ScalarToken } from \"./scalar-token\";\nexport class ExpressionToken extends ScalarToken {\n    constructor(type, file, range, directive, definitionInfo) {\n        super(type, file, range, definitionInfo);\n        this.directive = directive;\n    }\n    get isLiteral() {\n        return false;\n    }\n    get isExpression() {\n        return true;\n    }\n    static validateExpression(expression, allowedContext) {\n        const { namedContexts, functions } = splitAllowedContext(allowedContext);\n        // Parse\n        const lexer = new Lexer(expression);\n        const result = lexer.lex();\n        const p = new Parser(result.tokens, namedContexts, functions);\n        p.parse();\n    }\n}\n//# sourceMappingURL=expression-token.js.map","export { TemplateToken } from \"./template-token\";\nexport { ScalarToken } from \"./scalar-token\";\nexport { LiteralToken } from \"./literal-token\";\nexport { StringToken } from \"./string-token\";\nexport { NumberToken } from \"./number-token\";\nexport { BooleanToken } from \"./boolean-token\";\nexport { NullToken } from \"./null-token\";\nexport { KeyValuePair } from \"./key-value-pair\";\nexport { SequenceToken } from \"./sequence-token\";\nexport { MappingToken } from \"./mapping-token\";\nexport { ExpressionToken } from \"./expression-token\";\nexport { BasicExpressionToken } from \"./basic-expression-token\";\nexport { InsertExpressionToken } from \"./insert-expression-token\";\n//# sourceMappingURL=index.js.map","import { ScalarToken, ExpressionToken } from \".\";\nimport { INSERT_DIRECTIVE, OPEN_EXPRESSION, CLOSE_EXPRESSION } from \"../template-constants\";\nimport { TokenType } from \"./types\";\nexport class InsertExpressionToken extends ExpressionToken {\n    constructor(file, range, definitionInfo) {\n        super(TokenType.InsertExpression, file, range, INSERT_DIRECTIVE, definitionInfo);\n    }\n    clone(omitSource) {\n        return omitSource\n            ? new InsertExpressionToken(undefined, undefined, this.definitionInfo)\n            : new InsertExpressionToken(this.file, this.range, this.definitionInfo);\n    }\n    toString() {\n        return `${OPEN_EXPRESSION} ${INSERT_DIRECTIVE} ${CLOSE_EXPRESSION}`;\n    }\n    toDisplayString() {\n        return ScalarToken.trimDisplayString(this.toString());\n    }\n    toJSON() {\n        return {\n            type: TokenType.InsertExpression,\n            expr: \"insert\"\n        };\n    }\n}\n//# sourceMappingURL=insert-expression-token.js.map","export class KeyValuePair {\n    constructor(key, value) {\n        this.key = key;\n        this.value = value;\n    }\n}\n//# sourceMappingURL=key-value-pair.js.map","import { ScalarToken } from \"./scalar-token\";\nexport class LiteralToken extends ScalarToken {\n    constructor(type, file, range, definitionInfo) {\n        super(type, file, range, definitionInfo);\n    }\n    get isLiteral() {\n        return true;\n    }\n    get isExpression() {\n        return false;\n    }\n    toDisplayString() {\n        return ScalarToken.trimDisplayString(this.toString());\n    }\n    /**\n     * Throws a good debug message when an unexpected literal value is encountered\n     */\n    assertUnexpectedValue(objectDescription) {\n        throw new Error(`Error while reading '${objectDescription}'. Unexpected value '${this.toString()}'`);\n    }\n}\n//# sourceMappingURL=literal-token.js.map","import { TemplateToken, KeyValuePair } from \".\";\nimport { TokenType } from \"./types\";\nexport class MappingToken extends TemplateToken {\n    constructor(file, range, definitionInfo) {\n        super(TokenType.Mapping, file, range, definitionInfo);\n        this.map = [];\n    }\n    get count() {\n        return this.map.length;\n    }\n    get isScalar() {\n        return false;\n    }\n    get isLiteral() {\n        return false;\n    }\n    get isExpression() {\n        return false;\n    }\n    add(key, value) {\n        this.map.push(new KeyValuePair(key, value));\n    }\n    get(index) {\n        return this.map[index];\n    }\n    find(key) {\n        const pair = this.map.find(pair => pair.key.toString() === key);\n        return pair?.value;\n    }\n    remove(index) {\n        this.map.splice(index, 1);\n    }\n    clone(omitSource) {\n        const result = omitSource\n            ? new MappingToken(undefined, undefined, this.definitionInfo)\n            : new MappingToken(this.file, this.range, this.definitionInfo);\n        for (const item of this.map) {\n            result.add(item.key.clone(omitSource), item.value.clone(omitSource));\n        }\n        return result;\n    }\n    toJSON() {\n        const items = [];\n        for (const item of this.map) {\n            items.push({ Key: item.key, Value: item.value });\n        }\n        return {\n            type: TokenType.Mapping,\n            map: items\n        };\n    }\n    *[Symbol.iterator]() {\n        for (const item of this.map) {\n            yield item;\n        }\n    }\n}\n//# sourceMappingURL=mapping-token.js.map","import { LiteralToken } from \".\";\nimport { TokenType } from \"./types\";\nexport class NullToken extends LiteralToken {\n    constructor(file, range, definitionInfo) {\n        super(TokenType.Null, file, range, definitionInfo);\n    }\n    clone(omitSource) {\n        return omitSource\n            ? new NullToken(undefined, undefined, this.definitionInfo)\n            : new NullToken(this.file, this.range, this.definitionInfo);\n    }\n    toString() {\n        return \"\";\n    }\n    toJSON() {\n        return null;\n    }\n}\n//# sourceMappingURL=null-token.js.map","import { LiteralToken } from \".\";\nimport { TokenType } from \"./types\";\nexport class NumberToken extends LiteralToken {\n    constructor(file, range, value, definitionInfo) {\n        super(TokenType.Number, file, range, definitionInfo);\n        this.num = value;\n    }\n    get value() {\n        return this.num;\n    }\n    clone(omitSource) {\n        return omitSource\n            ? new NumberToken(undefined, undefined, this.num, this.definitionInfo)\n            : new NumberToken(this.file, this.range, this.num, this.definitionInfo);\n    }\n    toString() {\n        return `${this.num}`;\n    }\n    toJSON() {\n        return this.num;\n    }\n}\n//# sourceMappingURL=number-token.js.map","import { TemplateToken } from \"./template-token\";\n/**\n * Base class for everything that is not a mapping or sequence\n */\nexport class ScalarToken extends TemplateToken {\n    constructor(type, file, range, definitionInfo) {\n        super(type, file, range, definitionInfo);\n    }\n    get isScalar() {\n        return true;\n    }\n    static trimDisplayString(displayString) {\n        let firstLine = displayString.trimStart();\n        const firstNewLine = firstLine.indexOf(\"\\n\");\n        const firstCarriageReturn = firstLine.indexOf(\"\\r\");\n        if (firstNewLine >= 0 || firstCarriageReturn >= 0) {\n            firstLine = firstLine.substr(0, Math.min(firstNewLine >= 0 ? firstNewLine : Number.MAX_VALUE, firstCarriageReturn >= 0 ? firstCarriageReturn : Number.MAX_VALUE));\n        }\n        return firstLine;\n    }\n}\n//# sourceMappingURL=scalar-token.js.map","import { TemplateToken } from \".\";\nimport { TokenType } from \"./types\";\nexport class SequenceToken extends TemplateToken {\n    constructor(file, range, definitionInfo) {\n        super(TokenType.Sequence, file, range, definitionInfo);\n        this.seq = [];\n    }\n    get count() {\n        return this.seq.length;\n    }\n    get isScalar() {\n        return false;\n    }\n    get isLiteral() {\n        return false;\n    }\n    get isExpression() {\n        return false;\n    }\n    add(value) {\n        this.seq.push(value);\n    }\n    get(index) {\n        return this.seq[index];\n    }\n    clone(omitSource) {\n        const result = omitSource\n            ? new SequenceToken(undefined, undefined, this.definitionInfo)\n            : new SequenceToken(this.file, this.range, this.definitionInfo);\n        for (const item of this.seq) {\n            result.add(item.clone(omitSource));\n        }\n        return result;\n    }\n    toJSON() {\n        return {\n            type: TokenType.Sequence,\n            seq: this.seq\n        };\n    }\n    *[Symbol.iterator]() {\n        for (const item of this.seq) {\n            yield item;\n        }\n    }\n}\n//# sourceMappingURL=sequence-token.js.map","import { LiteralToken } from \".\";\nimport { TokenType } from \"./types\";\nexport class StringToken extends LiteralToken {\n    constructor(file, range, value, definitionInfo, source) {\n        super(TokenType.String, file, range, definitionInfo);\n        this.value = value;\n        this.source = source;\n    }\n    clone(omitSource) {\n        return omitSource\n            ? new StringToken(undefined, undefined, this.value, this.definitionInfo, this.source)\n            : new StringToken(this.file, this.range, this.value, this.definitionInfo, this.source);\n    }\n    toString() {\n        return this.value;\n    }\n    toJSON() {\n        return this.value;\n    }\n}\n//# sourceMappingURL=string-token.js.map","import { TraversalState } from \"./traversal-state\";\nimport { TokenType, tokenTypeName } from \"./types\";\nexport class TemplateTokenError extends Error {\n    constructor(message, token) {\n        super(message);\n        this.token = token;\n    }\n}\nexport class TemplateToken {\n    /**\n     * Base class for all template tokens\n     */\n    constructor(type, file, range, definitionInfo) {\n        this.type = type;\n        this.file = file;\n        this.range = range;\n        this.definitionInfo = definitionInfo;\n    }\n    get templateTokenType() {\n        return this.type;\n    }\n    get line() {\n        return this.range?.start.line;\n    }\n    get col() {\n        return this.range?.start.column;\n    }\n    get definition() {\n        return this.definitionInfo?.definition;\n    }\n    get description() {\n        return this._description || this.propertyDefinition?.description || this.definition?.description;\n    }\n    set description(description) {\n        this._description = description;\n    }\n    typeName() {\n        return tokenTypeName(this.type);\n    }\n    /**\n     * Asserts expected type and throws a good debug message if unexpected\n     */\n    assertNull(objectDescription) {\n        if (this.type === TokenType.Null) {\n            return this;\n        }\n        throw new TemplateTokenError(`Unexpected type '${this.typeName()}' encountered while reading '${objectDescription}'. The type '${tokenTypeName(TokenType.Null)}' was expected.`, this);\n    }\n    /**\n     * Asserts expected type and throws a good debug message if unexpected\n     */\n    assertBoolean(objectDescription) {\n        if (this.type === TokenType.Boolean) {\n            return this;\n        }\n        throw new TemplateTokenError(`Unexpected type '${this.typeName()}' encountered while reading '${objectDescription}'. The type '${tokenTypeName(TokenType.Boolean)}' was expected.`, this);\n    }\n    /**\n     * Asserts expected type and throws a good debug message if unexpected\n     */\n    assertNumber(objectDescription) {\n        if (this.type === TokenType.Number) {\n            return this;\n        }\n        throw new TemplateTokenError(`Unexpected type '${this.typeName()}' encountered while reading '${objectDescription}'. The type '${tokenTypeName(TokenType.Number)}' was expected.`, this);\n    }\n    /**\n     * Asserts expected type and throws a good debug message if unexpected\n     */\n    assertString(objectDescription) {\n        if (this.type === TokenType.String) {\n            return this;\n        }\n        throw new TemplateTokenError(`Unexpected type '${this.typeName()}' encountered while reading '${objectDescription}'. The type '${tokenTypeName(TokenType.String)}' was expected.`, this);\n    }\n    /**\n     * Asserts expected type and throws a good debug message if unexpected\n     */\n    assertScalar(objectDescription) {\n        if (this?.isScalar === true) {\n            return this;\n        }\n        throw new TemplateTokenError(`Unexpected type '${this.typeName()}' encountered while reading '${objectDescription}'. The type 'ScalarToken' was expected.`, this);\n    }\n    /**\n     * Asserts expected type and throws a good debug message if unexpected\n     */\n    assertSequence(objectDescription) {\n        if (this.type === TokenType.Sequence) {\n            return this;\n        }\n        throw new TemplateTokenError(`Unexpected type '${this.typeName()}' encountered while reading '${objectDescription}'. The type '${tokenTypeName(TokenType.Sequence)}' was expected.`, this);\n    }\n    /**\n     * Asserts expected type and throws a good debug message if unexpected\n     */\n    assertMapping(objectDescription) {\n        if (this.type === TokenType.Mapping) {\n            return this;\n        }\n        throw new TemplateTokenError(`Unexpected type '${this.typeName()}' encountered while reading '${objectDescription}'. The type '${tokenTypeName(TokenType.Mapping)}' was expected.`, this);\n    }\n    /**\n     * Returns all tokens (depth first)\n     * @param value The object to travese\n     * @param omitKeys Whether to omit mapping keys\n     */\n    static *traverse(value, omitKeys) {\n        yield [undefined, value, undefined];\n        switch (value.templateTokenType) {\n            case TokenType.Sequence:\n            case TokenType.Mapping: {\n                let state = new TraversalState(undefined, value);\n                state = new TraversalState(state, value);\n                while (state.parent) {\n                    if (state.moveNext(omitKeys ?? false)) {\n                        value = state.current;\n                        yield [state.parent?.current, value, state.currentKey];\n                        switch (value.type) {\n                            case TokenType.Sequence:\n                            case TokenType.Mapping:\n                                state = new TraversalState(state, value);\n                                break;\n                        }\n                    }\n                    else {\n                        state = state.parent;\n                    }\n                }\n                break;\n            }\n        }\n    }\n    toJSON() {\n        return undefined;\n    }\n}\n//# sourceMappingURL=template-token.js.map","import { TokenType } from \"./types\";\nexport class TraversalState {\n    constructor(parent, token) {\n        this.index = -1;\n        this.isKey = false;\n        this.parent = parent;\n        this._token = token;\n        this.current = token;\n    }\n    moveNext(omitKeys) {\n        switch (this._token.templateTokenType) {\n            case TokenType.Sequence: {\n                const sequence = this._token;\n                if (++this.index < sequence.count) {\n                    this.current = sequence.get(this.index);\n                    return true;\n                }\n                this.current = undefined;\n                return false;\n            }\n            case TokenType.Mapping: {\n                const mapping = this._token;\n                // Already returned the key, now return the value\n                if (this.isKey) {\n                    this.isKey = false;\n                    this.currentKey = this.current;\n                    this.current = mapping.get(this.index).value;\n                    return true;\n                }\n                // Move next\n                if (++this.index < mapping.count) {\n                    // Skip the key, return the value\n                    if (omitKeys) {\n                        this.isKey = false;\n                        this.currentKey = mapping.get(this.index).key;\n                        this.current = mapping.get(this.index).value;\n                        return true;\n                    }\n                    // Return the key\n                    this.isKey = true;\n                    this.currentKey = undefined;\n                    this.current = mapping.get(this.index).key;\n                    return true;\n                }\n                this.currentKey = undefined;\n                this.current = undefined;\n                return false;\n            }\n            default:\n                throw new Error(`Unexpected token type '${this._token.templateTokenType}' when traversing state`);\n        }\n    }\n}\n//# sourceMappingURL=traversal-state.js.map","import { MappingToken } from \"./mapping-token\";\nimport { SequenceToken } from \"./sequence-token\";\nimport { TokenType } from \"./types\";\nexport function isLiteral(t) {\n    return t.isLiteral;\n}\nexport function isScalar(t) {\n    return t.isScalar;\n}\nexport function isString(t) {\n    return isLiteral(t) && t.templateTokenType === TokenType.String;\n}\nexport function isNumber(t) {\n    return isLiteral(t) && t.templateTokenType === TokenType.Number;\n}\nexport function isBoolean(t) {\n    return isLiteral(t) && t.templateTokenType === TokenType.Boolean;\n}\nexport function isBasicExpression(t) {\n    return isScalar(t) && t.templateTokenType === TokenType.BasicExpression;\n}\nexport function isSequence(t) {\n    return t instanceof SequenceToken;\n}\nexport function isMapping(t) {\n    return t instanceof MappingToken;\n}\n//# sourceMappingURL=type-guards.js.map","export var TokenType;\n(function (TokenType) {\n    TokenType[TokenType[\"String\"] = 0] = \"String\";\n    TokenType[TokenType[\"Sequence\"] = 1] = \"Sequence\";\n    TokenType[TokenType[\"Mapping\"] = 2] = \"Mapping\";\n    TokenType[TokenType[\"BasicExpression\"] = 3] = \"BasicExpression\";\n    TokenType[TokenType[\"InsertExpression\"] = 4] = \"InsertExpression\";\n    TokenType[TokenType[\"Boolean\"] = 5] = \"Boolean\";\n    TokenType[TokenType[\"Number\"] = 6] = \"Number\";\n    TokenType[TokenType[\"Null\"] = 7] = \"Null\";\n})(TokenType || (TokenType = {}));\nexport function tokenTypeName(type) {\n    switch (type) {\n        case TokenType.String:\n            return \"StringToken\";\n        case TokenType.Sequence:\n            return \"SequenceToken\";\n        case TokenType.Mapping:\n            return \"MappingToken\";\n        case TokenType.BasicExpression:\n            return \"BasicExpressionToken\";\n        case TokenType.InsertExpression:\n            return \"InsertExpressionToken\";\n        case TokenType.Boolean:\n            return \"BooleanToken\";\n        case TokenType.Number:\n            return \"NumberToken\";\n        case TokenType.Null:\n            return \"NullToken\";\n        default: {\n            // Use never to ensure exhaustiveness\n            const exhaustiveCheck = type;\n            throw new Error(`Unhandled token type: ${type} ${exhaustiveCheck}}`);\n        }\n    }\n}\n//# sourceMappingURL=types.js.map","export class NoOperationTraceWriter {\n    error() {\n        // do nothing\n    }\n    info() {\n        // do nothing\n    }\n    verbose() {\n        // do nothing\n    }\n}\n//# sourceMappingURL=trace-writer.js.map","export function parseFileReference(ref) {\n    if (ref.startsWith(\"./\")) {\n        return {\n            path: ref.substring(2)\n        };\n    }\n    const [remotePath, version] = ref.split(\"@\");\n    const [owner, repository, ...pathSegments] = remotePath.split(\"/\").filter(s => s.length > 0);\n    if (!owner || !repository || !version) {\n        throw new Error(`Invalid file reference: ${ref}`);\n    }\n    return {\n        repository,\n        owner,\n        path: pathSegments.join(\"/\"),\n        version\n    };\n}\nexport function fileIdentifier(ref) {\n    if (!(\"repository\" in ref)) {\n        return \"./\" + ref.path;\n    }\n    return `${ref.owner}/${ref.repository}/${ref.path}@${ref.version}`;\n}\n//# sourceMappingURL=file-reference.js.map","export const WORKFLOW_ROOT = \"workflow-root-strict\";\n//# sourceMappingURL=workflow-constants.js.map","import { TemplateContext, TemplateValidationErrors } from \"../templates/template-context\";\nimport * as templateReader from \"../templates/template-reader\";\nimport { WORKFLOW_ROOT } from \"./workflow-constants\";\nimport { getWorkflowSchema } from \"./workflow-schema\";\nimport { YamlObjectReader } from \"./yaml-object-reader\";\nexport function parseWorkflow(entryFile, contextOrTrace) {\n    const context = contextOrTrace instanceof TemplateContext\n        ? contextOrTrace\n        : new TemplateContext(new TemplateValidationErrors(), getWorkflowSchema(), contextOrTrace);\n    const fileId = context.getFileId(entryFile.name);\n    const reader = new YamlObjectReader(fileId, entryFile.content);\n    if (reader.errors.length > 0) {\n        // The file is not valid YAML, template errors could be misleading\n        for (const err of reader.errors) {\n            context.error(fileId, err.message, err.range);\n        }\n        return {\n            context,\n            value: undefined\n        };\n    }\n    const result = templateReader.readTemplate(context, WORKFLOW_ROOT, reader, fileId);\n    return {\n        context,\n        value: result\n    };\n}\n//# sourceMappingURL=workflow-parser.js.map","import { JSONObjectReader } from \"../templates/json-object-reader\";\nimport { TemplateSchema } from \"../templates/schema\";\nimport WorkflowSchema from \"../workflow-v1.0.json\" assert { type: \"json\" };\nlet schema;\nexport function getWorkflowSchema() {\n    if (schema === undefined) {\n        const json = JSON.stringify(WorkflowSchema);\n        schema = TemplateSchema.load(new JSONObjectReader(undefined, json));\n    }\n    return schema;\n}\n//# sourceMappingURL=workflow-schema.js.map","import { isCollection, isDocument, isMap, isPair, isScalar, isSeq, LineCounter, parseDocument } from \"yaml\";\nimport { EventType, ParseEvent } from \"../templates/parse-event\";\nimport { BooleanToken, MappingToken, NullToken, NumberToken, SequenceToken, StringToken } from \"../templates/tokens/index\";\nexport class YamlObjectReader {\n    constructor(fileId, content) {\n        this.lineCounter = new LineCounter();\n        this.errors = [];\n        const doc = parseDocument(content, {\n            lineCounter: this.lineCounter,\n            keepSourceTokens: true,\n            uniqueKeys: false // Uniqueness is validated by the template reader\n        });\n        for (const err of doc.errors) {\n            this.errors.push({ message: err.message, range: rangeFromLinePos(err.linePos) });\n        }\n        this._generator = this.getNodes(doc);\n        this.fileId = fileId;\n    }\n    *getNodes(node) {\n        let range = this.getRange(node);\n        if (isDocument(node)) {\n            yield new ParseEvent(EventType.DocumentStart);\n            for (const item of this.getNodes(node.contents)) {\n                yield item;\n            }\n            yield new ParseEvent(EventType.DocumentEnd);\n        }\n        if (isCollection(node)) {\n            if (isSeq(node)) {\n                yield new ParseEvent(EventType.SequenceStart, new SequenceToken(this.fileId, range, undefined));\n            }\n            else if (isMap(node)) {\n                yield new ParseEvent(EventType.MappingStart, new MappingToken(this.fileId, range, undefined));\n            }\n            for (const item of node.items) {\n                for (const child of this.getNodes(item)) {\n                    yield child;\n                }\n            }\n            if (isSeq(node)) {\n                yield new ParseEvent(EventType.SequenceEnd);\n            }\n            else if (isMap(node)) {\n                yield new ParseEvent(EventType.MappingEnd);\n            }\n        }\n        if (isScalar(node)) {\n            yield new ParseEvent(EventType.Literal, YamlObjectReader.getLiteralToken(this.fileId, range, node));\n        }\n        if (isPair(node)) {\n            const scalarKey = node.key;\n            range = this.getRange(scalarKey);\n            const key = scalarKey.value;\n            yield new ParseEvent(EventType.Literal, new StringToken(this.fileId, range, key, undefined));\n            for (const child of this.getNodes(node.value)) {\n                yield child;\n            }\n        }\n    }\n    getRange(node) {\n        const range = node?.range ?? [];\n        const startPos = range[0];\n        const endPos = range[1];\n        if (startPos !== undefined && endPos !== undefined) {\n            const slp = this.lineCounter.linePos(startPos);\n            const elp = this.lineCounter.linePos(endPos);\n            return {\n                start: { line: slp.line, column: slp.col },\n                end: { line: elp.line, column: elp.col }\n            };\n        }\n        return undefined;\n    }\n    static getLiteralToken(fileId, range, token) {\n        const value = token.value;\n        if (value === null || value === undefined) {\n            return new NullToken(fileId, range, undefined);\n        }\n        switch (typeof value) {\n            case \"number\":\n                return new NumberToken(fileId, range, value, undefined);\n            case \"boolean\":\n                return new BooleanToken(fileId, range, value, undefined);\n            case \"string\": {\n                let source;\n                if (token.srcToken && \"source\" in token.srcToken) {\n                    source = token.srcToken.source;\n                }\n                return new StringToken(fileId, range, value, undefined, source);\n            }\n            default:\n                throw new Error(`Unexpected value type '${typeof value}' when reading object`);\n        }\n    }\n    allowLiteral() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.Literal) {\n                this._current = this._generator.next();\n                return parseEvent.token;\n            }\n        }\n        return undefined;\n    }\n    allowSequenceStart() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.SequenceStart) {\n                this._current = this._generator.next();\n                return parseEvent.token;\n            }\n        }\n        return undefined;\n    }\n    allowSequenceEnd() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.SequenceEnd) {\n                this._current = this._generator.next();\n                return true;\n            }\n        }\n        return false;\n    }\n    allowMappingStart() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.MappingStart) {\n                this._current = this._generator.next();\n                return parseEvent.token;\n            }\n        }\n        return undefined;\n    }\n    allowMappingEnd() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.MappingEnd) {\n                this._current = this._generator.next();\n                return true;\n            }\n        }\n        return false;\n    }\n    validateEnd() {\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.DocumentEnd) {\n                this._current = this._generator.next();\n                return;\n            }\n        }\n        throw new Error(\"Expected end of reader\");\n    }\n    validateStart() {\n        if (!this._current) {\n            this._current = this._generator.next();\n        }\n        if (!this._current.done) {\n            const parseEvent = this._current.value;\n            if (parseEvent.type === EventType.DocumentStart) {\n                this._current = this._generator.next();\n                return;\n            }\n        }\n        throw new Error(\"Expected start of reader\");\n    }\n}\nfunction rangeFromLinePos(linePos) {\n    if (linePos === undefined) {\n        return;\n    }\n    // TokenRange and linePos are both 1-based\n    const start = { line: linePos[0].line, column: linePos[0].col };\n    const end = linePos.length == 2 ? { line: linePos[1].line, column: linePos[1].col } : start;\n    return { start, end };\n}\n//# sourceMappingURL=yaml-object-reader.js.map","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = (module) => {\n\tvar getter = module && module.__esModule ?\n\t\t() => (module['default']) :\n\t\t() => (module);\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","import { getInput, setFailed, group, error, setOutput } from '@actions/core';\nimport { NoOperationTraceWriter, ParseWorkflowResult, parseWorkflow } from '@actions/workflow-parser';\nimport { readFileSync, readdirSync } from 'fs';\nimport { join } from 'path';\n\ninterface Input {\n  token: string;\n  owner: string;\n  repo: string;\n  files: string;\n}\n\nconst WORKFLOW_DIR = '.github/workflows';\n\nexport function getInputs(): Input {\n  const result = {} as Input;\n  result.token = getInput('github-token');\n  result.owner = getInput('owner');\n  result.repo = getInput('repo');\n  result.files = getInput('files');\n  return result;\n}\n\nconst run = async (): Promise<void> => {\n  const inputs = getInputs();\n  const workflowFiles = inputs.files ?\n    inputs.files.split(', ')\n    :\n    readdirSync(WORKFLOW_DIR)\n      .filter(name => name.endsWith('.yml') || name.endsWith('.yaml'))\n      .map(name => join(WORKFLOW_DIR, name));\n\n  let results: ParseWorkflowResult[] = [];\n  workflowFiles.forEach(fileName => {\n    group(`Linting ${fileName}`, async () => {\n      try {\n        const result = parseWorkflow({\n          name: fileName,\n          content: readFileSync(fileName, 'utf8')\n        }, new NoOperationTraceWriter());\n        result.context.errors.getErrors()?.forEach(err => {\n          const message = err.message.split(/\\): /);\n          error(\n            message[1],\n            {\n              endColumn: err.range?.end.column,\n              startColumn: err.range?.start.column,\n              endLine: err.range?.end.line,\n              startLine: err.range?.start.line,\n              file: result.context.getFileTable()[0],\n            }\n          )\n          results.push(result);\n        });\n      } catch (err) {\n        setFailed(`Workflow ${fileName} failed to parse: ${(err instanceof Error) ? err.message : err}`);\n        return;\n      }\n    });\n  });\n  // setOutput('results', JSON.stringify(results))\n};\n\nrun();\n"],"names":[],"sourceRoot":""}